{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the results and races datasets\n",
    "results = pd.read_csv('dataset/results.csv')\n",
    "races = pd.read_csv('dataset/races.csv')\n",
    "races['date'] = pd.to_datetime(races['date'])\n",
    "# sort by date\n",
    "races = races.sort_values('date')\n",
    "races['sorted_id'] = races.reset_index(drop=True).index + 1\n",
    "drivers = pd.read_csv('dataset/drivers.csv')\n",
    "\n",
    "# save races as races_sorted csv\n",
    "races.to_csv('races_time_sorted.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join them results on drivers using driverrId\n",
    "\n",
    "results= results.merge(drivers, on='driverId')\n",
    "# join on race using raceId\n",
    "\n",
    "results = results.merge(races, on='raceId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resultId</th>\n",
       "      <th>raceId</th>\n",
       "      <th>driverId</th>\n",
       "      <th>constructorId</th>\n",
       "      <th>number_x</th>\n",
       "      <th>grid</th>\n",
       "      <th>position</th>\n",
       "      <th>positionText</th>\n",
       "      <th>positionOrder</th>\n",
       "      <th>points</th>\n",
       "      <th>...</th>\n",
       "      <th>fp1_time</th>\n",
       "      <th>fp2_date</th>\n",
       "      <th>fp2_time</th>\n",
       "      <th>fp3_date</th>\n",
       "      <th>fp3_time</th>\n",
       "      <th>quali_date</th>\n",
       "      <th>quali_time</th>\n",
       "      <th>sprint_date</th>\n",
       "      <th>sprint_time</th>\n",
       "      <th>sorted_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>786</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   resultId  raceId  driverId  constructorId number_x  grid position  \\\n",
       "0         1      18         1              1       22     1        1   \n",
       "1         2      18         2              2        3     5        2   \n",
       "2         3      18         3              3        7     7        3   \n",
       "3         4      18         4              4        5    11        4   \n",
       "4         5      18         5              1       23     3        5   \n",
       "\n",
       "  positionText  positionOrder  points  ...  fp1_time fp2_date fp2_time  \\\n",
       "0            1              1    10.0  ...        \\N       \\N       \\N   \n",
       "1            2              2     8.0  ...        \\N       \\N       \\N   \n",
       "2            3              3     6.0  ...        \\N       \\N       \\N   \n",
       "3            4              4     5.0  ...        \\N       \\N       \\N   \n",
       "4            5              5     4.0  ...        \\N       \\N       \\N   \n",
       "\n",
       "  fp3_date fp3_time quali_date quali_time  sprint_date sprint_time sorted_id  \n",
       "0       \\N       \\N         \\N         \\N           \\N          \\N       786  \n",
       "1       \\N       \\N         \\N         \\N           \\N          \\N       786  \n",
       "2       \\N       \\N         \\N         \\N           \\N          \\N       786  \n",
       "3       \\N       \\N         \\N         \\N           \\N          \\N       786  \n",
       "4       \\N       \\N         \\N         \\N           \\N          \\N       786  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to temp_results.csv\n",
    "results.to_csv('temp_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the columns we want we onlt want reusltId and raceId\n",
    "results_cpy = results[['resultId' ,'raceId','driverId','position','driverRef','year','sorted_id']]\n",
    "# sort on sorted_id\n",
    "results_cpy = results_cpy.sort_values('sorted_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resultId</th>\n",
       "      <th>raceId</th>\n",
       "      <th>driverId</th>\n",
       "      <th>position</th>\n",
       "      <th>driverRef</th>\n",
       "      <th>year</th>\n",
       "      <th>sorted_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25810</th>\n",
       "      <td>20044</td>\n",
       "      <td>833</td>\n",
       "      <td>661</td>\n",
       "      <td>\\N</td>\n",
       "      <td>peter_walker</td>\n",
       "      <td>1950</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25807</th>\n",
       "      <td>20041</td>\n",
       "      <td>833</td>\n",
       "      <td>640</td>\n",
       "      <td>\\N</td>\n",
       "      <td>graffenried</td>\n",
       "      <td>1950</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25811</th>\n",
       "      <td>20178</td>\n",
       "      <td>833</td>\n",
       "      <td>666</td>\n",
       "      <td>\\N</td>\n",
       "      <td>rolt</td>\n",
       "      <td>1950</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25812</th>\n",
       "      <td>20038</td>\n",
       "      <td>833</td>\n",
       "      <td>669</td>\n",
       "      <td>\\N</td>\n",
       "      <td>bira</td>\n",
       "      <td>1950</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25813</th>\n",
       "      <td>20027</td>\n",
       "      <td>833</td>\n",
       "      <td>686</td>\n",
       "      <td>3</td>\n",
       "      <td>reg_parnell</td>\n",
       "      <td>1950</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       resultId  raceId  driverId position     driverRef  year  sorted_id\n",
       "25810     20044     833       661       \\N  peter_walker  1950          1\n",
       "25807     20041     833       640       \\N   graffenried  1950          1\n",
       "25811     20178     833       666       \\N          rolt  1950          1\n",
       "25812     20038     833       669       \\N          bira  1950          1\n",
       "25813     20027     833       686        3   reg_parnell  1950          1"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_cpy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop where postion in \\\\N\n",
    "results_cpy = results_cpy[results_cpy['position'] != '\\\\N']\n",
    "# make it int\n",
    "results_cpy['position'] = results_cpy['position'].astype(int)\n",
    "\n",
    "#only use reults from 1995 to 2022\n",
    "results_cpy = results_cpy[results_cpy['year'] >= 1960]\n",
    "results_cpy = results_cpy[results_cpy['year'] <= 2022]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# want to make a frame having all drivers exwept with driverid ==1 \n",
    "# and another frame having only dirverid ==1\n",
    "\n",
    "# get all drivers\n",
    "# make reults cpy have only positon between 1 and 20\n",
    "results_cpy = results_cpy[results_cpy['position'] <= 20]\n",
    "results_cpy = results_cpy[results_cpy['position'] >= 1]\n",
    "results_without_ham = results_cpy[results_cpy['driverId'] != 1]\n",
    "# sort on raceId\n",
    "results_ham = results_without_ham.sort_values(by=['raceId'])\n",
    "\n",
    "\n",
    "# get only hamilton\n",
    "results_ham = results_cpy[results_cpy['driverId'] == 1]\n",
    "# sort on raceId\n",
    "results_ham = results_ham.sort_values(by=['raceId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make each driver have a list of all his races\n",
    "# make a list of all drivers\n",
    "drivers = results_without_ham['driverId'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resultId</th>\n",
       "      <th>raceId</th>\n",
       "      <th>driverId</th>\n",
       "      <th>position</th>\n",
       "      <th>driverRef</th>\n",
       "      <th>year</th>\n",
       "      <th>sorted_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>7580</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>hamilton</td>\n",
       "      <td>2009</td>\n",
       "      <td>805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782</th>\n",
       "      <td>7599</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>hamilton</td>\n",
       "      <td>2009</td>\n",
       "      <td>806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802</th>\n",
       "      <td>7617</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>hamilton</td>\n",
       "      <td>2009</td>\n",
       "      <td>807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822</th>\n",
       "      <td>7642</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>hamilton</td>\n",
       "      <td>2009</td>\n",
       "      <td>808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842</th>\n",
       "      <td>7665</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>hamilton</td>\n",
       "      <td>2009</td>\n",
       "      <td>809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     resultId  raceId  driverId  position driverRef  year  sorted_id\n",
       "762      7580       2         1         7  hamilton  2009        805\n",
       "782      7599       3         1         6  hamilton  2009        806\n",
       "802      7617       4         1         4  hamilton  2009        807\n",
       "822      7642       5         1         9  hamilton  2009        808\n",
       "842      7665       6         1        12  hamilton  2009        809"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_ham.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resultId</th>\n",
       "      <th>raceId</th>\n",
       "      <th>driverId</th>\n",
       "      <th>position</th>\n",
       "      <th>driverRef</th>\n",
       "      <th>year</th>\n",
       "      <th>sorted_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23604</th>\n",
       "      <td>18077</td>\n",
       "      <td>746</td>\n",
       "      <td>499</td>\n",
       "      <td>11</td>\n",
       "      <td>bonomi</td>\n",
       "      <td>1960</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23605</th>\n",
       "      <td>18079</td>\n",
       "      <td>746</td>\n",
       "      <td>500</td>\n",
       "      <td>13</td>\n",
       "      <td>munaron</td>\n",
       "      <td>1960</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23592</th>\n",
       "      <td>18072</td>\n",
       "      <td>746</td>\n",
       "      <td>404</td>\n",
       "      <td>6</td>\n",
       "      <td>ireland</td>\n",
       "      <td>1960</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23603</th>\n",
       "      <td>18076</td>\n",
       "      <td>746</td>\n",
       "      <td>498</td>\n",
       "      <td>10</td>\n",
       "      <td>gonzalez</td>\n",
       "      <td>1960</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23602</th>\n",
       "      <td>18075</td>\n",
       "      <td>746</td>\n",
       "      <td>497</td>\n",
       "      <td>9</td>\n",
       "      <td>larreta</td>\n",
       "      <td>1960</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       resultId  raceId  driverId  position driverRef  year  sorted_id\n",
       "23604     18077     746       499        11    bonomi  1960         85\n",
       "23605     18079     746       500        13   munaron  1960         85\n",
       "23592     18072     746       404         6   ireland  1960         85\n",
       "23603     18076     746       498        10  gonzalez  1960         85\n",
       "23602     18075     746       497         9   larreta  1960         85"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort on sotred_id\n",
    "results_ham = results_ham.sort_values(by=['sorted_id'])\n",
    "results_without_ham.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18  19\n",
      "  20  21  22  23  24  25  26  27  29  30  31  32  33  34  35  36  37  38\n",
      "  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54  55  56\n",
      "  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  73  74  75\n",
      "  76  77  78  79  81  82  83  84  85  86  87  88  89  90  91  92  93  94\n",
      "  95  96  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111 112\n",
      " 113 114 116 117 118 119 120 121 122 123 125 126 127 128 129 131 133 136\n",
      " 137 138 139 140 141 145 146 147 148 151 152 153 154 155 156 157 158 159\n",
      " 160 163 165 166 167 168 169 170 172 173 174 175 176 177 178 179 180 181\n",
      " 182 183 184 185 186 187 188 189 190 192 193 194 195 196 197 199 200 201\n",
      " 202 203 205 206 207 208 209 211 212 216 217 219 221 222 223 224 229 230\n",
      " 231 232 233 235 236 237 238 239 240 243 246 249 250 251 252 253 254 255\n",
      " 256 258 259 262 265 267 269 270 271 272 273 274 275 276 277 278 280 282\n",
      " 284 286 287 288 289 290 291 292 293 294 296 297 298 300 301 302 304 305\n",
      " 306 307 308 309 311 312 313 314 317 320 321 322 323 324 327 328 329 330\n",
      " 331 332 333 337 338 340 341 342 344 345 346 347 348 350 351 352 353 355\n",
      " 356 357 358 359 360 361 362 363 364 365 368 370 373 374 375 376 379 380\n",
      " 382 383 385 386 387 388 389 390 392 394 395 396 397 399 400 401 402 403\n",
      " 404 405 406 407 408 409 410 411 412 413 418 420 423 424 425 427 428 430\n",
      " 431 433 434 435 436 437 438 439 440 441 448 449 453 454 455 456 459 460\n",
      " 463 465 466 468 469 471 475 476 477 478 479 480 481 482 484 489 493 494\n",
      " 496 497 498 499 500 506 507 509 510 511 512 513 514 515 516 517 518 519\n",
      " 520 521 522 523 524 525 526 541 542 543 544 545 548 807 808 810 811 812\n",
      " 813 814 815 816 817 818 819 820 821 822 823 824 825 826 828 829 830 831\n",
      " 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849\n",
      " 850 851 852 853 854 855 856]\n"
     ]
    }
   ],
   "source": [
    "# for each driver\n",
    "# store his info\n",
    "\n",
    "\n",
    "# make a list of all drivers\n",
    "drivers = results_without_ham['driverId'].unique()\n",
    "drivers.sort()\n",
    "print(drivers)\n",
    "\n",
    "# make a dict of all drivers\n",
    "drivers_dict = {}\n",
    "for driver in drivers:\n",
    "    drivers_dict[driver] = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over all drivers\n",
    "sorted_keys = sorted(drivers_dict.keys())\n",
    "for id_key in sorted_keys:\n",
    "    wanted_df = results_without_ham[results_without_ham['driverId'] == id_key]\n",
    "    for index, row in wanted_df.iterrows():\n",
    "        if row['driverId'] == id_key:\n",
    "            drivers_dict[id_key].append(row['position'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129\n"
     ]
    }
   ],
   "source": [
    "# print count of those who have more than 120 elemnt\n",
    "count =0\n",
    "for key in drivers_dict:\n",
    "    if len(drivers_dict[key]) > 30:\n",
    "        count +=1\n",
    "        # print(key, len(drivers_dict[key]))\n",
    "print(count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 30\n",
      "3 30\n",
      "4 30\n",
      "5 30\n",
      "6 30\n",
      "7 20\n",
      "8 30\n",
      "9 30\n",
      "10 30\n",
      "11 30\n",
      "12 17\n",
      "13 30\n",
      "14 30\n",
      "15 30\n",
      "16 30\n",
      "17 30\n",
      "18 30\n",
      "19 14\n",
      "20 30\n",
      "21 30\n",
      "22 30\n",
      "23 30\n",
      "24 30\n",
      "25 30\n",
      "26 17\n",
      "27 30\n",
      "29 14\n",
      "30 30\n",
      "31 30\n",
      "32 30\n",
      "33 30\n",
      "34 1\n",
      "35 30\n",
      "36 3\n",
      "37 30\n",
      "38 9\n",
      "39 30\n",
      "40 5\n",
      "41 19\n",
      "42 11\n",
      "43 20\n",
      "44 30\n",
      "45 6\n",
      "46 9\n",
      "47 12\n",
      "48 30\n",
      "49 30\n",
      "50 30\n",
      "51 7\n",
      "52 8\n",
      "53 5\n",
      "54 9\n",
      "55 30\n",
      "56 30\n",
      "57 30\n",
      "58 10\n",
      "59 9\n",
      "60 13\n",
      "61 2\n",
      "62 6\n",
      "63 30\n",
      "64 30\n",
      "65 30\n",
      "66 8\n",
      "67 30\n",
      "68 12\n",
      "69 30\n",
      "70 18\n",
      "71 30\n",
      "73 12\n",
      "74 4\n",
      "75 18\n",
      "76 9\n",
      "77 30\n",
      "78 30\n",
      "79 30\n",
      "81 30\n",
      "82 3\n",
      "83 19\n",
      "84 30\n",
      "85 4\n",
      "86 2\n",
      "87 30\n",
      "88 30\n",
      "89 5\n",
      "90 17\n",
      "91 18\n",
      "92 15\n",
      "93 3\n",
      "94 30\n",
      "95 30\n",
      "96 7\n",
      "97 2\n",
      "98 1\n",
      "99 13\n",
      "100 30\n",
      "101 7\n",
      "102 30\n",
      "103 30\n",
      "104 30\n",
      "105 30\n",
      "106 4\n",
      "107 1\n",
      "108 5\n",
      "109 30\n",
      "110 30\n",
      "111 4\n",
      "112 30\n",
      "113 1\n",
      "114 15\n",
      "116 1\n",
      "117 30\n",
      "118 30\n",
      "119 30\n",
      "120 3\n",
      "121 6\n",
      "122 30\n",
      "123 30\n",
      "125 3\n",
      "126 2\n",
      "127 30\n",
      "128 3\n",
      "129 14\n",
      "131 30\n",
      "133 30\n",
      "136 12\n",
      "137 30\n",
      "138 30\n",
      "139 17\n",
      "140 30\n",
      "141 5\n",
      "145 30\n",
      "146 3\n",
      "147 4\n",
      "148 2\n",
      "151 6\n",
      "152 30\n",
      "153 30\n",
      "154 30\n",
      "155 30\n",
      "156 30\n",
      "157 15\n",
      "158 30\n",
      "159 11\n",
      "160 20\n",
      "163 30\n",
      "165 2\n",
      "166 30\n",
      "167 2\n",
      "168 1\n",
      "169 8\n",
      "170 18\n",
      "172 30\n",
      "173 30\n",
      "174 6\n",
      "175 30\n",
      "176 30\n",
      "177 30\n",
      "178 30\n",
      "179 6\n",
      "180 3\n",
      "181 13\n",
      "182 30\n",
      "183 5\n",
      "184 17\n",
      "185 7\n",
      "186 1\n",
      "187 30\n",
      "188 7\n",
      "189 3\n",
      "190 3\n",
      "192 11\n",
      "193 7\n",
      "194 8\n",
      "195 5\n",
      "196 10\n",
      "197 30\n",
      "199 30\n",
      "200 30\n",
      "201 6\n",
      "202 30\n",
      "203 30\n",
      "205 10\n",
      "206 30\n",
      "207 30\n",
      "208 2\n",
      "209 3\n",
      "211 12\n",
      "212 15\n",
      "216 3\n",
      "217 6\n",
      "219 10\n",
      "221 30\n",
      "222 30\n",
      "223 30\n",
      "224 30\n",
      "229 11\n",
      "230 30\n",
      "231 30\n",
      "232 16\n",
      "233 30\n",
      "235 30\n",
      "236 1\n",
      "237 6\n",
      "238 30\n",
      "239 30\n",
      "240 1\n",
      "243 30\n",
      "246 6\n",
      "249 1\n",
      "250 30\n",
      "251 4\n",
      "252 30\n",
      "253 2\n",
      "254 3\n",
      "255 14\n",
      "256 5\n",
      "258 8\n",
      "259 4\n",
      "262 16\n",
      "265 8\n",
      "267 4\n",
      "269 1\n",
      "270 2\n",
      "271 1\n",
      "272 1\n",
      "273 1\n",
      "274 1\n",
      "275 7\n",
      "276 5\n",
      "277 5\n",
      "278 30\n",
      "280 30\n",
      "282 1\n",
      "284 3\n",
      "286 1\n",
      "287 1\n",
      "288 8\n",
      "289 30\n",
      "290 17\n",
      "291 1\n",
      "292 2\n",
      "293 3\n",
      "294 6\n",
      "296 4\n",
      "297 1\n",
      "298 7\n",
      "300 1\n",
      "301 1\n",
      "302 1\n",
      "304 30\n",
      "305 30\n",
      "306 30\n",
      "307 30\n",
      "308 2\n",
      "309 30\n",
      "311 1\n",
      "312 7\n",
      "313 4\n",
      "314 16\n",
      "317 8\n",
      "320 11\n",
      "321 2\n",
      "322 6\n",
      "323 1\n",
      "324 1\n",
      "327 30\n",
      "328 30\n",
      "329 13\n",
      "330 7\n",
      "331 1\n",
      "332 7\n",
      "333 12\n",
      "337 7\n",
      "338 5\n",
      "340 6\n",
      "341 30\n",
      "342 1\n",
      "344 1\n",
      "345 30\n",
      "346 30\n",
      "347 30\n",
      "348 1\n",
      "350 8\n",
      "351 4\n",
      "352 4\n",
      "353 3\n",
      "355 1\n",
      "356 30\n",
      "357 4\n",
      "358 30\n",
      "359 4\n",
      "360 30\n",
      "361 9\n",
      "362 2\n",
      "363 3\n",
      "364 30\n",
      "365 1\n",
      "368 2\n",
      "370 12\n",
      "373 30\n",
      "374 20\n",
      "375 6\n",
      "376 6\n",
      "379 1\n",
      "380 3\n",
      "382 3\n",
      "383 15\n",
      "385 30\n",
      "386 30\n",
      "387 3\n",
      "388 5\n",
      "389 6\n",
      "390 2\n",
      "392 1\n",
      "394 10\n",
      "395 1\n",
      "396 4\n",
      "397 8\n",
      "399 4\n",
      "400 1\n",
      "401 12\n",
      "402 1\n",
      "403 30\n",
      "404 30\n",
      "405 4\n",
      "406 2\n",
      "407 1\n",
      "408 18\n",
      "409 1\n",
      "410 1\n",
      "411 1\n",
      "412 1\n",
      "413 1\n",
      "418 13\n",
      "420 1\n",
      "423 2\n",
      "424 1\n",
      "425 3\n",
      "427 12\n",
      "428 1\n",
      "430 19\n",
      "431 1\n",
      "433 1\n",
      "434 4\n",
      "435 3\n",
      "436 2\n",
      "437 6\n",
      "438 2\n",
      "439 1\n",
      "440 8\n",
      "441 1\n",
      "448 1\n",
      "449 1\n",
      "453 5\n",
      "454 3\n",
      "455 2\n",
      "456 5\n",
      "459 1\n",
      "460 1\n",
      "463 1\n",
      "465 1\n",
      "466 1\n",
      "468 2\n",
      "469 1\n",
      "471 1\n",
      "475 8\n",
      "476 13\n",
      "477 2\n",
      "478 4\n",
      "479 9\n",
      "480 1\n",
      "481 6\n",
      "482 7\n",
      "484 1\n",
      "489 1\n",
      "493 1\n",
      "494 1\n",
      "496 1\n",
      "497 1\n",
      "498 1\n",
      "499 1\n",
      "500 2\n",
      "506 1\n",
      "507 1\n",
      "509 1\n",
      "510 1\n",
      "511 1\n",
      "512 1\n",
      "513 1\n",
      "514 1\n",
      "515 1\n",
      "516 1\n",
      "517 1\n",
      "518 1\n",
      "519 1\n",
      "520 1\n",
      "521 1\n",
      "522 1\n",
      "523 1\n",
      "524 1\n",
      "525 1\n",
      "526 1\n",
      "541 1\n",
      "542 1\n",
      "543 1\n",
      "544 1\n",
      "545 1\n",
      "548 1\n",
      "807 30\n",
      "808 30\n",
      "810 10\n",
      "811 30\n",
      "812 9\n",
      "813 30\n",
      "814 30\n",
      "815 30\n",
      "816 15\n",
      "817 30\n",
      "818 30\n",
      "819 30\n",
      "820 30\n",
      "821 30\n",
      "822 30\n",
      "823 14\n",
      "824 30\n",
      "825 30\n",
      "826 30\n",
      "828 30\n",
      "829 16\n",
      "830 30\n",
      "831 30\n",
      "832 30\n",
      "833 12\n",
      "834 5\n",
      "835 30\n",
      "836 30\n",
      "837 7\n",
      "838 30\n",
      "839 30\n",
      "840 30\n",
      "841 30\n",
      "842 30\n",
      "843 17\n",
      "844 30\n",
      "845 18\n",
      "846 30\n",
      "847 30\n",
      "848 30\n",
      "849 30\n",
      "850 2\n",
      "851 1\n",
      "852 30\n",
      "853 16\n",
      "854 30\n",
      "855 17\n",
      "856 1\n"
     ]
    }
   ],
   "source": [
    "new_drivers_dict = deepcopy(drivers_dict)\n",
    "for key in new_drivers_dict:\n",
    "    while len(new_drivers_dict[key]) < 30 and len(new_drivers_dict[key]) > 20:\n",
    "        # new_drivers_dict[key].append(0)\n",
    "        numbers = deepcopy(new_drivers_dict[key])\n",
    "        indices = np.arange(len(numbers))\n",
    "\n",
    "        # Interpolate to a length of 30 using the unsorted indices\n",
    "        interp_indices = np.linspace(0, len(numbers)-1, 30)\n",
    "        interp_numbers = np.interp(interp_indices, indices, numbers)\n",
    "\n",
    "        # Round the interpolated values to integers\n",
    "        interp_numbers = np.round(interp_numbers).astype(int)\n",
    "        new_drivers_dict[key] = interp_numbers\n",
    "\n",
    "\n",
    "# make all of them at max 30\n",
    "for key in new_drivers_dict:\n",
    "    new_drivers_dict[key] = new_drivers_dict[key][:30]\n",
    "\n",
    "# print len of them all\n",
    "for key in new_drivers_dict:\n",
    "    print(key, len(new_drivers_dict[key]))\n",
    "# remove anything having less than 30\n",
    "key_to_remove = []\n",
    "for key in new_drivers_dict:\n",
    "    if len(new_drivers_dict[key]) < 30:\n",
    "        key_to_remove.append(key)\n",
    "for key in key_to_remove:\n",
    "    del new_drivers_dict[key]\n",
    "# assert that all have 30\n",
    "for key in new_drivers_dict:\n",
    "    assert len(new_drivers_dict[key]) == 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "163"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_drivers_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "# Prepare the data\n",
    "# data = {'driver1': [1, 2, 3, ..., 30], 'driver2': [2, 3, 4, ..., 1], ...}\n",
    "key_sorted = sorted(new_drivers_dict.keys())\n",
    "X= []\n",
    "y= []\n",
    "for key in key_sorted:\n",
    "    X.append(new_drivers_dict[key][:20])\n",
    "    y.append(new_drivers_dict[key][20:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split size = 0.8\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the neural network\n",
    "class RacePredictor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RacePredictor, self).__init__()\n",
    "        self.fc1 = nn.Linear(20, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000, Loss: 63.27143669128418\n",
      "Epoch 2/1000, Loss: 57.195085525512695\n",
      "Epoch 3/1000, Loss: 49.84535884857178\n",
      "Epoch 4/1000, Loss: 41.58677959442139\n",
      "Epoch 5/1000, Loss: 33.56947374343872\n",
      "Epoch 6/1000, Loss: 26.87132215499878\n",
      "Epoch 7/1000, Loss: 21.83549451828003\n",
      "Epoch 8/1000, Loss: 17.901132583618164\n",
      "Epoch 9/1000, Loss: 14.65515398979187\n",
      "Epoch 10/1000, Loss: 12.457354068756104\n",
      "Epoch 11/1000, Loss: 11.473952054977417\n",
      "Epoch 12/1000, Loss: 11.414942026138306\n",
      "Epoch 13/1000, Loss: 11.570432901382446\n",
      "Epoch 14/1000, Loss: 11.539649248123169\n",
      "Epoch 15/1000, Loss: 11.354348182678223\n",
      "Epoch 16/1000, Loss: 11.138871192932129\n",
      "Epoch 17/1000, Loss: 10.97709345817566\n",
      "Epoch 18/1000, Loss: 10.89183497428894\n",
      "Epoch 19/1000, Loss: 10.831739902496338\n",
      "Epoch 20/1000, Loss: 10.766650915145874\n",
      "Epoch 21/1000, Loss: 10.695762157440186\n",
      "Epoch 22/1000, Loss: 10.627009630203247\n",
      "Epoch 23/1000, Loss: 10.56178879737854\n",
      "Epoch 24/1000, Loss: 10.50708794593811\n",
      "Epoch 25/1000, Loss: 10.45549988746643\n",
      "Epoch 26/1000, Loss: 10.40388822555542\n",
      "Epoch 27/1000, Loss: 10.352400779724121\n",
      "Epoch 28/1000, Loss: 10.302501678466797\n",
      "Epoch 29/1000, Loss: 10.255078315734863\n",
      "Epoch 30/1000, Loss: 10.208642721176147\n",
      "Epoch 31/1000, Loss: 10.16466212272644\n",
      "Epoch 32/1000, Loss: 10.121505737304688\n",
      "Epoch 33/1000, Loss: 10.079352855682373\n",
      "Epoch 34/1000, Loss: 10.03957486152649\n",
      "Epoch 35/1000, Loss: 10.000035762786865\n",
      "Epoch 36/1000, Loss: 9.961846590042114\n",
      "Epoch 37/1000, Loss: 9.924957513809204\n",
      "Epoch 38/1000, Loss: 9.888853549957275\n",
      "Epoch 39/1000, Loss: 9.853753805160522\n",
      "Epoch 40/1000, Loss: 9.819051742553711\n",
      "Epoch 41/1000, Loss: 9.78507924079895\n",
      "Epoch 42/1000, Loss: 9.752119302749634\n",
      "Epoch 43/1000, Loss: 9.720221519470215\n",
      "Epoch 44/1000, Loss: 9.688150882720947\n",
      "Epoch 45/1000, Loss: 9.65645956993103\n",
      "Epoch 46/1000, Loss: 9.624178409576416\n",
      "Epoch 47/1000, Loss: 9.591877222061157\n",
      "Epoch 48/1000, Loss: 9.55853796005249\n",
      "Epoch 49/1000, Loss: 9.527303457260132\n",
      "Epoch 50/1000, Loss: 9.494149208068848\n",
      "Epoch 51/1000, Loss: 9.461865663528442\n",
      "Epoch 52/1000, Loss: 9.430636405944824\n",
      "Epoch 53/1000, Loss: 9.40106463432312\n",
      "Epoch 54/1000, Loss: 9.369768381118774\n",
      "Epoch 55/1000, Loss: 9.340456485748291\n",
      "Epoch 56/1000, Loss: 9.309588432312012\n",
      "Epoch 57/1000, Loss: 9.280023097991943\n",
      "Epoch 58/1000, Loss: 9.248565435409546\n",
      "Epoch 59/1000, Loss: 9.218353509902954\n",
      "Epoch 60/1000, Loss: 9.188477993011475\n",
      "Epoch 61/1000, Loss: 9.157467126846313\n",
      "Epoch 62/1000, Loss: 9.128805160522461\n",
      "Epoch 63/1000, Loss: 9.097795248031616\n",
      "Epoch 64/1000, Loss: 9.068856239318848\n",
      "Epoch 65/1000, Loss: 9.037615656852722\n",
      "Epoch 66/1000, Loss: 9.007444858551025\n",
      "Epoch 67/1000, Loss: 8.97840678691864\n",
      "Epoch 68/1000, Loss: 8.94890284538269\n",
      "Epoch 69/1000, Loss: 8.917047023773193\n",
      "Epoch 70/1000, Loss: 8.890885949134827\n",
      "Epoch 71/1000, Loss: 8.863643765449524\n",
      "Epoch 72/1000, Loss: 8.83176040649414\n",
      "Epoch 73/1000, Loss: 8.799734830856323\n",
      "Epoch 74/1000, Loss: 8.769933223724365\n",
      "Epoch 75/1000, Loss: 8.738838076591492\n",
      "Epoch 76/1000, Loss: 8.709269881248474\n",
      "Epoch 77/1000, Loss: 8.678303360939026\n",
      "Epoch 78/1000, Loss: 8.648245334625244\n",
      "Epoch 79/1000, Loss: 8.616909384727478\n",
      "Epoch 80/1000, Loss: 8.58584988117218\n",
      "Epoch 81/1000, Loss: 8.556143283843994\n",
      "Epoch 82/1000, Loss: 8.526468276977539\n",
      "Epoch 83/1000, Loss: 8.495572686195374\n",
      "Epoch 84/1000, Loss: 8.464142084121704\n",
      "Epoch 85/1000, Loss: 8.436551570892334\n",
      "Epoch 86/1000, Loss: 8.40264356136322\n",
      "Epoch 87/1000, Loss: 8.372255086898804\n",
      "Epoch 88/1000, Loss: 8.341488599777222\n",
      "Epoch 89/1000, Loss: 8.312543272972107\n",
      "Epoch 90/1000, Loss: 8.284862995147705\n",
      "Epoch 91/1000, Loss: 8.25670301914215\n",
      "Epoch 92/1000, Loss: 8.224704384803772\n",
      "Epoch 93/1000, Loss: 8.19952130317688\n",
      "Epoch 94/1000, Loss: 8.17020845413208\n",
      "Epoch 95/1000, Loss: 8.14044201374054\n",
      "Epoch 96/1000, Loss: 8.115573048591614\n",
      "Epoch 97/1000, Loss: 8.08912706375122\n",
      "Epoch 98/1000, Loss: 8.058152675628662\n",
      "Epoch 99/1000, Loss: 8.03527569770813\n",
      "Epoch 100/1000, Loss: 8.009343028068542\n",
      "Epoch 101/1000, Loss: 7.979333519935608\n",
      "Epoch 102/1000, Loss: 7.955635666847229\n",
      "Epoch 103/1000, Loss: 7.929487705230713\n",
      "Epoch 104/1000, Loss: 7.901103138923645\n",
      "Epoch 105/1000, Loss: 7.878811001777649\n",
      "Epoch 106/1000, Loss: 7.852905750274658\n",
      "Epoch 107/1000, Loss: 7.823956608772278\n",
      "Epoch 108/1000, Loss: 7.7998305559158325\n",
      "Epoch 109/1000, Loss: 7.777135252952576\n",
      "Epoch 110/1000, Loss: 7.750102758407593\n",
      "Epoch 111/1000, Loss: 7.725725173950195\n",
      "Epoch 112/1000, Loss: 7.702040791511536\n",
      "Epoch 113/1000, Loss: 7.676237940788269\n",
      "Epoch 114/1000, Loss: 7.6569578647613525\n",
      "Epoch 115/1000, Loss: 7.633567929267883\n",
      "Epoch 116/1000, Loss: 7.604190826416016\n",
      "Epoch 117/1000, Loss: 7.584006428718567\n",
      "Epoch 118/1000, Loss: 7.5596606731414795\n",
      "Epoch 119/1000, Loss: 7.534001588821411\n",
      "Epoch 120/1000, Loss: 7.512359142303467\n",
      "Epoch 121/1000, Loss: 7.487263083457947\n",
      "Epoch 122/1000, Loss: 7.4658989906311035\n",
      "Epoch 123/1000, Loss: 7.4437257051467896\n",
      "Epoch 124/1000, Loss: 7.42165994644165\n",
      "Epoch 125/1000, Loss: 7.3990641832351685\n",
      "Epoch 126/1000, Loss: 7.378895878791809\n",
      "Epoch 127/1000, Loss: 7.359214901924133\n",
      "Epoch 128/1000, Loss: 7.336234092712402\n",
      "Epoch 129/1000, Loss: 7.319797396659851\n",
      "Epoch 130/1000, Loss: 7.298445105552673\n",
      "Epoch 131/1000, Loss: 7.278841733932495\n",
      "Epoch 132/1000, Loss: 7.2589945793151855\n",
      "Epoch 133/1000, Loss: 7.231504321098328\n",
      "Epoch 134/1000, Loss: 7.212000489234924\n",
      "Epoch 135/1000, Loss: 7.189909815788269\n",
      "Epoch 136/1000, Loss: 7.167579412460327\n",
      "Epoch 137/1000, Loss: 7.146336674690247\n",
      "Epoch 138/1000, Loss: 7.1220937967300415\n",
      "Epoch 139/1000, Loss: 7.101104378700256\n",
      "Epoch 140/1000, Loss: 7.081385970115662\n",
      "Epoch 141/1000, Loss: 7.0602744817733765\n",
      "Epoch 142/1000, Loss: 7.038851499557495\n",
      "Epoch 143/1000, Loss: 7.018450617790222\n",
      "Epoch 144/1000, Loss: 6.998283743858337\n",
      "Epoch 145/1000, Loss: 6.976574897766113\n",
      "Epoch 146/1000, Loss: 6.958003401756287\n",
      "Epoch 147/1000, Loss: 6.938167452812195\n",
      "Epoch 148/1000, Loss: 6.9213268756866455\n",
      "Epoch 149/1000, Loss: 6.898757457733154\n",
      "Epoch 150/1000, Loss: 6.880774021148682\n",
      "Epoch 151/1000, Loss: 6.863014101982117\n",
      "Epoch 152/1000, Loss: 6.841330289840698\n",
      "Epoch 153/1000, Loss: 6.819292783737183\n",
      "Epoch 154/1000, Loss: 6.799002647399902\n",
      "Epoch 155/1000, Loss: 6.780726075172424\n",
      "Epoch 156/1000, Loss: 6.761672496795654\n",
      "Epoch 157/1000, Loss: 6.744186758995056\n",
      "Epoch 158/1000, Loss: 6.723475456237793\n",
      "Epoch 159/1000, Loss: 6.7016459703445435\n",
      "Epoch 160/1000, Loss: 6.69013774394989\n",
      "Epoch 161/1000, Loss: 6.665609359741211\n",
      "Epoch 162/1000, Loss: 6.647107005119324\n",
      "Epoch 163/1000, Loss: 6.629082202911377\n",
      "Epoch 164/1000, Loss: 6.610123157501221\n",
      "Epoch 165/1000, Loss: 6.594653129577637\n",
      "Epoch 166/1000, Loss: 6.573483347892761\n",
      "Epoch 167/1000, Loss: 6.549788117408752\n",
      "Epoch 168/1000, Loss: 6.5367467403411865\n",
      "Epoch 169/1000, Loss: 6.512236595153809\n",
      "Epoch 170/1000, Loss: 6.491374969482422\n",
      "Epoch 171/1000, Loss: 6.4737420082092285\n",
      "Epoch 172/1000, Loss: 6.450007438659668\n",
      "Epoch 173/1000, Loss: 6.43294894695282\n",
      "Epoch 174/1000, Loss: 6.412302732467651\n",
      "Epoch 175/1000, Loss: 6.388715982437134\n",
      "Epoch 176/1000, Loss: 6.369795083999634\n",
      "Epoch 177/1000, Loss: 6.348636150360107\n",
      "Epoch 178/1000, Loss: 6.330453395843506\n",
      "Epoch 179/1000, Loss: 6.30564022064209\n",
      "Epoch 180/1000, Loss: 6.28509783744812\n",
      "Epoch 181/1000, Loss: 6.26630699634552\n",
      "Epoch 182/1000, Loss: 6.24190354347229\n",
      "Epoch 183/1000, Loss: 6.224122047424316\n",
      "Epoch 184/1000, Loss: 6.2015639543533325\n",
      "Epoch 185/1000, Loss: 6.186031103134155\n",
      "Epoch 186/1000, Loss: 6.166328191757202\n",
      "Epoch 187/1000, Loss: 6.146459937095642\n",
      "Epoch 188/1000, Loss: 6.1240023374557495\n",
      "Epoch 189/1000, Loss: 6.109844326972961\n",
      "Epoch 190/1000, Loss: 6.076776146888733\n",
      "Epoch 191/1000, Loss: 6.062244176864624\n",
      "Epoch 192/1000, Loss: 6.032592177391052\n",
      "Epoch 193/1000, Loss: 6.012243747711182\n",
      "Epoch 194/1000, Loss: 5.989261746406555\n",
      "Epoch 195/1000, Loss: 5.969110608100891\n",
      "Epoch 196/1000, Loss: 5.945122122764587\n",
      "Epoch 197/1000, Loss: 5.923773527145386\n",
      "Epoch 198/1000, Loss: 5.895512938499451\n",
      "Epoch 199/1000, Loss: 5.881072521209717\n",
      "Epoch 200/1000, Loss: 5.857002377510071\n",
      "Epoch 201/1000, Loss: 5.845088362693787\n",
      "Epoch 202/1000, Loss: 5.81102442741394\n",
      "Epoch 203/1000, Loss: 5.796619534492493\n",
      "Epoch 204/1000, Loss: 5.7612926959991455\n",
      "Epoch 205/1000, Loss: 5.754361391067505\n",
      "Epoch 206/1000, Loss: 5.732643246650696\n",
      "Epoch 207/1000, Loss: 5.719310402870178\n",
      "Epoch 208/1000, Loss: 5.691020965576172\n",
      "Epoch 209/1000, Loss: 5.6797016859054565\n",
      "Epoch 210/1000, Loss: 5.658519744873047\n",
      "Epoch 211/1000, Loss: 5.648838996887207\n",
      "Epoch 212/1000, Loss: 5.615787625312805\n",
      "Epoch 213/1000, Loss: 5.607058763504028\n",
      "Epoch 214/1000, Loss: 5.574256658554077\n",
      "Epoch 215/1000, Loss: 5.567689299583435\n",
      "Epoch 216/1000, Loss: 5.546051859855652\n",
      "Epoch 217/1000, Loss: 5.534437298774719\n",
      "Epoch 218/1000, Loss: 5.506578326225281\n",
      "Epoch 219/1000, Loss: 5.499254941940308\n",
      "Epoch 220/1000, Loss: 5.472620010375977\n",
      "Epoch 221/1000, Loss: 5.460008025169373\n",
      "Epoch 222/1000, Loss: 5.434780120849609\n",
      "Epoch 223/1000, Loss: 5.427796006202698\n",
      "Epoch 224/1000, Loss: 5.397895812988281\n",
      "Epoch 225/1000, Loss: 5.388227343559265\n",
      "Epoch 226/1000, Loss: 5.366639971733093\n",
      "Epoch 227/1000, Loss: 5.359439134597778\n",
      "Epoch 228/1000, Loss: 5.333767652511597\n",
      "Epoch 229/1000, Loss: 5.322074890136719\n",
      "Epoch 230/1000, Loss: 5.300467491149902\n",
      "Epoch 231/1000, Loss: 5.295071005821228\n",
      "Epoch 232/1000, Loss: 5.2678526639938354\n",
      "Epoch 233/1000, Loss: 5.261059999465942\n",
      "Epoch 234/1000, Loss: 5.238522171974182\n",
      "Epoch 235/1000, Loss: 5.229997634887695\n",
      "Epoch 236/1000, Loss: 5.206885814666748\n",
      "Epoch 237/1000, Loss: 5.198877453804016\n",
      "Epoch 238/1000, Loss: 5.172812342643738\n",
      "Epoch 239/1000, Loss: 5.1720603704452515\n",
      "Epoch 240/1000, Loss: 5.1516172885894775\n",
      "Epoch 241/1000, Loss: 5.146690487861633\n",
      "Epoch 242/1000, Loss: 5.119498372077942\n",
      "Epoch 243/1000, Loss: 5.1044251918792725\n",
      "Epoch 244/1000, Loss: 5.090198755264282\n",
      "Epoch 245/1000, Loss: 5.083373546600342\n",
      "Epoch 246/1000, Loss: 5.06883978843689\n",
      "Epoch 247/1000, Loss: 5.062183260917664\n",
      "Epoch 248/1000, Loss: 5.037346243858337\n",
      "Epoch 249/1000, Loss: 5.02841854095459\n",
      "Epoch 250/1000, Loss: 5.001780986785889\n",
      "Epoch 251/1000, Loss: 4.999667644500732\n",
      "Epoch 252/1000, Loss: 4.973382472991943\n",
      "Epoch 253/1000, Loss: 4.966243147850037\n",
      "Epoch 254/1000, Loss: 4.948771715164185\n",
      "Epoch 255/1000, Loss: 4.940504312515259\n",
      "Epoch 256/1000, Loss: 4.921957492828369\n",
      "Epoch 257/1000, Loss: 4.913522481918335\n",
      "Epoch 258/1000, Loss: 4.89823305606842\n",
      "Epoch 259/1000, Loss: 4.884190917015076\n",
      "Epoch 260/1000, Loss: 4.8709495067596436\n",
      "Epoch 261/1000, Loss: 4.864072561264038\n",
      "Epoch 262/1000, Loss: 4.850021481513977\n",
      "Epoch 263/1000, Loss: 4.835328817367554\n",
      "Epoch 264/1000, Loss: 4.833423018455505\n",
      "Epoch 265/1000, Loss: 4.813071012496948\n",
      "Epoch 266/1000, Loss: 4.805943846702576\n",
      "Epoch 267/1000, Loss: 4.789154648780823\n",
      "Epoch 268/1000, Loss: 4.77865743637085\n",
      "Epoch 269/1000, Loss: 4.773985147476196\n",
      "Epoch 270/1000, Loss: 4.752525687217712\n",
      "Epoch 271/1000, Loss: 4.7478286027908325\n",
      "Epoch 272/1000, Loss: 4.728987455368042\n",
      "Epoch 273/1000, Loss: 4.722797155380249\n",
      "Epoch 274/1000, Loss: 4.700652122497559\n",
      "Epoch 275/1000, Loss: 4.696370840072632\n",
      "Epoch 276/1000, Loss: 4.676921248435974\n",
      "Epoch 277/1000, Loss: 4.666449666023254\n",
      "Epoch 278/1000, Loss: 4.656177520751953\n",
      "Epoch 279/1000, Loss: 4.641536593437195\n",
      "Epoch 280/1000, Loss: 4.64180326461792\n",
      "Epoch 281/1000, Loss: 4.615523815155029\n",
      "Epoch 282/1000, Loss: 4.605616092681885\n",
      "Epoch 283/1000, Loss: 4.593124747276306\n",
      "Epoch 284/1000, Loss: 4.580721616744995\n",
      "Epoch 285/1000, Loss: 4.570852875709534\n",
      "Epoch 286/1000, Loss: 4.561093688011169\n",
      "Epoch 287/1000, Loss: 4.549639344215393\n",
      "Epoch 288/1000, Loss: 4.539562821388245\n",
      "Epoch 289/1000, Loss: 4.526009202003479\n",
      "Epoch 290/1000, Loss: 4.514506936073303\n",
      "Epoch 291/1000, Loss: 4.503636360168457\n",
      "Epoch 292/1000, Loss: 4.494630217552185\n",
      "Epoch 293/1000, Loss: 4.482734203338623\n",
      "Epoch 294/1000, Loss: 4.47696578502655\n",
      "Epoch 295/1000, Loss: 4.458919644355774\n",
      "Epoch 296/1000, Loss: 4.450835227966309\n",
      "Epoch 297/1000, Loss: 4.4409297704696655\n",
      "Epoch 298/1000, Loss: 4.429720163345337\n",
      "Epoch 299/1000, Loss: 4.420754671096802\n",
      "Epoch 300/1000, Loss: 4.409090876579285\n",
      "Epoch 301/1000, Loss: 4.396550297737122\n",
      "Epoch 302/1000, Loss: 4.3928996324539185\n",
      "Epoch 303/1000, Loss: 4.381653189659119\n",
      "Epoch 304/1000, Loss: 4.374755918979645\n",
      "Epoch 305/1000, Loss: 4.360077798366547\n",
      "Epoch 306/1000, Loss: 4.349284827709198\n",
      "Epoch 307/1000, Loss: 4.339982032775879\n",
      "Epoch 308/1000, Loss: 4.334292948246002\n",
      "Epoch 309/1000, Loss: 4.32098650932312\n",
      "Epoch 310/1000, Loss: 4.311963438987732\n",
      "Epoch 311/1000, Loss: 4.313406348228455\n",
      "Epoch 312/1000, Loss: 4.295594096183777\n",
      "Epoch 313/1000, Loss: 4.286530375480652\n",
      "Epoch 314/1000, Loss: 4.270891845226288\n",
      "Epoch 315/1000, Loss: 4.264309763908386\n",
      "Epoch 316/1000, Loss: 4.251939535140991\n",
      "Epoch 317/1000, Loss: 4.243152379989624\n",
      "Epoch 318/1000, Loss: 4.23503977060318\n",
      "Epoch 319/1000, Loss: 4.224075078964233\n",
      "Epoch 320/1000, Loss: 4.2164212465286255\n",
      "Epoch 321/1000, Loss: 4.20716404914856\n",
      "Epoch 322/1000, Loss: 4.195806503295898\n",
      "Epoch 323/1000, Loss: 4.186070084571838\n",
      "Epoch 324/1000, Loss: 4.1747366189956665\n",
      "Epoch 325/1000, Loss: 4.16418194770813\n",
      "Epoch 326/1000, Loss: 4.159079194068909\n",
      "Epoch 327/1000, Loss: 4.14903998374939\n",
      "Epoch 328/1000, Loss: 4.143417656421661\n",
      "Epoch 329/1000, Loss: 4.137900471687317\n",
      "Epoch 330/1000, Loss: 4.123178601264954\n",
      "Epoch 331/1000, Loss: 4.115851402282715\n",
      "Epoch 332/1000, Loss: 4.101807951927185\n",
      "Epoch 333/1000, Loss: 4.090467214584351\n",
      "Epoch 334/1000, Loss: 4.084804058074951\n",
      "Epoch 335/1000, Loss: 4.068961441516876\n",
      "Epoch 336/1000, Loss: 4.0622153878211975\n",
      "Epoch 337/1000, Loss: 4.052929937839508\n",
      "Epoch 338/1000, Loss: 4.042685329914093\n",
      "Epoch 339/1000, Loss: 4.031992793083191\n",
      "Epoch 340/1000, Loss: 4.026926219463348\n",
      "Epoch 341/1000, Loss: 4.024071276187897\n",
      "Epoch 342/1000, Loss: 4.011349678039551\n",
      "Epoch 343/1000, Loss: 4.002738296985626\n",
      "Epoch 344/1000, Loss: 3.9930790066719055\n",
      "Epoch 345/1000, Loss: 3.985549211502075\n",
      "Epoch 346/1000, Loss: 3.9804019927978516\n",
      "Epoch 347/1000, Loss: 3.9670474529266357\n",
      "Epoch 348/1000, Loss: 3.957186758518219\n",
      "Epoch 349/1000, Loss: 3.9515404105186462\n",
      "Epoch 350/1000, Loss: 3.945819139480591\n",
      "Epoch 351/1000, Loss: 3.9325509667396545\n",
      "Epoch 352/1000, Loss: 3.926500380039215\n",
      "Epoch 353/1000, Loss: 3.914473533630371\n",
      "Epoch 354/1000, Loss: 3.906227767467499\n",
      "Epoch 355/1000, Loss: 3.892559826374054\n",
      "Epoch 356/1000, Loss: 3.886437952518463\n",
      "Epoch 357/1000, Loss: 3.873891592025757\n",
      "Epoch 358/1000, Loss: 3.8632516860961914\n",
      "Epoch 359/1000, Loss: 3.8577167987823486\n",
      "Epoch 360/1000, Loss: 3.8455559611320496\n",
      "Epoch 361/1000, Loss: 3.8377453088760376\n",
      "Epoch 362/1000, Loss: 3.827323317527771\n",
      "Epoch 363/1000, Loss: 3.821566104888916\n",
      "Epoch 364/1000, Loss: 3.808485448360443\n",
      "Epoch 365/1000, Loss: 3.7994672060012817\n",
      "Epoch 366/1000, Loss: 3.793217897415161\n",
      "Epoch 367/1000, Loss: 3.790347993373871\n",
      "Epoch 368/1000, Loss: 3.7809056639671326\n",
      "Epoch 369/1000, Loss: 3.763920307159424\n",
      "Epoch 370/1000, Loss: 3.756890594959259\n",
      "Epoch 371/1000, Loss: 3.749450385570526\n",
      "Epoch 372/1000, Loss: 3.7457640171051025\n",
      "Epoch 373/1000, Loss: 3.7292520403862\n",
      "Epoch 374/1000, Loss: 3.7234463691711426\n",
      "Epoch 375/1000, Loss: 3.7148531675338745\n",
      "Epoch 376/1000, Loss: 3.7008171677589417\n",
      "Epoch 377/1000, Loss: 3.6945106983184814\n",
      "Epoch 378/1000, Loss: 3.6925854086875916\n",
      "Epoch 379/1000, Loss: 3.6828149557113647\n",
      "Epoch 380/1000, Loss: 3.6706626415252686\n",
      "Epoch 381/1000, Loss: 3.6615060567855835\n",
      "Epoch 382/1000, Loss: 3.6547495126724243\n",
      "Epoch 383/1000, Loss: 3.6407735347747803\n",
      "Epoch 384/1000, Loss: 3.634852707386017\n",
      "Epoch 385/1000, Loss: 3.628463923931122\n",
      "Epoch 386/1000, Loss: 3.6222766637802124\n",
      "Epoch 387/1000, Loss: 3.6174140572547913\n",
      "Epoch 388/1000, Loss: 3.6060373187065125\n",
      "Epoch 389/1000, Loss: 3.600167453289032\n",
      "Epoch 390/1000, Loss: 3.589819312095642\n",
      "Epoch 391/1000, Loss: 3.5803149342536926\n",
      "Epoch 392/1000, Loss: 3.5782649517059326\n",
      "Epoch 393/1000, Loss: 3.568666994571686\n",
      "Epoch 394/1000, Loss: 3.560361087322235\n",
      "Epoch 395/1000, Loss: 3.551227569580078\n",
      "Epoch 396/1000, Loss: 3.541347324848175\n",
      "Epoch 397/1000, Loss: 3.533828020095825\n",
      "Epoch 398/1000, Loss: 3.521709680557251\n",
      "Epoch 399/1000, Loss: 3.514922082424164\n",
      "Epoch 400/1000, Loss: 3.5062512159347534\n",
      "Epoch 401/1000, Loss: 3.5014805793762207\n",
      "Epoch 402/1000, Loss: 3.5011854767799377\n",
      "Epoch 403/1000, Loss: 3.490048050880432\n",
      "Epoch 404/1000, Loss: 3.4851869344711304\n",
      "Epoch 405/1000, Loss: 3.4778066277503967\n",
      "Epoch 406/1000, Loss: 3.4681456089019775\n",
      "Epoch 407/1000, Loss: 3.456229090690613\n",
      "Epoch 408/1000, Loss: 3.4457486867904663\n",
      "Epoch 409/1000, Loss: 3.4348815083503723\n",
      "Epoch 410/1000, Loss: 3.4336623549461365\n",
      "Epoch 411/1000, Loss: 3.4252514243125916\n",
      "Epoch 412/1000, Loss: 3.414724290370941\n",
      "Epoch 413/1000, Loss: 3.4149237871170044\n",
      "Epoch 414/1000, Loss: 3.404419481754303\n",
      "Epoch 415/1000, Loss: 3.39370995759964\n",
      "Epoch 416/1000, Loss: 3.385949492454529\n",
      "Epoch 417/1000, Loss: 3.376881420612335\n",
      "Epoch 418/1000, Loss: 3.3762499690055847\n",
      "Epoch 419/1000, Loss: 3.3697622418403625\n",
      "Epoch 420/1000, Loss: 3.3641902208328247\n",
      "Epoch 421/1000, Loss: 3.3534799814224243\n",
      "Epoch 422/1000, Loss: 3.3422634601593018\n",
      "Epoch 423/1000, Loss: 3.337027370929718\n",
      "Epoch 424/1000, Loss: 3.325735032558441\n",
      "Epoch 425/1000, Loss: 3.3208332657814026\n",
      "Epoch 426/1000, Loss: 3.3094703555107117\n",
      "Epoch 427/1000, Loss: 3.306107819080353\n",
      "Epoch 428/1000, Loss: 3.2998000979423523\n",
      "Epoch 429/1000, Loss: 3.293588936328888\n",
      "Epoch 430/1000, Loss: 3.2891340851783752\n",
      "Epoch 431/1000, Loss: 3.286669135093689\n",
      "Epoch 432/1000, Loss: 3.275408923625946\n",
      "Epoch 433/1000, Loss: 3.264790415763855\n",
      "Epoch 434/1000, Loss: 3.256750166416168\n",
      "Epoch 435/1000, Loss: 3.24715119600296\n",
      "Epoch 436/1000, Loss: 3.2473172545433044\n",
      "Epoch 437/1000, Loss: 3.236991763114929\n",
      "Epoch 438/1000, Loss: 3.2348195910453796\n",
      "Epoch 439/1000, Loss: 3.2282944917678833\n",
      "Epoch 440/1000, Loss: 3.221097409725189\n",
      "Epoch 441/1000, Loss: 3.2124234437942505\n",
      "Epoch 442/1000, Loss: 3.2019318342208862\n",
      "Epoch 443/1000, Loss: 3.1943281292915344\n",
      "Epoch 444/1000, Loss: 3.1882343888282776\n",
      "Epoch 445/1000, Loss: 3.1787710189819336\n",
      "Epoch 446/1000, Loss: 3.1745432019233704\n",
      "Epoch 447/1000, Loss: 3.1666454672813416\n",
      "Epoch 448/1000, Loss: 3.161673069000244\n",
      "Epoch 449/1000, Loss: 3.1575955152511597\n",
      "Epoch 450/1000, Loss: 3.147578239440918\n",
      "Epoch 451/1000, Loss: 3.1439494490623474\n",
      "Epoch 452/1000, Loss: 3.132652461528778\n",
      "Epoch 453/1000, Loss: 3.1303756833076477\n",
      "Epoch 454/1000, Loss: 3.1220468878746033\n",
      "Epoch 455/1000, Loss: 3.1156413555145264\n",
      "Epoch 456/1000, Loss: 3.111247956752777\n",
      "Epoch 457/1000, Loss: 3.103611409664154\n",
      "Epoch 458/1000, Loss: 3.097358226776123\n",
      "Epoch 459/1000, Loss: 3.093950092792511\n",
      "Epoch 460/1000, Loss: 3.0830734372138977\n",
      "Epoch 461/1000, Loss: 3.0725521445274353\n",
      "Epoch 462/1000, Loss: 3.0695073008537292\n",
      "Epoch 463/1000, Loss: 3.058924376964569\n",
      "Epoch 464/1000, Loss: 3.0534200072288513\n",
      "Epoch 465/1000, Loss: 3.0493149161338806\n",
      "Epoch 466/1000, Loss: 3.042253792285919\n",
      "Epoch 467/1000, Loss: 3.038791298866272\n",
      "Epoch 468/1000, Loss: 3.027421534061432\n",
      "Epoch 469/1000, Loss: 3.0174520015716553\n",
      "Epoch 470/1000, Loss: 3.0084569454193115\n",
      "Epoch 471/1000, Loss: 3.002912700176239\n",
      "Epoch 472/1000, Loss: 2.995635747909546\n",
      "Epoch 473/1000, Loss: 2.9893975257873535\n",
      "Epoch 474/1000, Loss: 2.9792569875717163\n",
      "Epoch 475/1000, Loss: 2.970873534679413\n",
      "Epoch 476/1000, Loss: 2.964897930622101\n",
      "Epoch 477/1000, Loss: 2.9578327536582947\n",
      "Epoch 478/1000, Loss: 2.950352132320404\n",
      "Epoch 479/1000, Loss: 2.9443320631980896\n",
      "Epoch 480/1000, Loss: 2.9403679370880127\n",
      "Epoch 481/1000, Loss: 2.930522382259369\n",
      "Epoch 482/1000, Loss: 2.92521870136261\n",
      "Epoch 483/1000, Loss: 2.9192763566970825\n",
      "Epoch 484/1000, Loss: 2.912578821182251\n",
      "Epoch 485/1000, Loss: 2.906939685344696\n",
      "Epoch 486/1000, Loss: 2.9002274870872498\n",
      "Epoch 487/1000, Loss: 2.896279275417328\n",
      "Epoch 488/1000, Loss: 2.888953447341919\n",
      "Epoch 489/1000, Loss: 2.886444866657257\n",
      "Epoch 490/1000, Loss: 2.87725031375885\n",
      "Epoch 491/1000, Loss: 2.869886338710785\n",
      "Epoch 492/1000, Loss: 2.8642722964286804\n",
      "Epoch 493/1000, Loss: 2.8620356917381287\n",
      "Epoch 494/1000, Loss: 2.8515089750289917\n",
      "Epoch 495/1000, Loss: 2.8498870730400085\n",
      "Epoch 496/1000, Loss: 2.8391740918159485\n",
      "Epoch 497/1000, Loss: 2.8294938802719116\n",
      "Epoch 498/1000, Loss: 2.8204091787338257\n",
      "Epoch 499/1000, Loss: 2.8129427433013916\n",
      "Epoch 500/1000, Loss: 2.8049153685569763\n",
      "Epoch 501/1000, Loss: 2.7985516786575317\n",
      "Epoch 502/1000, Loss: 2.7927846908569336\n",
      "Epoch 503/1000, Loss: 2.7806960344314575\n",
      "Epoch 504/1000, Loss: 2.7788528203964233\n",
      "Epoch 505/1000, Loss: 2.7714012265205383\n",
      "Epoch 506/1000, Loss: 2.762142598628998\n",
      "Epoch 507/1000, Loss: 2.7579283118247986\n",
      "Epoch 508/1000, Loss: 2.751906156539917\n",
      "Epoch 509/1000, Loss: 2.7436400651931763\n",
      "Epoch 510/1000, Loss: 2.7376335859298706\n",
      "Epoch 511/1000, Loss: 2.733294427394867\n",
      "Epoch 512/1000, Loss: 2.724093735218048\n",
      "Epoch 513/1000, Loss: 2.7177613377571106\n",
      "Epoch 514/1000, Loss: 2.712738871574402\n",
      "Epoch 515/1000, Loss: 2.7063443660736084\n",
      "Epoch 516/1000, Loss: 2.698841154575348\n",
      "Epoch 517/1000, Loss: 2.6953206658363342\n",
      "Epoch 518/1000, Loss: 2.686798393726349\n",
      "Epoch 519/1000, Loss: 2.678689479827881\n",
      "Epoch 520/1000, Loss: 2.6758695244789124\n",
      "Epoch 521/1000, Loss: 2.667689800262451\n",
      "Epoch 522/1000, Loss: 2.664371609687805\n",
      "Epoch 523/1000, Loss: 2.6589991450309753\n",
      "Epoch 524/1000, Loss: 2.6492884755134583\n",
      "Epoch 525/1000, Loss: 2.644926965236664\n",
      "Epoch 526/1000, Loss: 2.636912524700165\n",
      "Epoch 527/1000, Loss: 2.631623387336731\n",
      "Epoch 528/1000, Loss: 2.6208154559135437\n",
      "Epoch 529/1000, Loss: 2.6195547580718994\n",
      "Epoch 530/1000, Loss: 2.6075533628463745\n",
      "Epoch 531/1000, Loss: 2.601866602897644\n",
      "Epoch 532/1000, Loss: 2.595722198486328\n",
      "Epoch 533/1000, Loss: 2.5904197096824646\n",
      "Epoch 534/1000, Loss: 2.581771492958069\n",
      "Epoch 535/1000, Loss: 2.5786014795303345\n",
      "Epoch 536/1000, Loss: 2.569884240627289\n",
      "Epoch 537/1000, Loss: 2.567889630794525\n",
      "Epoch 538/1000, Loss: 2.5645123720169067\n",
      "Epoch 539/1000, Loss: 2.5618814826011658\n",
      "Epoch 540/1000, Loss: 2.561886191368103\n",
      "Epoch 541/1000, Loss: 2.5559927821159363\n",
      "Epoch 542/1000, Loss: 2.552599847316742\n",
      "Epoch 543/1000, Loss: 2.551850914955139\n",
      "Epoch 544/1000, Loss: 2.5512614250183105\n",
      "Epoch 545/1000, Loss: 2.5424172282218933\n",
      "Epoch 546/1000, Loss: 2.55129075050354\n",
      "Epoch 547/1000, Loss: 2.53313010931015\n",
      "Epoch 548/1000, Loss: 2.5304237008094788\n",
      "Epoch 549/1000, Loss: 2.5256513357162476\n",
      "Epoch 550/1000, Loss: 2.5157665014266968\n",
      "Epoch 551/1000, Loss: 2.5108972787857056\n",
      "Epoch 552/1000, Loss: 2.5092044472694397\n",
      "Epoch 553/1000, Loss: 2.4899010062217712\n",
      "Epoch 554/1000, Loss: 2.4795066714286804\n",
      "Epoch 555/1000, Loss: 2.4705787897109985\n",
      "Epoch 556/1000, Loss: 2.4734559655189514\n",
      "Epoch 557/1000, Loss: 2.4596058130264282\n",
      "Epoch 558/1000, Loss: 2.4569324254989624\n",
      "Epoch 559/1000, Loss: 2.4447595477104187\n",
      "Epoch 560/1000, Loss: 2.4358274936676025\n",
      "Epoch 561/1000, Loss: 2.430649220943451\n",
      "Epoch 562/1000, Loss: 2.430126667022705\n",
      "Epoch 563/1000, Loss: 2.423521876335144\n",
      "Epoch 564/1000, Loss: 2.4226580262184143\n",
      "Epoch 565/1000, Loss: 2.409215569496155\n",
      "Epoch 566/1000, Loss: 2.400456726551056\n",
      "Epoch 567/1000, Loss: 2.3856390714645386\n",
      "Epoch 568/1000, Loss: 2.392033576965332\n",
      "Epoch 569/1000, Loss: 2.3766302466392517\n",
      "Epoch 570/1000, Loss: 2.3804519176483154\n",
      "Epoch 571/1000, Loss: 2.36461341381073\n",
      "Epoch 572/1000, Loss: 2.3566922545433044\n",
      "Epoch 573/1000, Loss: 2.3451708555221558\n",
      "Epoch 574/1000, Loss: 2.3448609709739685\n",
      "Epoch 575/1000, Loss: 2.334032356739044\n",
      "Epoch 576/1000, Loss: 2.3310195207595825\n",
      "Epoch 577/1000, Loss: 2.3203412294387817\n",
      "Epoch 578/1000, Loss: 2.319702446460724\n",
      "Epoch 579/1000, Loss: 2.309770107269287\n",
      "Epoch 580/1000, Loss: 2.3072893023490906\n",
      "Epoch 581/1000, Loss: 2.298978269100189\n",
      "Epoch 582/1000, Loss: 2.2982089519500732\n",
      "Epoch 583/1000, Loss: 2.2901715636253357\n",
      "Epoch 584/1000, Loss: 2.285572826862335\n",
      "Epoch 585/1000, Loss: 2.2759422063827515\n",
      "Epoch 586/1000, Loss: 2.2759593725204468\n",
      "Epoch 587/1000, Loss: 2.266820549964905\n",
      "Epoch 588/1000, Loss: 2.26542329788208\n",
      "Epoch 589/1000, Loss: 2.2586835622787476\n",
      "Epoch 590/1000, Loss: 2.255407989025116\n",
      "Epoch 591/1000, Loss: 2.2479048371315002\n",
      "Epoch 592/1000, Loss: 2.245275139808655\n",
      "Epoch 593/1000, Loss: 2.2360792756080627\n",
      "Epoch 594/1000, Loss: 2.236350357532501\n",
      "Epoch 595/1000, Loss: 2.231559991836548\n",
      "Epoch 596/1000, Loss: 2.224651336669922\n",
      "Epoch 597/1000, Loss: 2.2250614762306213\n",
      "Epoch 598/1000, Loss: 2.2169917821884155\n",
      "Epoch 599/1000, Loss: 2.210196852684021\n",
      "Epoch 600/1000, Loss: 2.208488643169403\n",
      "Epoch 601/1000, Loss: 2.2088170647621155\n",
      "Epoch 602/1000, Loss: 2.2027998864650726\n",
      "Epoch 603/1000, Loss: 2.1984612345695496\n",
      "Epoch 604/1000, Loss: 2.19034743309021\n",
      "Epoch 605/1000, Loss: 2.1880962550640106\n",
      "Epoch 606/1000, Loss: 2.1775642335414886\n",
      "Epoch 607/1000, Loss: 2.1744750142097473\n",
      "Epoch 608/1000, Loss: 2.165594220161438\n",
      "Epoch 609/1000, Loss: 2.16058611869812\n",
      "Epoch 610/1000, Loss: 2.153690457344055\n",
      "Epoch 611/1000, Loss: 2.1565650701522827\n",
      "Epoch 612/1000, Loss: 2.143754303455353\n",
      "Epoch 613/1000, Loss: 2.140500456094742\n",
      "Epoch 614/1000, Loss: 2.13039493560791\n",
      "Epoch 615/1000, Loss: 2.12886980175972\n",
      "Epoch 616/1000, Loss: 2.1201133728027344\n",
      "Epoch 617/1000, Loss: 2.1205846071243286\n",
      "Epoch 618/1000, Loss: 2.107021987438202\n",
      "Epoch 619/1000, Loss: 2.1052905321121216\n",
      "Epoch 620/1000, Loss: 2.1041296422481537\n",
      "Epoch 621/1000, Loss: 2.0988683998584747\n",
      "Epoch 622/1000, Loss: 2.0902523696422577\n",
      "Epoch 623/1000, Loss: 2.095325618982315\n",
      "Epoch 624/1000, Loss: 2.0866681039333344\n",
      "Epoch 625/1000, Loss: 2.086692214012146\n",
      "Epoch 626/1000, Loss: 2.0808744728565216\n",
      "Epoch 627/1000, Loss: 2.077492892742157\n",
      "Epoch 628/1000, Loss: 2.0681821405887604\n",
      "Epoch 629/1000, Loss: 2.0719264149665833\n",
      "Epoch 630/1000, Loss: 2.060732126235962\n",
      "Epoch 631/1000, Loss: 2.0552126467227936\n",
      "Epoch 632/1000, Loss: 2.0548395216464996\n",
      "Epoch 633/1000, Loss: 2.047947734594345\n",
      "Epoch 634/1000, Loss: 2.0385654866695404\n",
      "Epoch 635/1000, Loss: 2.0454019904136658\n",
      "Epoch 636/1000, Loss: 2.0297171771526337\n",
      "Epoch 637/1000, Loss: 2.0300973653793335\n",
      "Epoch 638/1000, Loss: 2.0311756432056427\n",
      "Epoch 639/1000, Loss: 2.016038239002228\n",
      "Epoch 640/1000, Loss: 2.013960689306259\n",
      "Epoch 641/1000, Loss: 2.0097817182540894\n",
      "Epoch 642/1000, Loss: 2.000517636537552\n",
      "Epoch 643/1000, Loss: 2.001808673143387\n",
      "Epoch 644/1000, Loss: 1.9985968470573425\n",
      "Epoch 645/1000, Loss: 1.993333250284195\n",
      "Epoch 646/1000, Loss: 1.9870205521583557\n",
      "Epoch 647/1000, Loss: 1.989634394645691\n",
      "Epoch 648/1000, Loss: 1.9857555031776428\n",
      "Epoch 649/1000, Loss: 1.9863967299461365\n",
      "Epoch 650/1000, Loss: 1.9789337813854218\n",
      "Epoch 651/1000, Loss: 1.9772404432296753\n",
      "Epoch 652/1000, Loss: 1.979210764169693\n",
      "Epoch 653/1000, Loss: 1.9648009538650513\n",
      "Epoch 654/1000, Loss: 1.9699444472789764\n",
      "Epoch 655/1000, Loss: 1.9672927558422089\n",
      "Epoch 656/1000, Loss: 1.966826319694519\n",
      "Epoch 657/1000, Loss: 1.9550053477287292\n",
      "Epoch 658/1000, Loss: 1.9560046195983887\n",
      "Epoch 659/1000, Loss: 1.9473144114017487\n",
      "Epoch 660/1000, Loss: 1.942739725112915\n",
      "Epoch 661/1000, Loss: 1.9396501779556274\n",
      "Epoch 662/1000, Loss: 1.940582036972046\n",
      "Epoch 663/1000, Loss: 1.9267437160015106\n",
      "Epoch 664/1000, Loss: 1.9350135326385498\n",
      "Epoch 665/1000, Loss: 1.9322285652160645\n",
      "Epoch 666/1000, Loss: 1.924052506685257\n",
      "Epoch 667/1000, Loss: 1.9332509934902191\n",
      "Epoch 668/1000, Loss: 1.9258587956428528\n",
      "Epoch 669/1000, Loss: 1.9112140536308289\n",
      "Epoch 670/1000, Loss: 1.9238485097885132\n",
      "Epoch 671/1000, Loss: 1.9112362265586853\n",
      "Epoch 672/1000, Loss: 1.898342341184616\n",
      "Epoch 673/1000, Loss: 1.9082967042922974\n",
      "Epoch 674/1000, Loss: 1.8974605202674866\n",
      "Epoch 675/1000, Loss: 1.8819203078746796\n",
      "Epoch 676/1000, Loss: 1.883383333683014\n",
      "Epoch 677/1000, Loss: 1.8790236115455627\n",
      "Epoch 678/1000, Loss: 1.865502804517746\n",
      "Epoch 679/1000, Loss: 1.8669904172420502\n",
      "Epoch 680/1000, Loss: 1.86422461271286\n",
      "Epoch 681/1000, Loss: 1.8581379055976868\n",
      "Epoch 682/1000, Loss: 1.8529737293720245\n",
      "Epoch 683/1000, Loss: 1.8518708944320679\n",
      "Epoch 684/1000, Loss: 1.8449291288852692\n",
      "Epoch 685/1000, Loss: 1.8426805138587952\n",
      "Epoch 686/1000, Loss: 1.8368960320949554\n",
      "Epoch 687/1000, Loss: 1.8322389423847198\n",
      "Epoch 688/1000, Loss: 1.8259858191013336\n",
      "Epoch 689/1000, Loss: 1.8265594840049744\n",
      "Epoch 690/1000, Loss: 1.8162928819656372\n",
      "Epoch 691/1000, Loss: 1.8171602487564087\n",
      "Epoch 692/1000, Loss: 1.8077343106269836\n",
      "Epoch 693/1000, Loss: 1.8088766634464264\n",
      "Epoch 694/1000, Loss: 1.8027203977108002\n",
      "Epoch 695/1000, Loss: 1.8009359538555145\n",
      "Epoch 696/1000, Loss: 1.7945855557918549\n",
      "Epoch 697/1000, Loss: 1.7957746982574463\n",
      "Epoch 698/1000, Loss: 1.7870822548866272\n",
      "Epoch 699/1000, Loss: 1.7874888479709625\n",
      "Epoch 700/1000, Loss: 1.7817018032073975\n",
      "Epoch 701/1000, Loss: 1.7812893986701965\n",
      "Epoch 702/1000, Loss: 1.7701782882213593\n",
      "Epoch 703/1000, Loss: 1.773609846830368\n",
      "Epoch 704/1000, Loss: 1.7674039900302887\n",
      "Epoch 705/1000, Loss: 1.762225329875946\n",
      "Epoch 706/1000, Loss: 1.75736865401268\n",
      "Epoch 707/1000, Loss: 1.7585244476795197\n",
      "Epoch 708/1000, Loss: 1.7525672018527985\n",
      "Epoch 709/1000, Loss: 1.7482933700084686\n",
      "Epoch 710/1000, Loss: 1.7486771941184998\n",
      "Epoch 711/1000, Loss: 1.7447515428066254\n",
      "Epoch 712/1000, Loss: 1.7438428699970245\n",
      "Epoch 713/1000, Loss: 1.7393253147602081\n",
      "Epoch 714/1000, Loss: 1.7397668361663818\n",
      "Epoch 715/1000, Loss: 1.7294406592845917\n",
      "Epoch 716/1000, Loss: 1.7298571169376373\n",
      "Epoch 717/1000, Loss: 1.725254386663437\n",
      "Epoch 718/1000, Loss: 1.7212602496147156\n",
      "Epoch 719/1000, Loss: 1.7212065160274506\n",
      "Epoch 720/1000, Loss: 1.7140683829784393\n",
      "Epoch 721/1000, Loss: 1.7149493992328644\n",
      "Epoch 722/1000, Loss: 1.7131399512290955\n",
      "Epoch 723/1000, Loss: 1.7097916901111603\n",
      "Epoch 724/1000, Loss: 1.7079127430915833\n",
      "Epoch 725/1000, Loss: 1.7035711109638214\n",
      "Epoch 726/1000, Loss: 1.6960802972316742\n",
      "Epoch 727/1000, Loss: 1.6946049332618713\n",
      "Epoch 728/1000, Loss: 1.6889037489891052\n",
      "Epoch 729/1000, Loss: 1.6891814172267914\n",
      "Epoch 730/1000, Loss: 1.6845971941947937\n",
      "Epoch 731/1000, Loss: 1.6864579021930695\n",
      "Epoch 732/1000, Loss: 1.680909901857376\n",
      "Epoch 733/1000, Loss: 1.6815243363380432\n",
      "Epoch 734/1000, Loss: 1.6796930432319641\n",
      "Epoch 735/1000, Loss: 1.671551138162613\n",
      "Epoch 736/1000, Loss: 1.6751250922679901\n",
      "Epoch 737/1000, Loss: 1.674255907535553\n",
      "Epoch 738/1000, Loss: 1.6625731587409973\n",
      "Epoch 739/1000, Loss: 1.663284182548523\n",
      "Epoch 740/1000, Loss: 1.6576486229896545\n",
      "Epoch 741/1000, Loss: 1.6521016359329224\n",
      "Epoch 742/1000, Loss: 1.652769535779953\n",
      "Epoch 743/1000, Loss: 1.647693693637848\n",
      "Epoch 744/1000, Loss: 1.6434734761714935\n",
      "Epoch 745/1000, Loss: 1.641453593969345\n",
      "Epoch 746/1000, Loss: 1.6366955041885376\n",
      "Epoch 747/1000, Loss: 1.6326259076595306\n",
      "Epoch 748/1000, Loss: 1.6317332684993744\n",
      "Epoch 749/1000, Loss: 1.6315758228302002\n",
      "Epoch 750/1000, Loss: 1.6241568326950073\n",
      "Epoch 751/1000, Loss: 1.626978725194931\n",
      "Epoch 752/1000, Loss: 1.6214230954647064\n",
      "Epoch 753/1000, Loss: 1.6167354881763458\n",
      "Epoch 754/1000, Loss: 1.615195780992508\n",
      "Epoch 755/1000, Loss: 1.6205769777297974\n",
      "Epoch 756/1000, Loss: 1.6121043264865875\n",
      "Epoch 757/1000, Loss: 1.6122874021530151\n",
      "Epoch 758/1000, Loss: 1.6111040711402893\n",
      "Epoch 759/1000, Loss: 1.6097275614738464\n",
      "Epoch 760/1000, Loss: 1.6133626699447632\n",
      "Epoch 761/1000, Loss: 1.614818423986435\n",
      "Epoch 762/1000, Loss: 1.6131767332553864\n",
      "Epoch 763/1000, Loss: 1.6105204820632935\n",
      "Epoch 764/1000, Loss: 1.6158186793327332\n",
      "Epoch 765/1000, Loss: 1.612991064786911\n",
      "Epoch 766/1000, Loss: 1.617526650428772\n",
      "Epoch 767/1000, Loss: 1.6177341043949127\n",
      "Epoch 768/1000, Loss: 1.6021848320960999\n",
      "Epoch 769/1000, Loss: 1.6091292202472687\n",
      "Epoch 770/1000, Loss: 1.611180305480957\n",
      "Epoch 771/1000, Loss: 1.584704875946045\n",
      "Epoch 772/1000, Loss: 1.5934421122074127\n",
      "Epoch 773/1000, Loss: 1.5891065895557404\n",
      "Epoch 774/1000, Loss: 1.5698398053646088\n",
      "Epoch 775/1000, Loss: 1.577081024646759\n",
      "Epoch 776/1000, Loss: 1.587301343679428\n",
      "Epoch 777/1000, Loss: 1.5612529814243317\n",
      "Epoch 778/1000, Loss: 1.5594747364521027\n",
      "Epoch 779/1000, Loss: 1.5612070858478546\n",
      "Epoch 780/1000, Loss: 1.5466071963310242\n",
      "Epoch 781/1000, Loss: 1.5430071949958801\n",
      "Epoch 782/1000, Loss: 1.549837201833725\n",
      "Epoch 783/1000, Loss: 1.5401257574558258\n",
      "Epoch 784/1000, Loss: 1.5325770676136017\n",
      "Epoch 785/1000, Loss: 1.5342105329036713\n",
      "Epoch 786/1000, Loss: 1.5265451073646545\n",
      "Epoch 787/1000, Loss: 1.5207676589488983\n",
      "Epoch 788/1000, Loss: 1.5219303369522095\n",
      "Epoch 789/1000, Loss: 1.5180159509181976\n",
      "Epoch 790/1000, Loss: 1.512109398841858\n",
      "Epoch 791/1000, Loss: 1.5125076472759247\n",
      "Epoch 792/1000, Loss: 1.5052323639392853\n",
      "Epoch 793/1000, Loss: 1.5058358013629913\n",
      "Epoch 794/1000, Loss: 1.503924697637558\n",
      "Epoch 795/1000, Loss: 1.5063887536525726\n",
      "Epoch 796/1000, Loss: 1.4995291233062744\n",
      "Epoch 797/1000, Loss: 1.4987964630126953\n",
      "Epoch 798/1000, Loss: 1.489788442850113\n",
      "Epoch 799/1000, Loss: 1.49317467212677\n",
      "Epoch 800/1000, Loss: 1.4893684089183807\n",
      "Epoch 801/1000, Loss: 1.4873573780059814\n",
      "Epoch 802/1000, Loss: 1.4886540174484253\n",
      "Epoch 803/1000, Loss: 1.4852317869663239\n",
      "Epoch 804/1000, Loss: 1.479781597852707\n",
      "Epoch 805/1000, Loss: 1.4833477437496185\n",
      "Epoch 806/1000, Loss: 1.4784540235996246\n",
      "Epoch 807/1000, Loss: 1.4822923839092255\n",
      "Epoch 808/1000, Loss: 1.4796951413154602\n",
      "Epoch 809/1000, Loss: 1.4732223749160767\n",
      "Epoch 810/1000, Loss: 1.4677608609199524\n",
      "Epoch 811/1000, Loss: 1.470319539308548\n",
      "Epoch 812/1000, Loss: 1.4613515138626099\n",
      "Epoch 813/1000, Loss: 1.4611321687698364\n",
      "Epoch 814/1000, Loss: 1.464991420507431\n",
      "Epoch 815/1000, Loss: 1.453140377998352\n",
      "Epoch 816/1000, Loss: 1.448506385087967\n",
      "Epoch 817/1000, Loss: 1.4499596953392029\n",
      "Epoch 818/1000, Loss: 1.4469420313835144\n",
      "Epoch 819/1000, Loss: 1.4432478249073029\n",
      "Epoch 820/1000, Loss: 1.4450938403606415\n",
      "Epoch 821/1000, Loss: 1.4363398253917694\n",
      "Epoch 822/1000, Loss: 1.4374653100967407\n",
      "Epoch 823/1000, Loss: 1.4346867203712463\n",
      "Epoch 824/1000, Loss: 1.4347821176052094\n",
      "Epoch 825/1000, Loss: 1.430177390575409\n",
      "Epoch 826/1000, Loss: 1.4364780187606812\n",
      "Epoch 827/1000, Loss: 1.4240092933177948\n",
      "Epoch 828/1000, Loss: 1.423872321844101\n",
      "Epoch 829/1000, Loss: 1.4257342517375946\n",
      "Epoch 830/1000, Loss: 1.4179550409317017\n",
      "Epoch 831/1000, Loss: 1.4165385067462921\n",
      "Epoch 832/1000, Loss: 1.4209844172000885\n",
      "Epoch 833/1000, Loss: 1.4087187945842743\n",
      "Epoch 834/1000, Loss: 1.409261703491211\n",
      "Epoch 835/1000, Loss: 1.4088134169578552\n",
      "Epoch 836/1000, Loss: 1.398023545742035\n",
      "Epoch 837/1000, Loss: 1.3953321874141693\n",
      "Epoch 838/1000, Loss: 1.404923290014267\n",
      "Epoch 839/1000, Loss: 1.3874180614948273\n",
      "Epoch 840/1000, Loss: 1.3877596259117126\n",
      "Epoch 841/1000, Loss: 1.3869706988334656\n",
      "Epoch 842/1000, Loss: 1.3791453838348389\n",
      "Epoch 843/1000, Loss: 1.3746139407157898\n",
      "Epoch 844/1000, Loss: 1.379909187555313\n",
      "Epoch 845/1000, Loss: 1.3672689199447632\n",
      "Epoch 846/1000, Loss: 1.3698484599590302\n",
      "Epoch 847/1000, Loss: 1.365692377090454\n",
      "Epoch 848/1000, Loss: 1.3603020310401917\n",
      "Epoch 849/1000, Loss: 1.3570065200328827\n",
      "Epoch 850/1000, Loss: 1.3573349118232727\n",
      "Epoch 851/1000, Loss: 1.3526053130626678\n",
      "Epoch 852/1000, Loss: 1.3505352437496185\n",
      "Epoch 853/1000, Loss: 1.350005954504013\n",
      "Epoch 854/1000, Loss: 1.3482747972011566\n",
      "Epoch 855/1000, Loss: 1.3447019457817078\n",
      "Epoch 856/1000, Loss: 1.3478062748908997\n",
      "Epoch 857/1000, Loss: 1.3399257063865662\n",
      "Epoch 858/1000, Loss: 1.3361015319824219\n",
      "Epoch 859/1000, Loss: 1.3403530418872833\n",
      "Epoch 860/1000, Loss: 1.3316624462604523\n",
      "Epoch 861/1000, Loss: 1.3312429785728455\n",
      "Epoch 862/1000, Loss: 1.3298121392726898\n",
      "Epoch 863/1000, Loss: 1.3274850249290466\n",
      "Epoch 864/1000, Loss: 1.3210568130016327\n",
      "Epoch 865/1000, Loss: 1.328007072210312\n",
      "Epoch 866/1000, Loss: 1.319350928068161\n",
      "Epoch 867/1000, Loss: 1.3196637332439423\n",
      "Epoch 868/1000, Loss: 1.3183742463588715\n",
      "Epoch 869/1000, Loss: 1.3170841038227081\n",
      "Epoch 870/1000, Loss: 1.3107024133205414\n",
      "Epoch 871/1000, Loss: 1.3110001683235168\n",
      "Epoch 872/1000, Loss: 1.3064347803592682\n",
      "Epoch 873/1000, Loss: 1.3045614063739777\n",
      "Epoch 874/1000, Loss: 1.297629565000534\n",
      "Epoch 875/1000, Loss: 1.3020086884498596\n",
      "Epoch 876/1000, Loss: 1.2945057451725006\n",
      "Epoch 877/1000, Loss: 1.2901335060596466\n",
      "Epoch 878/1000, Loss: 1.295703500509262\n",
      "Epoch 879/1000, Loss: 1.2841944098472595\n",
      "Epoch 880/1000, Loss: 1.2826162576675415\n",
      "Epoch 881/1000, Loss: 1.2853302657604218\n",
      "Epoch 882/1000, Loss: 1.2755324840545654\n",
      "Epoch 883/1000, Loss: 1.273880124092102\n",
      "Epoch 884/1000, Loss: 1.2738076150417328\n",
      "Epoch 885/1000, Loss: 1.2690130174160004\n",
      "Epoch 886/1000, Loss: 1.2666524648666382\n",
      "Epoch 887/1000, Loss: 1.266959697008133\n",
      "Epoch 888/1000, Loss: 1.263742208480835\n",
      "Epoch 889/1000, Loss: 1.259517639875412\n",
      "Epoch 890/1000, Loss: 1.25663623213768\n",
      "Epoch 891/1000, Loss: 1.2583381235599518\n",
      "Epoch 892/1000, Loss: 1.251255989074707\n",
      "Epoch 893/1000, Loss: 1.2526476979255676\n",
      "Epoch 894/1000, Loss: 1.2553390860557556\n",
      "Epoch 895/1000, Loss: 1.2508779764175415\n",
      "Epoch 896/1000, Loss: 1.245186448097229\n",
      "Epoch 897/1000, Loss: 1.2524158358573914\n",
      "Epoch 898/1000, Loss: 1.2386762499809265\n",
      "Epoch 899/1000, Loss: 1.2363550961017609\n",
      "Epoch 900/1000, Loss: 1.2438757121562958\n",
      "Epoch 901/1000, Loss: 1.233996033668518\n",
      "Epoch 902/1000, Loss: 1.2275202870368958\n",
      "Epoch 903/1000, Loss: 1.2413192689418793\n",
      "Epoch 904/1000, Loss: 1.2267549932003021\n",
      "Epoch 905/1000, Loss: 1.231330394744873\n",
      "Epoch 906/1000, Loss: 1.2326407134532928\n",
      "Epoch 907/1000, Loss: 1.224187046289444\n",
      "Epoch 908/1000, Loss: 1.223434954881668\n",
      "Epoch 909/1000, Loss: 1.2204656898975372\n",
      "Epoch 910/1000, Loss: 1.2170368134975433\n",
      "Epoch 911/1000, Loss: 1.2124540507793427\n",
      "Epoch 912/1000, Loss: 1.2064317762851715\n",
      "Epoch 913/1000, Loss: 1.2107234299182892\n",
      "Epoch 914/1000, Loss: 1.2018487453460693\n",
      "Epoch 915/1000, Loss: 1.2007604241371155\n",
      "Epoch 916/1000, Loss: 1.1995864808559418\n",
      "Epoch 917/1000, Loss: 1.1920894086360931\n",
      "Epoch 918/1000, Loss: 1.1869098842144012\n",
      "Epoch 919/1000, Loss: 1.187012642621994\n",
      "Epoch 920/1000, Loss: 1.1818024814128876\n",
      "Epoch 921/1000, Loss: 1.1773749887943268\n",
      "Epoch 922/1000, Loss: 1.1797727048397064\n",
      "Epoch 923/1000, Loss: 1.1748985350131989\n",
      "Epoch 924/1000, Loss: 1.1714936196804047\n",
      "Epoch 925/1000, Loss: 1.170309692621231\n",
      "Epoch 926/1000, Loss: 1.1678735315799713\n",
      "Epoch 927/1000, Loss: 1.1637586951255798\n",
      "Epoch 928/1000, Loss: 1.164663314819336\n",
      "Epoch 929/1000, Loss: 1.1620188653469086\n",
      "Epoch 930/1000, Loss: 1.1579675078392029\n",
      "Epoch 931/1000, Loss: 1.1585440337657928\n",
      "Epoch 932/1000, Loss: 1.1565222442150116\n",
      "Epoch 933/1000, Loss: 1.1501908600330353\n",
      "Epoch 934/1000, Loss: 1.1515019536018372\n",
      "Epoch 935/1000, Loss: 1.1526189148426056\n",
      "Epoch 936/1000, Loss: 1.1473571956157684\n",
      "Epoch 937/1000, Loss: 1.1432612538337708\n",
      "Epoch 938/1000, Loss: 1.142570048570633\n",
      "Epoch 939/1000, Loss: 1.136770874261856\n",
      "Epoch 940/1000, Loss: 1.1352930963039398\n",
      "Epoch 941/1000, Loss: 1.1346631050109863\n",
      "Epoch 942/1000, Loss: 1.1310597658157349\n",
      "Epoch 943/1000, Loss: 1.1285252273082733\n",
      "Epoch 944/1000, Loss: 1.1295563876628876\n",
      "Epoch 945/1000, Loss: 1.1263482868671417\n",
      "Epoch 946/1000, Loss: 1.1198433190584183\n",
      "Epoch 947/1000, Loss: 1.1223863363265991\n",
      "Epoch 948/1000, Loss: 1.117348551750183\n",
      "Epoch 949/1000, Loss: 1.1169739812612534\n",
      "Epoch 950/1000, Loss: 1.1126204282045364\n",
      "Epoch 951/1000, Loss: 1.1163046211004257\n",
      "Epoch 952/1000, Loss: 1.1090074479579926\n",
      "Epoch 953/1000, Loss: 1.1108838766813278\n",
      "Epoch 954/1000, Loss: 1.1118863075971603\n",
      "Epoch 955/1000, Loss: 1.1078770458698273\n",
      "Epoch 956/1000, Loss: 1.0994702279567719\n",
      "Epoch 957/1000, Loss: 1.102215737104416\n",
      "Epoch 958/1000, Loss: 1.1013177037239075\n",
      "Epoch 959/1000, Loss: 1.0981088280677795\n",
      "Epoch 960/1000, Loss: 1.094066634774208\n",
      "Epoch 961/1000, Loss: 1.095828801393509\n",
      "Epoch 962/1000, Loss: 1.088496670126915\n",
      "Epoch 963/1000, Loss: 1.0888184905052185\n",
      "Epoch 964/1000, Loss: 1.0840915441513062\n",
      "Epoch 965/1000, Loss: 1.0834407210350037\n",
      "Epoch 966/1000, Loss: 1.0818518698215485\n",
      "Epoch 967/1000, Loss: 1.0757484287023544\n",
      "Epoch 968/1000, Loss: 1.0792912542819977\n",
      "Epoch 969/1000, Loss: 1.0815547853708267\n",
      "Epoch 970/1000, Loss: 1.0771800428628922\n",
      "Epoch 971/1000, Loss: 1.074251264333725\n",
      "Epoch 972/1000, Loss: 1.0804454684257507\n",
      "Epoch 973/1000, Loss: 1.0697237998247147\n",
      "Epoch 974/1000, Loss: 1.0661651194095612\n",
      "Epoch 975/1000, Loss: 1.0751865655183792\n",
      "Epoch 976/1000, Loss: 1.0646903216838837\n",
      "Epoch 977/1000, Loss: 1.060930073261261\n",
      "Epoch 978/1000, Loss: 1.0661430060863495\n",
      "Epoch 979/1000, Loss: 1.0614977180957794\n",
      "Epoch 980/1000, Loss: 1.060021162033081\n",
      "Epoch 981/1000, Loss: 1.059141293168068\n",
      "Epoch 982/1000, Loss: 1.063116580247879\n",
      "Epoch 983/1000, Loss: 1.0549966990947723\n",
      "Epoch 984/1000, Loss: 1.0531160682439804\n",
      "Epoch 985/1000, Loss: 1.0570890754461288\n",
      "Epoch 986/1000, Loss: 1.044767588376999\n",
      "Epoch 987/1000, Loss: 1.0474079102277756\n",
      "Epoch 988/1000, Loss: 1.0468128621578217\n",
      "Epoch 989/1000, Loss: 1.0459472239017487\n",
      "Epoch 990/1000, Loss: 1.0386977344751358\n",
      "Epoch 991/1000, Loss: 1.0434911251068115\n",
      "Epoch 992/1000, Loss: 1.0392621606588364\n",
      "Epoch 993/1000, Loss: 1.0354913473129272\n",
      "Epoch 994/1000, Loss: 1.028801053762436\n",
      "Epoch 995/1000, Loss: 1.0388727188110352\n",
      "Epoch 996/1000, Loss: 1.0260052233934402\n",
      "Epoch 997/1000, Loss: 1.0244349986314774\n",
      "Epoch 998/1000, Loss: 1.0315766483545303\n",
      "Epoch 999/1000, Loss: 1.0243605077266693\n",
      "Epoch 1000/1000, Loss: 1.0255930125713348\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Instantiate the neural network and optimizer\n",
    "model = RacePredictor()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 1000\n",
    "batch_size = 32\n",
    "num_batches = len(X_train) // batch_size\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0.0\n",
    "    for i in range(num_batches):\n",
    "        X_batch = torch.tensor(X_train[i*batch_size:(i+1)*batch_size], dtype=torch.float32)\n",
    "        y_batch = torch.tensor(y_train[i*batch_size:(i+1)*batch_size], dtype=torch.float32)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X_batch)\n",
    "        loss = criterion(output, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "    if num_epochs >0 and num_batches > 0    :\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss / num_batches}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43706/2768834670.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test = torch.tensor(X_test, dtype=torch.float32)\n",
      "/tmp/ipykernel_43706/2768834670.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test = torch.tensor(y_test, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 26.75223159790039\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with torch.no_grad():\n",
    "    output = model(X_test)\n",
    "    mse = criterion(output, y_test)\n",
    "print(f'Test MSE: {mse.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Make predictions\n",
    "with torch.no_grad():\n",
    "    predictions = model(X_test)\n",
    "    predictions = predictions.numpy()\n",
    "predictions = np.round(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8.  6. 11. 13.  9.  9.  8.  7.  9. -1.]\n",
      " [16. 12. 13. 17. 18. 18. 15. 16. 14. 18.]\n",
      " [ 9. 10. 12.  8.  5.  9. 11. 10. 10.  8.]\n",
      " [13. 17. 19. 16. 14. 11.  7.  6. 14. 14.]\n",
      " [12. 13. 12. 16. 15. 15. 16. 19. 12. 15.]\n",
      " [11. 11. 14. 12. 11.  8. 10. 11.  8. 12.]\n",
      " [ 7. 13. 13. 10. 11. 11.  9. 13. 13. 12.]\n",
      " [ 5. 18.  7.  4.  9.  7.  5. 16. 11.  3.]\n",
      " [ 4. 14. 11. 12.  4.  4. 13. 16.  5.  6.]\n",
      " [13. 18.  6.  9. 10.  4.  9. 18. 12. 13.]\n",
      " [ 2. 12. 13.  8.  7. 10.  4.  4.  8.  9.]\n",
      " [ 4. 14. 11.  8.  8. 10. 12.  3.  9.  9.]\n",
      " [16. 14. 20. 20. 17. 12. 16. 17. 13. 19.]\n",
      " [-0. -4.  5.  6. 18. 11. 10.  8.  3.  4.]\n",
      " [18. 27. 27. 19. 12. 19. 18. 16. 20. 21.]\n",
      " [ 6. 14. 16. 14. 10. 16. 11. 12. 13. 11.]\n",
      " [12. 14. 18. 14. 12.  3. 14. 20. 12. 13.]]\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8.  6. 11. 13.  9.  9.  8.  7.  9. -1.]\n",
      "[ 8.  2.  2.  5.  3. 11.  7.  6.  2.  2.]\n",
      "0.8242705\n",
      "===================================================================================\n",
      "0.8242705\n",
      "[16. 12. 13. 17. 18. 18. 15. 16. 14. 18.]\n",
      "[15. 18. 12. 13. 15. 17. 17. 13. 19. 15.]\n",
      "0.9776236\n",
      "===================================================================================\n",
      "0.9776236\n",
      "[ 9. 10. 12.  8.  5.  9. 11. 10. 10.  8.]\n",
      "[ 8. 14. 15. 14. 11. 17.  6. 16.  6.  8.]\n",
      "0.92963535\n",
      "===================================================================================\n",
      "0.92963535\n",
      "[13. 17. 19. 16. 14. 11.  7.  6. 14. 14.]\n",
      "[13. 11. 11. 11. 12. 13.  9.  9. 14. 12.]\n",
      "0.9661704\n",
      "===================================================================================\n",
      "0.9661704\n",
      "[12. 13. 12. 16. 15. 15. 16. 19. 12. 15.]\n",
      "[14. 17. 15. 16. 12. 17. 15. 14. 14. 14.]\n",
      "0.98336345\n",
      "===================================================================================\n",
      "0.98336345\n",
      "[11. 11. 14. 12. 11.  8. 10. 11.  8. 12.]\n",
      "[16. 12. 15. 11. 13. 15. 12. 12. 16. 15.]\n",
      "0.97484195\n",
      "===================================================================================\n",
      "0.97484195\n",
      "[ 7. 13. 13. 10. 11. 11.  9. 13. 13. 12.]\n",
      "[10. 10.  6.  6.  5.  8. 12. 10. 11.  6.]\n",
      "0.94132185\n",
      "===================================================================================\n",
      "0.94132185\n",
      "[ 5. 18.  7.  4.  9.  7.  5. 16. 11.  3.]\n",
      "[11. 17. 17. 14. 12. 17. 13.  9. 14. 15.]\n",
      "0.8475177\n",
      "===================================================================================\n",
      "0.8475177\n",
      "[ 4. 14. 11. 12.  4.  4. 13. 16.  5.  6.]\n",
      "[16.  9. 14. 17. 14. 17. 16. 16. 11. 10.]\n",
      "0.87807316\n",
      "===================================================================================\n",
      "0.87807316\n",
      "[13. 18.  6.  9. 10.  4.  9. 18. 12. 13.]\n",
      "[13. 11.  8.  6.  6.  5.  8. 10.  7.  4.]\n",
      "0.94558704\n",
      "===================================================================================\n",
      "0.94558704\n",
      "[ 2. 12. 13.  8.  7. 10.  4.  4.  8.  9.]\n",
      "[3. 3. 2. 3. 4. 1. 1. 2. 3. 6.]\n",
      "0.8357952\n",
      "===================================================================================\n",
      "0.8357952\n",
      "[ 4. 14. 11.  8.  8. 10. 12.  3.  9.  9.]\n",
      "[ 5.  9. 10.  7.  4.  6. 15. 13.  8.  8.]\n",
      "0.9000488\n",
      "===================================================================================\n",
      "0.9000488\n",
      "[16. 14. 20. 20. 17. 12. 16. 17. 13. 19.]\n",
      "[18. 12. 18. 17. 14. 11. 18. 14. 16. 12.]\n",
      "0.98364663\n",
      "===================================================================================\n",
      "0.98364663\n",
      "[-0. -4.  5.  6. 18. 11. 10.  8.  3.  4.]\n",
      "[13.  4.  5.  8.  5.  8.  6. 15.  3. 10.]\n",
      "0.64273393\n",
      "===================================================================================\n",
      "0.64273393\n",
      "[18. 27. 27. 19. 12. 19. 18. 16. 20. 21.]\n",
      "[17. 16. 14.  7.  9. 16. 11. 19. 17. 15.]\n",
      "0.95878696\n",
      "===================================================================================\n",
      "0.95878696\n",
      "[ 6. 14. 16. 14. 10. 16. 11. 12. 13. 11.]\n",
      "[ 7. 12. 10. 17. 13. 14. 16. 19. 13. 14.]\n",
      "0.96290445\n",
      "===================================================================================\n",
      "0.96290445\n",
      "[12. 14. 18. 14. 12.  3. 14. 20. 12. 13.]\n",
      "[13. 17. 15. 14. 14.  8.  6. 15. 14. 17.]\n",
      "0.95880544\n",
      "===================================================================================\n",
      "0.95880544\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# print acc\n",
    "count = 0\n",
    "for i in range(len(predictions)):\n",
    "    np_pred = np.array(predictions[i]) \n",
    "    np_y_test = np.array(y_test[i]) \n",
    "\n",
    "    similarity = cosine_similarity([np_pred, np_y_test])\n",
    "    cosine_sim = similarity[0][1]\n",
    "    print(np_pred )\n",
    "    print(np_y_test )\n",
    "    print(cosine_sim)\n",
    "    print('===================================================================================')\n",
    "    print(cosine_sim)\n",
    "\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = deepcopy(list(zip(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def one_hot_encode(data, num_classes):\n",
    "    encoded_data = []\n",
    "    for sublist in data:\n",
    "        encoded_sublist = np.zeros((len(sublist), num_classes))\n",
    "        encoded_sublist[np.arange(len(sublist)), np.array(sublist)-1] = 1\n",
    "        encoded_data.append(encoded_sublist.tolist())\n",
    "    return encoded_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class LSTMRacePosition(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(LSTMRacePosition, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(1, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(1, x.size(0), self.hidden_size).to(x.device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out)\n",
    "        out = F.softmax(out, dim=2)\n",
    "        return out.transpose(1, 2)\n",
    "# Define the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class RaceData(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        # print(X)\n",
    "        self.X = torch.tensor(one_hot_encode(X,20), dtype=torch.float32)\n",
    "        self.y = torch.tensor(one_hot_encode(y,20), dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, shuffle=False)\n",
    "\n",
    "# # to numpy  \n",
    "# X_train = np.array(X_train)\n",
    "# X_test = np.array(X_test)\n",
    "# y_train = np.array(y_train)\n",
    "# y_test = np.array(y_test)\n",
    "print(len(y_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = RaceData(X_train, y_train)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 0.05002117156982422\n",
      "Epoch: 2, Loss: 0.0500025600194931\n",
      "Epoch: 3, Loss: 0.049992531538009644\n",
      "Epoch: 4, Loss: 0.04998767748475075\n",
      "Epoch: 5, Loss: 0.04998258128762245\n",
      "Epoch: 6, Loss: 0.04997546598315239\n",
      "Epoch: 7, Loss: 0.04996810853481293\n",
      "Epoch: 8, Loss: 0.04996103793382645\n",
      "Epoch: 9, Loss: 0.04995385557413101\n",
      "Epoch: 10, Loss: 0.04994618892669678\n",
      "Epoch: 11, Loss: 0.049937836825847626\n",
      "Epoch: 12, Loss: 0.04992857947945595\n",
      "Epoch: 13, Loss: 0.04991809278726578\n",
      "Epoch: 14, Loss: 0.04990602284669876\n",
      "Epoch: 15, Loss: 0.049891937524080276\n",
      "Epoch: 16, Loss: 0.049875203520059586\n",
      "Epoch: 17, Loss: 0.04985472187399864\n",
      "Epoch: 18, Loss: 0.04982858523726463\n",
      "Epoch: 19, Loss: 0.04979352653026581\n",
      "Epoch: 20, Loss: 0.04974406212568283\n",
      "Epoch: 21, Loss: 0.04967445135116577\n",
      "Epoch: 22, Loss: 0.04959264397621155\n",
      "Epoch: 23, Loss: 0.04950718209147453\n",
      "Epoch: 24, Loss: 0.049401044845581055\n",
      "Epoch: 25, Loss: 0.049266617745161057\n",
      "Epoch: 26, Loss: 0.04912607744336128\n",
      "Epoch: 27, Loss: 0.04902291297912598\n",
      "Epoch: 28, Loss: 0.04888211563229561\n",
      "Epoch: 29, Loss: 0.04878704622387886\n",
      "Epoch: 30, Loss: 0.048634689301252365\n",
      "Epoch: 31, Loss: 0.04891075938940048\n",
      "Epoch: 32, Loss: 0.04840248450636864\n",
      "Epoch: 33, Loss: 0.04846901819109917\n",
      "Epoch: 34, Loss: 0.04818813502788544\n",
      "Epoch: 35, Loss: 0.04812385141849518\n",
      "Epoch: 36, Loss: 0.04828665032982826\n",
      "Epoch: 37, Loss: 0.04788367077708244\n",
      "Epoch: 38, Loss: 0.04786158725619316\n",
      "Epoch: 39, Loss: 0.0484197773039341\n",
      "Epoch: 40, Loss: 0.047585345804691315\n",
      "Epoch: 41, Loss: 0.047394901514053345\n",
      "Epoch: 42, Loss: 0.04756544902920723\n",
      "Epoch: 43, Loss: 0.04733749106526375\n",
      "Epoch: 44, Loss: 0.04754611849784851\n",
      "Epoch: 45, Loss: 0.04688441753387451\n",
      "Epoch: 46, Loss: 0.04690016433596611\n",
      "Epoch: 47, Loss: 0.04656092822551727\n",
      "Epoch: 48, Loss: 0.04645165428519249\n",
      "Epoch: 49, Loss: 0.04638136178255081\n",
      "Epoch: 50, Loss: 0.04714728891849518\n",
      "Epoch: 51, Loss: 0.04617122933268547\n",
      "Epoch: 52, Loss: 0.046382512897253036\n",
      "Epoch: 53, Loss: 0.045991405844688416\n",
      "Epoch: 54, Loss: 0.04615269973874092\n",
      "Epoch: 55, Loss: 0.04576195776462555\n",
      "Epoch: 56, Loss: 0.04558185487985611\n",
      "Epoch: 57, Loss: 0.04558422788977623\n",
      "Epoch: 58, Loss: 0.04574350640177727\n",
      "Epoch: 59, Loss: 0.046986330300569534\n",
      "Epoch: 60, Loss: 0.04560403898358345\n",
      "Epoch: 61, Loss: 0.045056022703647614\n",
      "Epoch: 62, Loss: 0.045030202716588974\n",
      "Epoch: 63, Loss: 0.04475942254066467\n",
      "Epoch: 64, Loss: 0.04452846199274063\n",
      "Epoch: 65, Loss: 0.04442872852087021\n",
      "Epoch: 66, Loss: 0.04447285085916519\n",
      "Epoch: 67, Loss: 0.0441313199698925\n",
      "Epoch: 68, Loss: 0.04446358606219292\n",
      "Epoch: 69, Loss: 0.04429362341761589\n",
      "Epoch: 70, Loss: 0.04510314390063286\n",
      "Epoch: 71, Loss: 0.043529365211725235\n",
      "Epoch: 72, Loss: 0.04363295063376427\n",
      "Epoch: 73, Loss: 0.04331102967262268\n",
      "Epoch: 74, Loss: 0.04319280385971069\n",
      "Epoch: 75, Loss: 0.043049443513154984\n",
      "Epoch: 76, Loss: 0.042919181287288666\n",
      "Epoch: 77, Loss: 0.042922984808683395\n",
      "Epoch: 78, Loss: 0.04260536655783653\n",
      "Epoch: 79, Loss: 0.04283631965517998\n",
      "Epoch: 80, Loss: 0.042770352214574814\n",
      "Epoch: 81, Loss: 0.04466121271252632\n",
      "Epoch: 82, Loss: 0.04246533289551735\n",
      "Epoch: 83, Loss: 0.04277542978525162\n",
      "Epoch: 84, Loss: 0.04203440248966217\n",
      "Epoch: 85, Loss: 0.04185368865728378\n",
      "Epoch: 86, Loss: 0.041534505784511566\n",
      "Epoch: 87, Loss: 0.041639331728219986\n",
      "Epoch: 88, Loss: 0.04143385961651802\n",
      "Epoch: 89, Loss: 0.041805706918239594\n",
      "Epoch: 90, Loss: 0.04144914448261261\n",
      "Epoch: 91, Loss: 0.041942331939935684\n",
      "Epoch: 92, Loss: 0.04095469042658806\n",
      "Epoch: 93, Loss: 0.04134589061141014\n",
      "Epoch: 94, Loss: 0.04046273231506348\n",
      "Epoch: 95, Loss: 0.04089699685573578\n",
      "Epoch: 96, Loss: 0.04018435999751091\n",
      "Epoch: 97, Loss: 0.04038994014263153\n",
      "Epoch: 98, Loss: 0.039946068078279495\n",
      "Epoch: 99, Loss: 0.040168311446905136\n",
      "Epoch: 100, Loss: 0.039875295013189316\n",
      "Epoch: 101, Loss: 0.04023748263716698\n",
      "Epoch: 102, Loss: 0.039849214255809784\n",
      "Epoch: 103, Loss: 0.04032636061310768\n",
      "Epoch: 104, Loss: 0.039658453315496445\n",
      "Epoch: 105, Loss: 0.039970677345991135\n",
      "Epoch: 106, Loss: 0.03913982957601547\n",
      "Epoch: 107, Loss: 0.03894386440515518\n",
      "Epoch: 108, Loss: 0.038692813366651535\n",
      "Epoch: 109, Loss: 0.038683000952005386\n",
      "Epoch: 110, Loss: 0.03840260952711105\n",
      "Epoch: 111, Loss: 0.03835210204124451\n",
      "Epoch: 112, Loss: 0.03809777647256851\n",
      "Epoch: 113, Loss: 0.03807523474097252\n",
      "Epoch: 114, Loss: 0.037865955382585526\n",
      "Epoch: 115, Loss: 0.03790697455406189\n",
      "Epoch: 116, Loss: 0.037787534296512604\n",
      "Epoch: 117, Loss: 0.03796174377202988\n",
      "Epoch: 118, Loss: 0.0377371609210968\n",
      "Epoch: 119, Loss: 0.03769521042704582\n",
      "Epoch: 120, Loss: 0.03779737651348114\n",
      "Epoch: 121, Loss: 0.037587448954582214\n",
      "Epoch: 122, Loss: 0.03760743513703346\n",
      "Epoch: 123, Loss: 0.03742546960711479\n",
      "Epoch: 124, Loss: 0.0371234230697155\n",
      "Epoch: 125, Loss: 0.036782026290893555\n",
      "Epoch: 126, Loss: 0.03679025545716286\n",
      "Epoch: 127, Loss: 0.036595288664102554\n",
      "Epoch: 128, Loss: 0.03645216301083565\n",
      "Epoch: 129, Loss: 0.03640466928482056\n",
      "Epoch: 130, Loss: 0.03610619902610779\n",
      "Epoch: 131, Loss: 0.03597426787018776\n",
      "Epoch: 132, Loss: 0.03579666092991829\n",
      "Epoch: 133, Loss: 0.035794250667095184\n",
      "Epoch: 134, Loss: 0.03589029237627983\n",
      "Epoch: 135, Loss: 0.03563053905963898\n",
      "Epoch: 136, Loss: 0.03563762828707695\n",
      "Epoch: 137, Loss: 0.03572480380535126\n",
      "Epoch: 138, Loss: 0.03549141064286232\n",
      "Epoch: 139, Loss: 0.03542269393801689\n",
      "Epoch: 140, Loss: 0.03512870520353317\n",
      "Epoch: 141, Loss: 0.035247646272182465\n",
      "Epoch: 142, Loss: 0.03510129824280739\n",
      "Epoch: 143, Loss: 0.03466513752937317\n",
      "Epoch: 144, Loss: 0.0345810241997242\n",
      "Epoch: 145, Loss: 0.0343879833817482\n",
      "Epoch: 146, Loss: 0.03434279188513756\n",
      "Epoch: 147, Loss: 0.034144043922424316\n",
      "Epoch: 148, Loss: 0.03397548198699951\n",
      "Epoch: 149, Loss: 0.03386455774307251\n",
      "Epoch: 150, Loss: 0.03375595435500145\n",
      "Epoch: 151, Loss: 0.03365340828895569\n",
      "Epoch: 152, Loss: 0.03354819864034653\n",
      "Epoch: 153, Loss: 0.0335809588432312\n",
      "Epoch: 154, Loss: 0.0336710661649704\n",
      "Epoch: 155, Loss: 0.033601313829422\n",
      "Epoch: 156, Loss: 0.03392815962433815\n",
      "Epoch: 157, Loss: 0.03408486396074295\n",
      "Epoch: 158, Loss: 0.034292176365852356\n",
      "Epoch: 159, Loss: 0.034023016691207886\n",
      "Epoch: 160, Loss: 0.034849800169467926\n",
      "Epoch: 161, Loss: 0.036159057170152664\n",
      "Epoch: 162, Loss: 0.033404234796762466\n",
      "Epoch: 163, Loss: 0.03341672196984291\n",
      "Epoch: 164, Loss: 0.03313683718442917\n",
      "Epoch: 165, Loss: 0.032754555344581604\n",
      "Epoch: 166, Loss: 0.03253880515694618\n",
      "Epoch: 167, Loss: 0.03235213831067085\n",
      "Epoch: 168, Loss: 0.03225269168615341\n",
      "Epoch: 169, Loss: 0.03212263062596321\n",
      "Epoch: 170, Loss: 0.031998906284570694\n",
      "Epoch: 171, Loss: 0.031894050538539886\n",
      "Epoch: 172, Loss: 0.03181856870651245\n",
      "Epoch: 173, Loss: 0.031714096665382385\n",
      "Epoch: 174, Loss: 0.03163866326212883\n",
      "Epoch: 175, Loss: 0.03160494938492775\n",
      "Epoch: 176, Loss: 0.03151097148656845\n",
      "Epoch: 177, Loss: 0.03138649836182594\n",
      "Epoch: 178, Loss: 0.031355489045381546\n",
      "Epoch: 179, Loss: 0.03125951066613197\n",
      "Epoch: 180, Loss: 0.03118523769080639\n",
      "Epoch: 181, Loss: 0.0311902929097414\n",
      "Epoch: 182, Loss: 0.03127814829349518\n",
      "Epoch: 183, Loss: 0.031079309061169624\n",
      "Epoch: 184, Loss: 0.031141582876443863\n",
      "Epoch: 185, Loss: 0.03128340467810631\n",
      "Epoch: 186, Loss: 0.03134918585419655\n",
      "Epoch: 187, Loss: 0.031535565853118896\n",
      "Epoch: 188, Loss: 0.03184424340724945\n",
      "Epoch: 189, Loss: 0.03151186928153038\n",
      "Epoch: 190, Loss: 0.031006691977381706\n",
      "Epoch: 191, Loss: 0.03113151155412197\n",
      "Epoch: 192, Loss: 0.031468477100133896\n",
      "Epoch: 193, Loss: 0.03171061351895332\n",
      "Epoch: 194, Loss: 0.03207673132419586\n",
      "Epoch: 195, Loss: 0.03097011335194111\n",
      "Epoch: 196, Loss: 0.030981171876192093\n",
      "Epoch: 197, Loss: 0.030943168327212334\n",
      "Epoch: 198, Loss: 0.03045763447880745\n",
      "Epoch: 199, Loss: 0.030555788427591324\n",
      "Epoch: 200, Loss: 0.030284333974123\n",
      "Epoch: 201, Loss: 0.030003484338521957\n",
      "Epoch: 202, Loss: 0.02990279719233513\n",
      "Epoch: 203, Loss: 0.029801107943058014\n",
      "Epoch: 204, Loss: 0.029750747606158257\n",
      "Epoch: 205, Loss: 0.02967001125216484\n",
      "Epoch: 206, Loss: 0.029622569680213928\n",
      "Epoch: 207, Loss: 0.029606731608510017\n",
      "Epoch: 208, Loss: 0.029541457071900368\n",
      "Epoch: 209, Loss: 0.029580581933259964\n",
      "Epoch: 210, Loss: 0.029475849121809006\n",
      "Epoch: 211, Loss: 0.029389576986432076\n",
      "Epoch: 212, Loss: 0.0293487086892128\n",
      "Epoch: 213, Loss: 0.02927209995687008\n",
      "Epoch: 214, Loss: 0.029227999970316887\n",
      "Epoch: 215, Loss: 0.02921057678759098\n",
      "Epoch: 216, Loss: 0.02915482595562935\n",
      "Epoch: 217, Loss: 0.029282303526997566\n",
      "Epoch: 218, Loss: 0.02928796596825123\n",
      "Epoch: 219, Loss: 0.02912776730954647\n",
      "Epoch: 220, Loss: 0.02908185124397278\n",
      "Epoch: 221, Loss: 0.02937071956694126\n",
      "Epoch: 222, Loss: 0.029264384880661964\n",
      "Epoch: 223, Loss: 0.02967534027993679\n",
      "Epoch: 224, Loss: 0.030708424746990204\n",
      "Epoch: 225, Loss: 0.03207290545105934\n",
      "Epoch: 226, Loss: 0.030788641422986984\n",
      "Epoch: 227, Loss: 0.031059235334396362\n",
      "Epoch: 228, Loss: 0.031061431393027306\n",
      "Epoch: 229, Loss: 0.03063359297811985\n",
      "Epoch: 230, Loss: 0.029313500970602036\n",
      "Epoch: 231, Loss: 0.02924044243991375\n",
      "Epoch: 232, Loss: 0.029021287336945534\n",
      "Epoch: 233, Loss: 0.028779124841094017\n",
      "Epoch: 234, Loss: 0.028695616871118546\n",
      "Epoch: 235, Loss: 0.028592703863978386\n",
      "Epoch: 236, Loss: 0.028456242755055428\n",
      "Epoch: 237, Loss: 0.028360579162836075\n",
      "Epoch: 238, Loss: 0.02833726443350315\n",
      "Epoch: 239, Loss: 0.028264882043004036\n",
      "Epoch: 240, Loss: 0.028195412829518318\n",
      "Epoch: 241, Loss: 0.028135452419519424\n",
      "Epoch: 242, Loss: 0.028092332184314728\n",
      "Epoch: 243, Loss: 0.02804717794060707\n",
      "Epoch: 244, Loss: 0.028005236759781837\n",
      "Epoch: 245, Loss: 0.02797534503042698\n",
      "Epoch: 246, Loss: 0.02791745215654373\n",
      "Epoch: 247, Loss: 0.02788185328245163\n",
      "Epoch: 248, Loss: 0.027830462902784348\n",
      "Epoch: 249, Loss: 0.027789561077952385\n",
      "Epoch: 250, Loss: 0.027754632756114006\n",
      "Epoch: 251, Loss: 0.027710357680916786\n",
      "Epoch: 252, Loss: 0.02767210826277733\n",
      "Epoch: 253, Loss: 0.027635445818305016\n",
      "Epoch: 254, Loss: 0.02759694866836071\n",
      "Epoch: 255, Loss: 0.02756435237824917\n",
      "Epoch: 256, Loss: 0.027534542605280876\n",
      "Epoch: 257, Loss: 0.027515150606632233\n",
      "Epoch: 258, Loss: 0.027512721717357635\n",
      "Epoch: 259, Loss: 0.027503615245223045\n",
      "Epoch: 260, Loss: 0.027463635429739952\n",
      "Epoch: 261, Loss: 0.027473358437418938\n",
      "Epoch: 262, Loss: 0.027503276243805885\n",
      "Epoch: 263, Loss: 0.027560576796531677\n",
      "Epoch: 264, Loss: 0.02770337462425232\n",
      "Epoch: 265, Loss: 0.02762085571885109\n",
      "Epoch: 266, Loss: 0.02757994458079338\n",
      "Epoch: 267, Loss: 0.027684444561600685\n",
      "Epoch: 268, Loss: 0.02774069458246231\n",
      "Epoch: 269, Loss: 0.02779006026685238\n",
      "Epoch: 270, Loss: 0.0280899740755558\n",
      "Epoch: 271, Loss: 0.027733027935028076\n",
      "Epoch: 272, Loss: 0.027677617967128754\n",
      "Epoch: 273, Loss: 0.029294688254594803\n",
      "Epoch: 274, Loss: 0.029378661885857582\n",
      "Epoch: 275, Loss: 0.028647365048527718\n",
      "Epoch: 276, Loss: 0.027668481692671776\n",
      "Epoch: 277, Loss: 0.02743997797369957\n",
      "Epoch: 278, Loss: 0.027203017845749855\n",
      "Epoch: 279, Loss: 0.027247916907072067\n",
      "Epoch: 280, Loss: 0.02720959298312664\n",
      "Epoch: 281, Loss: 0.02711503766477108\n",
      "Epoch: 282, Loss: 0.026995936408638954\n",
      "Epoch: 283, Loss: 0.026759542524814606\n",
      "Epoch: 284, Loss: 0.02672538533806801\n",
      "Epoch: 285, Loss: 0.026642639189958572\n",
      "Epoch: 286, Loss: 0.026615850627422333\n",
      "Epoch: 287, Loss: 0.026577193289995193\n",
      "Epoch: 288, Loss: 0.026533806696534157\n",
      "Epoch: 289, Loss: 0.02649739198386669\n",
      "Epoch: 290, Loss: 0.026470109820365906\n",
      "Epoch: 291, Loss: 0.026438793167471886\n",
      "Epoch: 292, Loss: 0.026404863223433495\n",
      "Epoch: 293, Loss: 0.026380036026239395\n",
      "Epoch: 294, Loss: 0.026346934959292412\n",
      "Epoch: 295, Loss: 0.026319952681660652\n",
      "Epoch: 296, Loss: 0.02628921903669834\n",
      "Epoch: 297, Loss: 0.026262495666742325\n",
      "Epoch: 298, Loss: 0.026234474033117294\n",
      "Epoch: 299, Loss: 0.02620731294155121\n",
      "Epoch: 300, Loss: 0.0261822622269392\n",
      "Epoch: 301, Loss: 0.026155607774853706\n",
      "Epoch: 302, Loss: 0.026131825521588326\n",
      "Epoch: 303, Loss: 0.02610711380839348\n",
      "Epoch: 304, Loss: 0.02608557604253292\n",
      "Epoch: 305, Loss: 0.026064952835440636\n",
      "Epoch: 306, Loss: 0.026046965271234512\n",
      "Epoch: 307, Loss: 0.02603105455636978\n",
      "Epoch: 308, Loss: 0.026015328243374825\n",
      "Epoch: 309, Loss: 0.02600044757127762\n",
      "Epoch: 310, Loss: 0.02598310075700283\n",
      "Epoch: 311, Loss: 0.025964774191379547\n",
      "Epoch: 312, Loss: 0.025949375703930855\n",
      "Epoch: 313, Loss: 0.025929832831025124\n",
      "Epoch: 314, Loss: 0.02592257782816887\n",
      "Epoch: 315, Loss: 0.025907663628458977\n",
      "Epoch: 316, Loss: 0.025899453088641167\n",
      "Epoch: 317, Loss: 0.025891125202178955\n",
      "Epoch: 318, Loss: 0.025880495086312294\n",
      "Epoch: 319, Loss: 0.025895675644278526\n",
      "Epoch: 320, Loss: 0.025902163237333298\n",
      "Epoch: 321, Loss: 0.02595328353345394\n",
      "Epoch: 322, Loss: 0.02596474625170231\n",
      "Epoch: 323, Loss: 0.02593897096812725\n",
      "Epoch: 324, Loss: 0.0258348286151886\n",
      "Epoch: 325, Loss: 0.025764906778931618\n",
      "Epoch: 326, Loss: 0.025686804205179214\n",
      "Epoch: 327, Loss: 0.025679651647806168\n",
      "Epoch: 328, Loss: 0.025647131726145744\n",
      "Epoch: 329, Loss: 0.025636861100792885\n",
      "Epoch: 330, Loss: 0.025595877319574356\n",
      "Epoch: 331, Loss: 0.02556823566555977\n",
      "Epoch: 332, Loss: 0.025544576346874237\n",
      "Epoch: 333, Loss: 0.02551203966140747\n",
      "Epoch: 334, Loss: 0.025495896115899086\n",
      "Epoch: 335, Loss: 0.025491517037153244\n",
      "Epoch: 336, Loss: 0.025440990924835205\n",
      "Epoch: 337, Loss: 0.025414954870939255\n",
      "Epoch: 338, Loss: 0.02552880346775055\n",
      "Epoch: 339, Loss: 0.025518912822008133\n",
      "Epoch: 340, Loss: 0.02553456462919712\n",
      "Epoch: 341, Loss: 0.025808118283748627\n",
      "Epoch: 342, Loss: 0.02591061405837536\n",
      "Epoch: 343, Loss: 0.026037544012069702\n",
      "Epoch: 344, Loss: 0.026698743924498558\n",
      "Epoch: 345, Loss: 0.02653464488685131\n",
      "Epoch: 346, Loss: 0.026541121304035187\n",
      "Epoch: 347, Loss: 0.0285954512655735\n",
      "Epoch: 348, Loss: 0.029934057965874672\n",
      "Epoch: 349, Loss: 0.027009783312678337\n",
      "Epoch: 350, Loss: 0.02636449970304966\n",
      "Epoch: 351, Loss: 0.02566794864833355\n",
      "Epoch: 352, Loss: 0.02547430619597435\n",
      "Epoch: 353, Loss: 0.025462422519922256\n",
      "Epoch: 354, Loss: 0.02560647390782833\n",
      "Epoch: 355, Loss: 0.025187212973833084\n",
      "Epoch: 356, Loss: 0.025104118511080742\n",
      "Epoch: 357, Loss: 0.025043288245797157\n",
      "Epoch: 358, Loss: 0.024967968463897705\n",
      "Epoch: 359, Loss: 0.02492549642920494\n",
      "Epoch: 360, Loss: 0.024884771555662155\n",
      "Epoch: 361, Loss: 0.02485026977956295\n",
      "Epoch: 362, Loss: 0.024814508855342865\n",
      "Epoch: 363, Loss: 0.02478567697107792\n",
      "Epoch: 364, Loss: 0.02476288564503193\n",
      "Epoch: 365, Loss: 0.024741025641560555\n",
      "Epoch: 366, Loss: 0.024715173989534378\n",
      "Epoch: 367, Loss: 0.024692628532648087\n",
      "Epoch: 368, Loss: 0.024670638144016266\n",
      "Epoch: 369, Loss: 0.024649228900671005\n",
      "Epoch: 370, Loss: 0.02462850697338581\n",
      "Epoch: 371, Loss: 0.024606909602880478\n",
      "Epoch: 372, Loss: 0.024587180465459824\n",
      "Epoch: 373, Loss: 0.024565815925598145\n",
      "Epoch: 374, Loss: 0.024546848610043526\n",
      "Epoch: 375, Loss: 0.02452579140663147\n",
      "Epoch: 376, Loss: 0.024506399407982826\n",
      "Epoch: 377, Loss: 0.024486646056175232\n",
      "Epoch: 378, Loss: 0.024467185139656067\n",
      "Epoch: 379, Loss: 0.024448620155453682\n",
      "Epoch: 380, Loss: 0.02442898228764534\n",
      "Epoch: 381, Loss: 0.024410607293248177\n",
      "Epoch: 382, Loss: 0.02439146116375923\n",
      "Epoch: 383, Loss: 0.0243733748793602\n",
      "Epoch: 384, Loss: 0.024356907233595848\n",
      "Epoch: 385, Loss: 0.02434193715453148\n",
      "Epoch: 386, Loss: 0.024329708889126778\n",
      "Epoch: 387, Loss: 0.02432580292224884\n",
      "Epoch: 388, Loss: 0.024324167519807816\n",
      "Epoch: 389, Loss: 0.0243349839001894\n",
      "Epoch: 390, Loss: 0.024349136278033257\n",
      "Epoch: 391, Loss: 0.024342592805624008\n",
      "Epoch: 392, Loss: 0.024359937757253647\n",
      "Epoch: 393, Loss: 0.02434513159096241\n",
      "Epoch: 394, Loss: 0.024325603619217873\n",
      "Epoch: 395, Loss: 0.024316279217600822\n",
      "Epoch: 396, Loss: 0.024267440661787987\n",
      "Epoch: 397, Loss: 0.024356244131922722\n",
      "Epoch: 398, Loss: 0.02439521811902523\n",
      "Epoch: 399, Loss: 0.024271713569760323\n",
      "Epoch: 400, Loss: 0.024291932582855225\n",
      "Epoch: 401, Loss: 0.02438143827021122\n",
      "Epoch: 402, Loss: 0.02436450496315956\n",
      "Epoch: 403, Loss: 0.02427864260971546\n",
      "Epoch: 404, Loss: 0.024292318150401115\n",
      "Epoch: 405, Loss: 0.024282218888401985\n",
      "Epoch: 406, Loss: 0.02413877099752426\n",
      "Epoch: 407, Loss: 0.024052521213889122\n",
      "Epoch: 408, Loss: 0.024067673832178116\n",
      "Epoch: 409, Loss: 0.024079572409391403\n",
      "Epoch: 410, Loss: 0.02411469630897045\n",
      "Epoch: 411, Loss: 0.02411438338458538\n",
      "Epoch: 412, Loss: 0.02409275993704796\n",
      "Epoch: 413, Loss: 0.024103408679366112\n",
      "Epoch: 414, Loss: 0.02406264841556549\n",
      "Epoch: 415, Loss: 0.023959944024682045\n",
      "Epoch: 416, Loss: 0.02398804947733879\n",
      "Epoch: 417, Loss: 0.02405092492699623\n",
      "Epoch: 418, Loss: 0.02405686303973198\n",
      "Epoch: 419, Loss: 0.02398451417684555\n",
      "Epoch: 420, Loss: 0.023957734927535057\n",
      "Epoch: 421, Loss: 0.0239801574498415\n",
      "Epoch: 422, Loss: 0.02391529083251953\n",
      "Epoch: 423, Loss: 0.023833833634853363\n",
      "Epoch: 424, Loss: 0.023829838261008263\n",
      "Epoch: 425, Loss: 0.0238388329744339\n",
      "Epoch: 426, Loss: 0.02392631769180298\n",
      "Epoch: 427, Loss: 0.02388545125722885\n",
      "Epoch: 428, Loss: 0.023812495172023773\n",
      "Epoch: 429, Loss: 0.023833300918340683\n",
      "Epoch: 430, Loss: 0.023830024525523186\n",
      "Epoch: 431, Loss: 0.023767026141285896\n",
      "Epoch: 432, Loss: 0.023767322301864624\n",
      "Epoch: 433, Loss: 0.023822559043765068\n",
      "Epoch: 434, Loss: 0.023918326944112778\n",
      "Epoch: 435, Loss: 0.02383175678551197\n",
      "Epoch: 436, Loss: 0.023803073912858963\n",
      "Epoch: 437, Loss: 0.02386374957859516\n",
      "Epoch: 438, Loss: 0.023758770897984505\n",
      "Epoch: 439, Loss: 0.023625684902071953\n",
      "Epoch: 440, Loss: 0.02366136759519577\n",
      "Epoch: 441, Loss: 0.023691749200224876\n",
      "Epoch: 442, Loss: 0.02363903634250164\n",
      "Epoch: 443, Loss: 0.02354719303548336\n",
      "Epoch: 444, Loss: 0.023545607924461365\n",
      "Epoch: 445, Loss: 0.023584648966789246\n",
      "Epoch: 446, Loss: 0.023523792624473572\n",
      "Epoch: 447, Loss: 0.023474831134080887\n",
      "Epoch: 448, Loss: 0.023529427126049995\n",
      "Epoch: 449, Loss: 0.02351921983063221\n",
      "Epoch: 450, Loss: 0.02346995659172535\n",
      "Epoch: 451, Loss: 0.0234419796615839\n",
      "Epoch: 452, Loss: 0.02341596409678459\n",
      "Epoch: 453, Loss: 0.023424135521054268\n",
      "Epoch: 454, Loss: 0.02342330850660801\n",
      "Epoch: 455, Loss: 0.023441726341843605\n",
      "Epoch: 456, Loss: 0.023460403084754944\n",
      "Epoch: 457, Loss: 0.023367449641227722\n",
      "Epoch: 458, Loss: 0.023374490439891815\n",
      "Epoch: 459, Loss: 0.023348890244960785\n",
      "Epoch: 460, Loss: 0.023352988064289093\n",
      "Epoch: 461, Loss: 0.023393025621771812\n",
      "Epoch: 462, Loss: 0.023404672741889954\n",
      "Epoch: 463, Loss: 0.023473462089896202\n",
      "Epoch: 464, Loss: 0.02351641096174717\n",
      "Epoch: 465, Loss: 0.0234886035323143\n",
      "Epoch: 466, Loss: 0.02350059151649475\n",
      "Epoch: 467, Loss: 0.02340109646320343\n",
      "Epoch: 468, Loss: 0.023304391652345657\n",
      "Epoch: 469, Loss: 0.023299282416701317\n",
      "Epoch: 470, Loss: 0.02328180894255638\n",
      "Epoch: 471, Loss: 0.02328130602836609\n",
      "Epoch: 472, Loss: 0.023298919200897217\n",
      "Epoch: 473, Loss: 0.023229029029607773\n",
      "Epoch: 474, Loss: 0.02317420393228531\n",
      "Epoch: 475, Loss: 0.02314794808626175\n",
      "Epoch: 476, Loss: 0.023222411051392555\n",
      "Epoch: 477, Loss: 0.023356294259428978\n",
      "Epoch: 478, Loss: 0.02332833968102932\n",
      "Epoch: 479, Loss: 0.023330900818109512\n",
      "Epoch: 480, Loss: 0.023536819964647293\n",
      "Epoch: 481, Loss: 0.02368859201669693\n",
      "Epoch: 482, Loss: 0.023619776591658592\n",
      "Epoch: 483, Loss: 0.02350432425737381\n",
      "Epoch: 484, Loss: 0.023384705185890198\n",
      "Epoch: 485, Loss: 0.023257043212652206\n",
      "Epoch: 486, Loss: 0.02329312451183796\n",
      "Epoch: 487, Loss: 0.0232397448271513\n",
      "Epoch: 488, Loss: 0.023108478635549545\n",
      "Epoch: 489, Loss: 0.0230348352342844\n",
      "Epoch: 490, Loss: 0.023089256137609482\n",
      "Epoch: 491, Loss: 0.02314206026494503\n",
      "Epoch: 492, Loss: 0.0230768583714962\n",
      "Epoch: 493, Loss: 0.0231292936950922\n",
      "Epoch: 494, Loss: 0.023329459130764008\n",
      "Epoch: 495, Loss: 0.0233918447047472\n",
      "Epoch: 496, Loss: 0.023406894877552986\n",
      "Epoch: 497, Loss: 0.02340572141110897\n",
      "Epoch: 498, Loss: 0.023307260125875473\n",
      "Epoch: 499, Loss: 0.023305736482143402\n",
      "Epoch: 500, Loss: 0.023411907255649567\n",
      "Epoch: 501, Loss: 0.02351011522114277\n",
      "Epoch: 502, Loss: 0.02332635223865509\n",
      "Epoch: 503, Loss: 0.023622509092092514\n",
      "Epoch: 504, Loss: 0.023695388808846474\n",
      "Epoch: 505, Loss: 0.024642745032906532\n",
      "Epoch: 506, Loss: 0.02388680726289749\n",
      "Epoch: 507, Loss: 0.023361017927527428\n",
      "Epoch: 508, Loss: 0.023020632565021515\n",
      "Epoch: 509, Loss: 0.022917451336979866\n",
      "Epoch: 510, Loss: 0.022807015106081963\n",
      "Epoch: 511, Loss: 0.02275148779153824\n",
      "Epoch: 512, Loss: 0.02269609272480011\n",
      "Epoch: 513, Loss: 0.022672053426504135\n",
      "Epoch: 514, Loss: 0.02264445833861828\n",
      "Epoch: 515, Loss: 0.022628113627433777\n",
      "Epoch: 516, Loss: 0.02261176146566868\n",
      "Epoch: 517, Loss: 0.022601300850510597\n",
      "Epoch: 518, Loss: 0.022588685154914856\n",
      "Epoch: 519, Loss: 0.022580940276384354\n",
      "Epoch: 520, Loss: 0.022572966292500496\n",
      "Epoch: 521, Loss: 0.022566668689250946\n",
      "Epoch: 522, Loss: 0.022557979449629784\n",
      "Epoch: 523, Loss: 0.022560840472579002\n",
      "Epoch: 524, Loss: 0.022547615692019463\n",
      "Epoch: 525, Loss: 0.022539028897881508\n",
      "Epoch: 526, Loss: 0.022535905241966248\n",
      "Epoch: 527, Loss: 0.022527078166604042\n",
      "Epoch: 528, Loss: 0.022539477795362473\n",
      "Epoch: 529, Loss: 0.022573037073016167\n",
      "Epoch: 530, Loss: 0.02254483476281166\n",
      "Epoch: 531, Loss: 0.022541772574186325\n",
      "Epoch: 532, Loss: 0.022564969956874847\n",
      "Epoch: 533, Loss: 0.022532019764184952\n",
      "Epoch: 534, Loss: 0.022651880979537964\n",
      "Epoch: 535, Loss: 0.022703392431139946\n",
      "Epoch: 536, Loss: 0.022584466263651848\n",
      "Epoch: 537, Loss: 0.022653359919786453\n",
      "Epoch: 538, Loss: 0.022651104256510735\n",
      "Epoch: 539, Loss: 0.022574009373784065\n",
      "Epoch: 540, Loss: 0.022661475464701653\n",
      "Epoch: 541, Loss: 0.02271856740117073\n",
      "Epoch: 542, Loss: 0.022698385640978813\n",
      "Epoch: 543, Loss: 0.022649936378002167\n",
      "Epoch: 544, Loss: 0.02260437048971653\n",
      "Epoch: 545, Loss: 0.022570516914129257\n",
      "Epoch: 546, Loss: 0.02255117893218994\n",
      "Epoch: 547, Loss: 0.022538090124726295\n",
      "Epoch: 548, Loss: 0.02257765457034111\n",
      "Epoch: 549, Loss: 0.02253703773021698\n",
      "Epoch: 550, Loss: 0.02247050032019615\n",
      "Epoch: 551, Loss: 0.02248953841626644\n",
      "Epoch: 552, Loss: 0.022447619587183\n",
      "Epoch: 553, Loss: 0.022405747324228287\n",
      "Epoch: 554, Loss: 0.022408653050661087\n",
      "Epoch: 555, Loss: 0.02247074991464615\n",
      "Epoch: 556, Loss: 0.022469069808721542\n",
      "Epoch: 557, Loss: 0.02242075651884079\n",
      "Epoch: 558, Loss: 0.022424114868044853\n",
      "Epoch: 559, Loss: 0.022444546222686768\n",
      "Epoch: 560, Loss: 0.022413130849599838\n",
      "Epoch: 561, Loss: 0.02245592698454857\n",
      "Epoch: 562, Loss: 0.022426079958677292\n",
      "Epoch: 563, Loss: 0.02241760678589344\n",
      "Epoch: 564, Loss: 0.022377490997314453\n",
      "Epoch: 565, Loss: 0.02237820252776146\n",
      "Epoch: 566, Loss: 0.022389912977814674\n",
      "Epoch: 567, Loss: 0.02236521616578102\n",
      "Epoch: 568, Loss: 0.022327659651637077\n",
      "Epoch: 569, Loss: 0.022379141300916672\n",
      "Epoch: 570, Loss: 0.02234124019742012\n",
      "Epoch: 571, Loss: 0.022304514423012733\n",
      "Epoch: 572, Loss: 0.022410299628973007\n",
      "Epoch: 573, Loss: 0.022447846829891205\n",
      "Epoch: 574, Loss: 0.022407090291380882\n",
      "Epoch: 575, Loss: 0.022623274475336075\n",
      "Epoch: 576, Loss: 0.022708898410201073\n",
      "Epoch: 577, Loss: 0.0231435876339674\n",
      "Epoch: 578, Loss: 0.024204935878515244\n",
      "Epoch: 579, Loss: 0.024937186390161514\n",
      "Epoch: 580, Loss: 0.026067953556776047\n",
      "Epoch: 581, Loss: 0.024598488584160805\n",
      "Epoch: 582, Loss: 0.023916669189929962\n",
      "Epoch: 583, Loss: 0.02421177737414837\n",
      "Epoch: 584, Loss: 0.023361239582300186\n",
      "Epoch: 585, Loss: 0.02359945699572563\n",
      "Epoch: 586, Loss: 0.0234428308904171\n",
      "Epoch: 587, Loss: 0.023702308535575867\n",
      "Epoch: 588, Loss: 0.024064134806394577\n",
      "Epoch: 589, Loss: 0.023174460977315903\n",
      "Epoch: 590, Loss: 0.022626228630542755\n",
      "Epoch: 591, Loss: 0.02257070131599903\n",
      "Epoch: 592, Loss: 0.02238311991095543\n",
      "Epoch: 593, Loss: 0.022316040471196175\n",
      "Epoch: 594, Loss: 0.022251494228839874\n",
      "Epoch: 595, Loss: 0.022209400311112404\n",
      "Epoch: 596, Loss: 0.022173091769218445\n",
      "Epoch: 597, Loss: 0.022147053852677345\n",
      "Epoch: 598, Loss: 0.022131510078907013\n",
      "Epoch: 599, Loss: 0.022110959514975548\n",
      "Epoch: 600, Loss: 0.02209649607539177\n",
      "Epoch: 601, Loss: 0.022080983966588974\n",
      "Epoch: 602, Loss: 0.02207089401781559\n",
      "Epoch: 603, Loss: 0.022061899304389954\n",
      "Epoch: 604, Loss: 0.022051017731428146\n",
      "Epoch: 605, Loss: 0.022045137360692024\n",
      "Epoch: 606, Loss: 0.022033732384443283\n",
      "Epoch: 607, Loss: 0.022025572136044502\n",
      "Epoch: 608, Loss: 0.0220181904733181\n",
      "Epoch: 609, Loss: 0.02200915664434433\n",
      "Epoch: 610, Loss: 0.022007044404745102\n",
      "Epoch: 611, Loss: 0.021995866671204567\n",
      "Epoch: 612, Loss: 0.021987585350871086\n",
      "Epoch: 613, Loss: 0.021987484768033028\n",
      "Epoch: 614, Loss: 0.021982302889227867\n",
      "Epoch: 615, Loss: 0.021980727091431618\n",
      "Epoch: 616, Loss: 0.021969763562083244\n",
      "Epoch: 617, Loss: 0.021968185901641846\n",
      "Epoch: 618, Loss: 0.02199103683233261\n",
      "Epoch: 619, Loss: 0.021983373910188675\n",
      "Epoch: 620, Loss: 0.02196706272661686\n",
      "Epoch: 621, Loss: 0.021983325481414795\n",
      "Epoch: 622, Loss: 0.02201218530535698\n",
      "Epoch: 623, Loss: 0.022023189812898636\n",
      "Epoch: 624, Loss: 0.022002605721354485\n",
      "Epoch: 625, Loss: 0.02199036441743374\n",
      "Epoch: 626, Loss: 0.022067826241254807\n",
      "Epoch: 627, Loss: 0.022178901359438896\n",
      "Epoch: 628, Loss: 0.022131070494651794\n",
      "Epoch: 629, Loss: 0.02198314666748047\n",
      "Epoch: 630, Loss: 0.022046362981200218\n",
      "Epoch: 631, Loss: 0.022197861224412918\n",
      "Epoch: 632, Loss: 0.022242754697799683\n",
      "Epoch: 633, Loss: 0.022075887769460678\n",
      "Epoch: 634, Loss: 0.02201279252767563\n",
      "Epoch: 635, Loss: 0.022085227072238922\n",
      "Epoch: 636, Loss: 0.022142348811030388\n",
      "Epoch: 637, Loss: 0.0220300555229187\n",
      "Epoch: 638, Loss: 0.021912217140197754\n",
      "Epoch: 639, Loss: 0.02189032919704914\n",
      "Epoch: 640, Loss: 0.021932918578386307\n",
      "Epoch: 641, Loss: 0.021984605118632317\n",
      "Epoch: 642, Loss: 0.021931642666459084\n",
      "Epoch: 643, Loss: 0.021900659427046776\n",
      "Epoch: 644, Loss: 0.02190754935145378\n",
      "Epoch: 645, Loss: 0.02191350795328617\n",
      "Epoch: 646, Loss: 0.021925728768110275\n",
      "Epoch: 647, Loss: 0.021856950595974922\n",
      "Epoch: 648, Loss: 0.02181669883430004\n",
      "Epoch: 649, Loss: 0.021814493462443352\n",
      "Epoch: 650, Loss: 0.02182060293853283\n",
      "Epoch: 651, Loss: 0.021810436621308327\n",
      "Epoch: 652, Loss: 0.021778913214802742\n",
      "Epoch: 653, Loss: 0.02178315445780754\n",
      "Epoch: 654, Loss: 0.02181374840438366\n",
      "Epoch: 655, Loss: 0.02180265262722969\n",
      "Epoch: 656, Loss: 0.021762985736131668\n",
      "Epoch: 657, Loss: 0.021767226979136467\n",
      "Epoch: 658, Loss: 0.021826131269335747\n",
      "Epoch: 659, Loss: 0.021861549466848373\n",
      "Epoch: 660, Loss: 0.021914685145020485\n",
      "Epoch: 661, Loss: 0.021897317841649055\n",
      "Epoch: 662, Loss: 0.021977219730615616\n",
      "Epoch: 663, Loss: 0.02196471020579338\n",
      "Epoch: 664, Loss: 0.021858355030417442\n",
      "Epoch: 665, Loss: 0.021798057481646538\n",
      "Epoch: 666, Loss: 0.02184063196182251\n",
      "Epoch: 667, Loss: 0.02185719460248947\n",
      "Epoch: 668, Loss: 0.02183830551803112\n",
      "Epoch: 669, Loss: 0.021810729056596756\n",
      "Epoch: 670, Loss: 0.021776767447590828\n",
      "Epoch: 671, Loss: 0.021780118346214294\n",
      "Epoch: 672, Loss: 0.021768881008028984\n",
      "Epoch: 673, Loss: 0.02177327685058117\n",
      "Epoch: 674, Loss: 0.021803520619869232\n",
      "Epoch: 675, Loss: 0.021731529384851456\n",
      "Epoch: 676, Loss: 0.021717723459005356\n",
      "Epoch: 677, Loss: 0.021735861897468567\n",
      "Epoch: 678, Loss: 0.02172890119254589\n",
      "Epoch: 679, Loss: 0.02172255888581276\n",
      "Epoch: 680, Loss: 0.021711183711886406\n",
      "Epoch: 681, Loss: 0.02170546166598797\n",
      "Epoch: 682, Loss: 0.021733438596129417\n",
      "Epoch: 683, Loss: 0.02169855311512947\n",
      "Epoch: 684, Loss: 0.021662937477231026\n",
      "Epoch: 685, Loss: 0.021635206416249275\n",
      "Epoch: 686, Loss: 0.021670615300536156\n",
      "Epoch: 687, Loss: 0.021612202748656273\n",
      "Epoch: 688, Loss: 0.021543122828006744\n",
      "Epoch: 689, Loss: 0.021536437794566154\n",
      "Epoch: 690, Loss: 0.021531162783503532\n",
      "Epoch: 691, Loss: 0.0215279720723629\n",
      "Epoch: 692, Loss: 0.021539390087127686\n",
      "Epoch: 693, Loss: 0.02155950479209423\n",
      "Epoch: 694, Loss: 0.021584047004580498\n",
      "Epoch: 695, Loss: 0.02157578617334366\n",
      "Epoch: 696, Loss: 0.021537218242883682\n",
      "Epoch: 697, Loss: 0.0216103196144104\n",
      "Epoch: 698, Loss: 0.021743403747677803\n",
      "Epoch: 699, Loss: 0.021645229309797287\n",
      "Epoch: 700, Loss: 0.021651586517691612\n",
      "Epoch: 701, Loss: 0.021729346364736557\n",
      "Epoch: 702, Loss: 0.021852590143680573\n",
      "Epoch: 703, Loss: 0.021746670827269554\n",
      "Epoch: 704, Loss: 0.02169778384268284\n",
      "Epoch: 705, Loss: 0.021572133526206017\n",
      "Epoch: 706, Loss: 0.021606801077723503\n",
      "Epoch: 707, Loss: 0.021759241819381714\n",
      "Epoch: 708, Loss: 0.02183549664914608\n",
      "Epoch: 709, Loss: 0.021724767982959747\n",
      "Epoch: 710, Loss: 0.021908294409513474\n",
      "Epoch: 711, Loss: 0.021936018019914627\n",
      "Epoch: 712, Loss: 0.021818624809384346\n",
      "Epoch: 713, Loss: 0.022050907835364342\n",
      "Epoch: 714, Loss: 0.022083114832639694\n",
      "Epoch: 715, Loss: 0.022207632660865784\n",
      "Epoch: 716, Loss: 0.02202630415558815\n",
      "Epoch: 717, Loss: 0.021808162331581116\n",
      "Epoch: 718, Loss: 0.021718300879001617\n",
      "Epoch: 719, Loss: 0.02175055257976055\n",
      "Epoch: 720, Loss: 0.021761683747172356\n",
      "Epoch: 721, Loss: 0.02159338817000389\n",
      "Epoch: 722, Loss: 0.021481024101376534\n",
      "Epoch: 723, Loss: 0.021411020308732986\n",
      "Epoch: 724, Loss: 0.021406691521406174\n",
      "Epoch: 725, Loss: 0.021418122574687004\n",
      "Epoch: 726, Loss: 0.02139880694448948\n",
      "Epoch: 727, Loss: 0.021361829712986946\n",
      "Epoch: 728, Loss: 0.021338969469070435\n",
      "Epoch: 729, Loss: 0.021337047219276428\n",
      "Epoch: 730, Loss: 0.02136867679655552\n",
      "Epoch: 731, Loss: 0.02134954184293747\n",
      "Epoch: 732, Loss: 0.02133237197995186\n",
      "Epoch: 733, Loss: 0.021298397332429886\n",
      "Epoch: 734, Loss: 0.021301086992025375\n",
      "Epoch: 735, Loss: 0.021301833912730217\n",
      "Epoch: 736, Loss: 0.0212798360735178\n",
      "Epoch: 737, Loss: 0.021268663927912712\n",
      "Epoch: 738, Loss: 0.021285245195031166\n",
      "Epoch: 739, Loss: 0.021255256608128548\n",
      "Epoch: 740, Loss: 0.0212604608386755\n",
      "Epoch: 741, Loss: 0.021266303956508636\n",
      "Epoch: 742, Loss: 0.02126990258693695\n",
      "Epoch: 743, Loss: 0.02127240225672722\n",
      "Epoch: 744, Loss: 0.02122144028544426\n",
      "Epoch: 745, Loss: 0.021225279197096825\n",
      "Epoch: 746, Loss: 0.021218005567789078\n",
      "Epoch: 747, Loss: 0.02123054675757885\n",
      "Epoch: 748, Loss: 0.02121713198721409\n",
      "Epoch: 749, Loss: 0.021226514130830765\n",
      "Epoch: 750, Loss: 0.02121308445930481\n",
      "Epoch: 751, Loss: 0.021219909191131592\n",
      "Epoch: 752, Loss: 0.021204985678195953\n",
      "Epoch: 753, Loss: 0.021243497729301453\n",
      "Epoch: 754, Loss: 0.02125752903521061\n",
      "Epoch: 755, Loss: 0.021282367408275604\n",
      "Epoch: 756, Loss: 0.02140447497367859\n",
      "Epoch: 757, Loss: 0.02133464626967907\n",
      "Epoch: 758, Loss: 0.0215371772646904\n",
      "Epoch: 759, Loss: 0.021665286272764206\n",
      "Epoch: 760, Loss: 0.02165762521326542\n",
      "Epoch: 761, Loss: 0.02178177796304226\n",
      "Epoch: 762, Loss: 0.021912015974521637\n",
      "Epoch: 763, Loss: 0.02238769829273224\n",
      "Epoch: 764, Loss: 0.022561797872185707\n",
      "Epoch: 765, Loss: 0.02223096415400505\n",
      "Epoch: 766, Loss: 0.02220158837735653\n",
      "Epoch: 767, Loss: 0.021998204290866852\n",
      "Epoch: 768, Loss: 0.021733513101935387\n",
      "Epoch: 769, Loss: 0.021471135318279266\n",
      "Epoch: 770, Loss: 0.021265551447868347\n",
      "Epoch: 771, Loss: 0.02132035605609417\n",
      "Epoch: 772, Loss: 0.02122131548821926\n",
      "Epoch: 773, Loss: 0.021161939948797226\n",
      "Epoch: 774, Loss: 0.02112470753490925\n",
      "Epoch: 775, Loss: 0.02110505849123001\n",
      "Epoch: 776, Loss: 0.021060051396489143\n",
      "Epoch: 777, Loss: 0.021097691729664803\n",
      "Epoch: 778, Loss: 0.021114230155944824\n",
      "Epoch: 779, Loss: 0.021073244512081146\n",
      "Epoch: 780, Loss: 0.021055297926068306\n",
      "Epoch: 781, Loss: 0.02102918177843094\n",
      "Epoch: 782, Loss: 0.02102934755384922\n",
      "Epoch: 783, Loss: 0.02100858837366104\n",
      "Epoch: 784, Loss: 0.020981652662158012\n",
      "Epoch: 785, Loss: 0.020970281213521957\n",
      "Epoch: 786, Loss: 0.02096467837691307\n",
      "Epoch: 787, Loss: 0.020978249609470367\n",
      "Epoch: 788, Loss: 0.020962068811058998\n",
      "Epoch: 789, Loss: 0.020959388464689255\n",
      "Epoch: 790, Loss: 0.020969899371266365\n",
      "Epoch: 791, Loss: 0.020955421030521393\n",
      "Epoch: 792, Loss: 0.0209439005702734\n",
      "Epoch: 793, Loss: 0.020946728065609932\n",
      "Epoch: 794, Loss: 0.020950907841324806\n",
      "Epoch: 795, Loss: 0.020957618951797485\n",
      "Epoch: 796, Loss: 0.020952574908733368\n",
      "Epoch: 797, Loss: 0.020959652960300446\n",
      "Epoch: 798, Loss: 0.020959358662366867\n",
      "Epoch: 799, Loss: 0.021003704518079758\n",
      "Epoch: 800, Loss: 0.02100546285510063\n",
      "Epoch: 801, Loss: 0.020988959819078445\n",
      "Epoch: 802, Loss: 0.021040113642811775\n",
      "Epoch: 803, Loss: 0.02107246406376362\n",
      "Epoch: 804, Loss: 0.021008659154176712\n",
      "Epoch: 805, Loss: 0.02107768878340721\n",
      "Epoch: 806, Loss: 0.021074939519166946\n",
      "Epoch: 807, Loss: 0.021025391295552254\n",
      "Epoch: 808, Loss: 0.020994119346141815\n",
      "Epoch: 809, Loss: 0.021063214167952538\n",
      "Epoch: 810, Loss: 0.021017594262957573\n",
      "Epoch: 811, Loss: 0.02095884084701538\n",
      "Epoch: 812, Loss: 0.021006908267736435\n",
      "Epoch: 813, Loss: 0.021123085170984268\n",
      "Epoch: 814, Loss: 0.02099194936454296\n",
      "Epoch: 815, Loss: 0.021036656573414803\n",
      "Epoch: 816, Loss: 0.02102951519191265\n",
      "Epoch: 817, Loss: 0.0209796242415905\n",
      "Epoch: 818, Loss: 0.020967042073607445\n",
      "Epoch: 819, Loss: 0.021077515557408333\n",
      "Epoch: 820, Loss: 0.021004749462008476\n",
      "Epoch: 821, Loss: 0.020916704088449478\n",
      "Epoch: 822, Loss: 0.020923050120472908\n",
      "Epoch: 823, Loss: 0.020943893119692802\n",
      "Epoch: 824, Loss: 0.02088998630642891\n",
      "Epoch: 825, Loss: 0.020908260717988014\n",
      "Epoch: 826, Loss: 0.020932679995894432\n",
      "Epoch: 827, Loss: 0.020872872322797775\n",
      "Epoch: 828, Loss: 0.02095579355955124\n",
      "Epoch: 829, Loss: 0.020994415506720543\n",
      "Epoch: 830, Loss: 0.02090434543788433\n",
      "Epoch: 831, Loss: 0.020973140373826027\n",
      "Epoch: 832, Loss: 0.021006902679800987\n",
      "Epoch: 833, Loss: 0.020994341000914574\n",
      "Epoch: 834, Loss: 0.02139819599688053\n",
      "Epoch: 835, Loss: 0.021320724859833717\n",
      "Epoch: 836, Loss: 0.02117556519806385\n",
      "Epoch: 837, Loss: 0.021103808656334877\n",
      "Epoch: 838, Loss: 0.02103009819984436\n",
      "Epoch: 839, Loss: 0.020901504904031754\n",
      "Epoch: 840, Loss: 0.020867234095931053\n",
      "Epoch: 841, Loss: 0.0208851620554924\n",
      "Epoch: 842, Loss: 0.020900381729006767\n",
      "Epoch: 843, Loss: 0.020932624116539955\n",
      "Epoch: 844, Loss: 0.02086549811065197\n",
      "Epoch: 845, Loss: 0.020863015204668045\n",
      "Epoch: 846, Loss: 0.020830435678362846\n",
      "Epoch: 847, Loss: 0.020805897191166878\n",
      "Epoch: 848, Loss: 0.020792057737708092\n",
      "Epoch: 849, Loss: 0.020797010511159897\n",
      "Epoch: 850, Loss: 0.020784679800271988\n",
      "Epoch: 851, Loss: 0.020785143598914146\n",
      "Epoch: 852, Loss: 0.020769840106368065\n",
      "Epoch: 853, Loss: 0.02077341079711914\n",
      "Epoch: 854, Loss: 0.020822016522288322\n",
      "Epoch: 855, Loss: 0.020802700892090797\n",
      "Epoch: 856, Loss: 0.020823121070861816\n",
      "Epoch: 857, Loss: 0.02092450112104416\n",
      "Epoch: 858, Loss: 0.02085386961698532\n",
      "Epoch: 859, Loss: 0.020879343152046204\n",
      "Epoch: 860, Loss: 0.021000701934099197\n",
      "Epoch: 861, Loss: 0.020977087318897247\n",
      "Epoch: 862, Loss: 0.021341055631637573\n",
      "Epoch: 863, Loss: 0.02125227265059948\n",
      "Epoch: 864, Loss: 0.021176354959607124\n",
      "Epoch: 865, Loss: 0.02104802615940571\n",
      "Epoch: 866, Loss: 0.021056238561868668\n",
      "Epoch: 867, Loss: 0.021087121218442917\n",
      "Epoch: 868, Loss: 0.021370241418480873\n",
      "Epoch: 869, Loss: 0.021071569994091988\n",
      "Epoch: 870, Loss: 0.021010199561715126\n",
      "Epoch: 871, Loss: 0.020947884768247604\n",
      "Epoch: 872, Loss: 0.020943474024534225\n",
      "Epoch: 873, Loss: 0.020884085446596146\n",
      "Epoch: 874, Loss: 0.020966826006770134\n",
      "Epoch: 875, Loss: 0.02114144153892994\n",
      "Epoch: 876, Loss: 0.02113693207502365\n",
      "Epoch: 877, Loss: 0.021503321826457977\n",
      "Epoch: 878, Loss: 0.021447815001010895\n",
      "Epoch: 879, Loss: 0.021347740665078163\n",
      "Epoch: 880, Loss: 0.02116432972252369\n",
      "Epoch: 881, Loss: 0.02105272375047207\n",
      "Epoch: 882, Loss: 0.021200545132160187\n",
      "Epoch: 883, Loss: 0.021369904279708862\n",
      "Epoch: 884, Loss: 0.021273517981171608\n",
      "Epoch: 885, Loss: 0.02088894695043564\n",
      "Epoch: 886, Loss: 0.02084013633430004\n",
      "Epoch: 887, Loss: 0.02079089917242527\n",
      "Epoch: 888, Loss: 0.020749039947986603\n",
      "Epoch: 889, Loss: 0.020730197429656982\n",
      "Epoch: 890, Loss: 0.020739367231726646\n",
      "Epoch: 891, Loss: 0.020678889006376266\n",
      "Epoch: 892, Loss: 0.020659035071730614\n",
      "Epoch: 893, Loss: 0.02065904438495636\n",
      "Epoch: 894, Loss: 0.02066144533455372\n",
      "Epoch: 895, Loss: 0.0206640362739563\n",
      "Epoch: 896, Loss: 0.0206448957324028\n",
      "Epoch: 897, Loss: 0.020632179453969002\n",
      "Epoch: 898, Loss: 0.02062554471194744\n",
      "Epoch: 899, Loss: 0.02062246948480606\n",
      "Epoch: 900, Loss: 0.020614365115761757\n",
      "Epoch: 901, Loss: 0.020606931298971176\n",
      "Epoch: 902, Loss: 0.020600629970431328\n",
      "Epoch: 903, Loss: 0.02060559205710888\n",
      "Epoch: 904, Loss: 0.02060375176370144\n",
      "Epoch: 905, Loss: 0.02060648612678051\n",
      "Epoch: 906, Loss: 0.02061438001692295\n",
      "Epoch: 907, Loss: 0.02062377706170082\n",
      "Epoch: 908, Loss: 0.020619070157408714\n",
      "Epoch: 909, Loss: 0.020634833723306656\n",
      "Epoch: 910, Loss: 0.020634537562727928\n",
      "Epoch: 911, Loss: 0.020620698109269142\n",
      "Epoch: 912, Loss: 0.020646316930651665\n",
      "Epoch: 913, Loss: 0.02064129151403904\n",
      "Epoch: 914, Loss: 0.02062262035906315\n",
      "Epoch: 915, Loss: 0.020644603297114372\n",
      "Epoch: 916, Loss: 0.02065678872168064\n",
      "Epoch: 917, Loss: 0.020670905709266663\n",
      "Epoch: 918, Loss: 0.0207833219319582\n",
      "Epoch: 919, Loss: 0.02085544355213642\n",
      "Epoch: 920, Loss: 0.02091171033680439\n",
      "Epoch: 921, Loss: 0.02102096565067768\n",
      "Epoch: 922, Loss: 0.020931299775838852\n",
      "Epoch: 923, Loss: 0.020847612991929054\n",
      "Epoch: 924, Loss: 0.02104349434375763\n",
      "Epoch: 925, Loss: 0.021084103733301163\n",
      "Epoch: 926, Loss: 0.02093270607292652\n",
      "Epoch: 927, Loss: 0.02090292051434517\n",
      "Epoch: 928, Loss: 0.02083926647901535\n",
      "Epoch: 929, Loss: 0.020860837772488594\n",
      "Epoch: 930, Loss: 0.02093775011599064\n",
      "Epoch: 931, Loss: 0.020838690921664238\n",
      "Epoch: 932, Loss: 0.02084718830883503\n",
      "Epoch: 933, Loss: 0.020818931981921196\n",
      "Epoch: 934, Loss: 0.021082140505313873\n",
      "Epoch: 935, Loss: 0.021200336515903473\n",
      "Epoch: 936, Loss: 0.020913708955049515\n",
      "Epoch: 937, Loss: 0.02080337144434452\n",
      "Epoch: 938, Loss: 0.02075994201004505\n",
      "Epoch: 939, Loss: 0.020607242360711098\n",
      "Epoch: 940, Loss: 0.02067692205309868\n",
      "Epoch: 941, Loss: 0.020666664466261864\n",
      "Epoch: 942, Loss: 0.020689593628048897\n",
      "Epoch: 943, Loss: 0.020632624626159668\n",
      "Epoch: 944, Loss: 0.02053827792406082\n",
      "Epoch: 945, Loss: 0.020519301295280457\n",
      "Epoch: 946, Loss: 0.020511498674750328\n",
      "Epoch: 947, Loss: 0.02053230255842209\n",
      "Epoch: 948, Loss: 0.02055000700056553\n",
      "Epoch: 949, Loss: 0.020535653457045555\n",
      "Epoch: 950, Loss: 0.020502310246229172\n",
      "Epoch: 951, Loss: 0.020496580749750137\n",
      "Epoch: 952, Loss: 0.02050902135670185\n",
      "Epoch: 953, Loss: 0.020498618483543396\n",
      "Epoch: 954, Loss: 0.02048114314675331\n",
      "Epoch: 955, Loss: 0.02048206329345703\n",
      "Epoch: 956, Loss: 0.020488444715738297\n",
      "Epoch: 957, Loss: 0.02049964852631092\n",
      "Epoch: 958, Loss: 0.020515331998467445\n",
      "Epoch: 959, Loss: 0.020525414496660233\n",
      "Epoch: 960, Loss: 0.02052422985434532\n",
      "Epoch: 961, Loss: 0.02049952745437622\n",
      "Epoch: 962, Loss: 0.020500412210822105\n",
      "Epoch: 963, Loss: 0.020523499697446823\n",
      "Epoch: 964, Loss: 0.020502952858805656\n",
      "Epoch: 965, Loss: 0.020474478602409363\n",
      "Epoch: 966, Loss: 0.020552895963191986\n",
      "Epoch: 967, Loss: 0.020542919635772705\n",
      "Epoch: 968, Loss: 0.020512504503130913\n",
      "Epoch: 969, Loss: 0.020622413605451584\n",
      "Epoch: 970, Loss: 0.020627809688448906\n",
      "Epoch: 971, Loss: 0.020548757165670395\n",
      "Epoch: 972, Loss: 0.02063801884651184\n",
      "Epoch: 973, Loss: 0.02065720595419407\n",
      "Epoch: 974, Loss: 0.020626403391361237\n",
      "Epoch: 975, Loss: 0.020571168512105942\n",
      "Epoch: 976, Loss: 0.020586108788847923\n",
      "Epoch: 977, Loss: 0.02056298218667507\n",
      "Epoch: 978, Loss: 0.020565584301948547\n",
      "Epoch: 979, Loss: 0.020541416481137276\n",
      "Epoch: 980, Loss: 0.02047528512775898\n",
      "Epoch: 981, Loss: 0.02053319662809372\n",
      "Epoch: 982, Loss: 0.020556915551424026\n",
      "Epoch: 983, Loss: 0.020470496267080307\n",
      "Epoch: 984, Loss: 0.02048766054213047\n",
      "Epoch: 985, Loss: 0.020580116659402847\n",
      "Epoch: 986, Loss: 0.020520223304629326\n",
      "Epoch: 987, Loss: 0.020551232621073723\n",
      "Epoch: 988, Loss: 0.020601728931069374\n",
      "Epoch: 989, Loss: 0.02054007723927498\n",
      "Epoch: 990, Loss: 0.020551417022943497\n",
      "Epoch: 991, Loss: 0.020634939894080162\n",
      "Epoch: 992, Loss: 0.020592616870999336\n",
      "Epoch: 993, Loss: 0.020514242351055145\n",
      "Epoch: 994, Loss: 0.0205107219517231\n",
      "Epoch: 995, Loss: 0.02052614837884903\n",
      "Epoch: 996, Loss: 0.02046629972755909\n",
      "Epoch: 997, Loss: 0.02042972855269909\n",
      "Epoch: 998, Loss: 0.020481526851654053\n",
      "Epoch: 999, Loss: 0.02057846449315548\n",
      "Epoch: 1000, Loss: 0.02061905711889267\n",
      "Epoch: 1001, Loss: 0.020505782216787338\n",
      "Epoch: 1002, Loss: 0.020466942340135574\n",
      "Epoch: 1003, Loss: 0.020495424047112465\n",
      "Epoch: 1004, Loss: 0.020472489297389984\n",
      "Epoch: 1005, Loss: 0.02041216753423214\n",
      "Epoch: 1006, Loss: 0.020371176302433014\n",
      "Epoch: 1007, Loss: 0.02037137746810913\n",
      "Epoch: 1008, Loss: 0.02039387822151184\n",
      "Epoch: 1009, Loss: 0.020386893302202225\n",
      "Epoch: 1010, Loss: 0.020349891856312752\n",
      "Epoch: 1011, Loss: 0.020404895767569542\n",
      "Epoch: 1012, Loss: 0.020407211035490036\n",
      "Epoch: 1013, Loss: 0.02041027881205082\n",
      "Epoch: 1014, Loss: 0.020623724907636642\n",
      "Epoch: 1015, Loss: 0.020596249029040337\n",
      "Epoch: 1016, Loss: 0.020541619509458542\n",
      "Epoch: 1017, Loss: 0.020875779911875725\n",
      "Epoch: 1018, Loss: 0.020846199244260788\n",
      "Epoch: 1019, Loss: 0.020544210448861122\n",
      "Epoch: 1020, Loss: 0.020590608939528465\n",
      "Epoch: 1021, Loss: 0.0209578238427639\n",
      "Epoch: 1022, Loss: 0.02110709249973297\n",
      "Epoch: 1023, Loss: 0.020799750462174416\n",
      "Epoch: 1024, Loss: 0.02064117230474949\n",
      "Epoch: 1025, Loss: 0.020552415400743484\n",
      "Epoch: 1026, Loss: 0.020627101883292198\n",
      "Epoch: 1027, Loss: 0.020697154104709625\n",
      "Epoch: 1028, Loss: 0.02087007276713848\n",
      "Epoch: 1029, Loss: 0.020905939862132072\n",
      "Epoch: 1030, Loss: 0.020762383937835693\n",
      "Epoch: 1031, Loss: 0.02068682201206684\n",
      "Epoch: 1032, Loss: 0.0207709651440382\n",
      "Epoch: 1033, Loss: 0.020811645314097404\n",
      "Epoch: 1034, Loss: 0.020519765093922615\n",
      "Epoch: 1035, Loss: 0.020437490195035934\n",
      "Epoch: 1036, Loss: 0.020380087196826935\n",
      "Epoch: 1037, Loss: 0.0203410591930151\n",
      "Epoch: 1038, Loss: 0.02034507505595684\n",
      "Epoch: 1039, Loss: 0.020297711715102196\n",
      "Epoch: 1040, Loss: 0.020293457433581352\n",
      "Epoch: 1041, Loss: 0.020299283787608147\n",
      "Epoch: 1042, Loss: 0.020271753892302513\n",
      "Epoch: 1043, Loss: 0.0202553179115057\n",
      "Epoch: 1044, Loss: 0.020243659615516663\n",
      "Epoch: 1045, Loss: 0.020236779004335403\n",
      "Epoch: 1046, Loss: 0.02023395523428917\n",
      "Epoch: 1047, Loss: 0.0202247966080904\n",
      "Epoch: 1048, Loss: 0.02022453397512436\n",
      "Epoch: 1049, Loss: 0.020234180614352226\n",
      "Epoch: 1050, Loss: 0.020235303789377213\n",
      "Epoch: 1051, Loss: 0.02022763527929783\n",
      "Epoch: 1052, Loss: 0.020231803879141808\n",
      "Epoch: 1053, Loss: 0.020217034965753555\n",
      "Epoch: 1054, Loss: 0.02021702006459236\n",
      "Epoch: 1055, Loss: 0.020263370126485825\n",
      "Epoch: 1056, Loss: 0.020300602540373802\n",
      "Epoch: 1057, Loss: 0.020259812474250793\n",
      "Epoch: 1058, Loss: 0.020269794389605522\n",
      "Epoch: 1059, Loss: 0.020263832062482834\n",
      "Epoch: 1060, Loss: 0.020224090665578842\n",
      "Epoch: 1061, Loss: 0.020291732624173164\n",
      "Epoch: 1062, Loss: 0.02038280852138996\n",
      "Epoch: 1063, Loss: 0.02032896690070629\n",
      "Epoch: 1064, Loss: 0.020423244684934616\n",
      "Epoch: 1065, Loss: 0.02042757160961628\n",
      "Epoch: 1066, Loss: 0.02025117166340351\n",
      "Epoch: 1067, Loss: 0.02036747895181179\n",
      "Epoch: 1068, Loss: 0.020476246252655983\n",
      "Epoch: 1069, Loss: 0.02040949836373329\n",
      "Epoch: 1070, Loss: 0.02040356956422329\n",
      "Epoch: 1071, Loss: 0.02052794210612774\n",
      "Epoch: 1072, Loss: 0.020453456789255142\n",
      "Epoch: 1073, Loss: 0.02042657509446144\n",
      "Epoch: 1074, Loss: 0.020362233743071556\n",
      "Epoch: 1075, Loss: 0.02035761997103691\n",
      "Epoch: 1076, Loss: 0.02036111243069172\n",
      "Epoch: 1077, Loss: 0.020342938601970673\n",
      "Epoch: 1078, Loss: 0.020335553213953972\n",
      "Epoch: 1079, Loss: 0.02028312347829342\n",
      "Epoch: 1080, Loss: 0.020246075466275215\n",
      "Epoch: 1081, Loss: 0.020249122753739357\n",
      "Epoch: 1082, Loss: 0.020282916724681854\n",
      "Epoch: 1083, Loss: 0.020300285890698433\n",
      "Epoch: 1084, Loss: 0.02022918500006199\n",
      "Epoch: 1085, Loss: 0.02025272324681282\n",
      "Epoch: 1086, Loss: 0.020276840776205063\n",
      "Epoch: 1087, Loss: 0.02021077461540699\n",
      "Epoch: 1088, Loss: 0.020163092762231827\n",
      "Epoch: 1089, Loss: 0.020259231328964233\n",
      "Epoch: 1090, Loss: 0.02029808610677719\n",
      "Epoch: 1091, Loss: 0.020224088802933693\n",
      "Epoch: 1092, Loss: 0.020237235352396965\n",
      "Epoch: 1093, Loss: 0.020341990515589714\n",
      "Epoch: 1094, Loss: 0.020361395552754402\n",
      "Epoch: 1095, Loss: 0.020264077931642532\n",
      "Epoch: 1096, Loss: 0.020224500447511673\n",
      "Epoch: 1097, Loss: 0.020189639180898666\n",
      "Epoch: 1098, Loss: 0.020181866362690926\n",
      "Epoch: 1099, Loss: 0.020200606435537338\n",
      "Epoch: 1100, Loss: 0.020213589072227478\n",
      "Epoch: 1101, Loss: 0.020225152373313904\n",
      "Epoch: 1102, Loss: 0.02022966556251049\n",
      "Epoch: 1103, Loss: 0.020292431116104126\n",
      "Epoch: 1104, Loss: 0.020265083760023117\n",
      "Epoch: 1105, Loss: 0.020170118659734726\n",
      "Epoch: 1106, Loss: 0.020153742283582687\n",
      "Epoch: 1107, Loss: 0.020181521773338318\n",
      "Epoch: 1108, Loss: 0.020135438069701195\n",
      "Epoch: 1109, Loss: 0.020100174471735954\n",
      "Epoch: 1110, Loss: 0.020130285993218422\n",
      "Epoch: 1111, Loss: 0.02022487483918667\n",
      "Epoch: 1112, Loss: 0.020146191120147705\n",
      "Epoch: 1113, Loss: 0.020125433802604675\n",
      "Epoch: 1114, Loss: 0.02030169777572155\n",
      "Epoch: 1115, Loss: 0.020269369706511497\n",
      "Epoch: 1116, Loss: 0.02025805599987507\n",
      "Epoch: 1117, Loss: 0.020426325500011444\n",
      "Epoch: 1118, Loss: 0.02059578336775303\n",
      "Epoch: 1119, Loss: 0.020758558064699173\n",
      "Epoch: 1120, Loss: 0.02094152383506298\n",
      "Epoch: 1121, Loss: 0.021925557404756546\n",
      "Epoch: 1122, Loss: 0.021879537031054497\n",
      "Epoch: 1123, Loss: 0.02125272899866104\n",
      "Epoch: 1124, Loss: 0.02211231365799904\n",
      "Epoch: 1125, Loss: 0.023654095828533173\n",
      "Epoch: 1126, Loss: 0.022226518020033836\n",
      "Epoch: 1127, Loss: 0.02423909120261669\n",
      "Epoch: 1128, Loss: 0.023989010602235794\n",
      "Epoch: 1129, Loss: 0.02296014316380024\n",
      "Epoch: 1130, Loss: 0.022738121449947357\n",
      "Epoch: 1131, Loss: 0.022460974752902985\n",
      "Epoch: 1132, Loss: 0.021720021963119507\n",
      "Epoch: 1133, Loss: 0.021220913156867027\n",
      "Epoch: 1134, Loss: 0.020942900329828262\n",
      "Epoch: 1135, Loss: 0.020713966339826584\n",
      "Epoch: 1136, Loss: 0.020610226318240166\n",
      "Epoch: 1137, Loss: 0.020454341545701027\n",
      "Epoch: 1138, Loss: 0.02039540559053421\n",
      "Epoch: 1139, Loss: 0.020333927124738693\n",
      "Epoch: 1140, Loss: 0.02028789184987545\n",
      "Epoch: 1141, Loss: 0.020238958299160004\n",
      "Epoch: 1142, Loss: 0.020206015557050705\n",
      "Epoch: 1143, Loss: 0.02016586810350418\n",
      "Epoch: 1144, Loss: 0.02013310417532921\n",
      "Epoch: 1145, Loss: 0.020111236721277237\n",
      "Epoch: 1146, Loss: 0.020099902525544167\n",
      "Epoch: 1147, Loss: 0.020086415112018585\n",
      "Epoch: 1148, Loss: 0.020078547298908234\n",
      "Epoch: 1149, Loss: 0.02006813883781433\n",
      "Epoch: 1150, Loss: 0.02005867473781109\n",
      "Epoch: 1151, Loss: 0.02004983462393284\n",
      "Epoch: 1152, Loss: 0.020042147487401962\n",
      "Epoch: 1153, Loss: 0.020034588873386383\n",
      "Epoch: 1154, Loss: 0.020027976483106613\n",
      "Epoch: 1155, Loss: 0.020021144300699234\n",
      "Epoch: 1156, Loss: 0.02001475915312767\n",
      "Epoch: 1157, Loss: 0.02000853605568409\n",
      "Epoch: 1158, Loss: 0.02000287175178528\n",
      "Epoch: 1159, Loss: 0.019997838884592056\n",
      "Epoch: 1160, Loss: 0.01999300718307495\n",
      "Epoch: 1161, Loss: 0.01998923346400261\n",
      "Epoch: 1162, Loss: 0.01998482644557953\n",
      "Epoch: 1163, Loss: 0.019982215017080307\n",
      "Epoch: 1164, Loss: 0.019978610798716545\n",
      "Epoch: 1165, Loss: 0.01997772976756096\n",
      "Epoch: 1166, Loss: 0.019976535812020302\n",
      "Epoch: 1167, Loss: 0.019978679716587067\n",
      "Epoch: 1168, Loss: 0.019979091361165047\n",
      "Epoch: 1169, Loss: 0.01998198963701725\n",
      "Epoch: 1170, Loss: 0.01997692883014679\n",
      "Epoch: 1171, Loss: 0.019975675269961357\n",
      "Epoch: 1172, Loss: 0.019968079403042793\n",
      "Epoch: 1173, Loss: 0.01996557228267193\n",
      "Epoch: 1174, Loss: 0.019959954544901848\n",
      "Epoch: 1175, Loss: 0.019955897703766823\n",
      "Epoch: 1176, Loss: 0.019953882321715355\n",
      "Epoch: 1177, Loss: 0.019948970526456833\n",
      "Epoch: 1178, Loss: 0.01995086297392845\n",
      "Epoch: 1179, Loss: 0.019948100671172142\n",
      "Epoch: 1180, Loss: 0.019956029951572418\n",
      "Epoch: 1181, Loss: 0.01996455527842045\n",
      "Epoch: 1182, Loss: 0.01998557150363922\n",
      "Epoch: 1183, Loss: 0.019974425435066223\n",
      "Epoch: 1184, Loss: 0.019982248544692993\n",
      "Epoch: 1185, Loss: 0.019969461485743523\n",
      "Epoch: 1186, Loss: 0.019973644986748695\n",
      "Epoch: 1187, Loss: 0.019963620230555534\n",
      "Epoch: 1188, Loss: 0.019957074895501137\n",
      "Epoch: 1189, Loss: 0.019967002794146538\n",
      "Epoch: 1190, Loss: 0.0199641901999712\n",
      "Epoch: 1191, Loss: 0.01994360238313675\n",
      "Epoch: 1192, Loss: 0.01996767707169056\n",
      "Epoch: 1193, Loss: 0.020004039630293846\n",
      "Epoch: 1194, Loss: 0.01996719278395176\n",
      "Epoch: 1195, Loss: 0.019949302077293396\n",
      "Epoch: 1196, Loss: 0.019969312474131584\n",
      "Epoch: 1197, Loss: 0.0199833195656538\n",
      "Epoch: 1198, Loss: 0.019939303398132324\n",
      "Epoch: 1199, Loss: 0.01993042416870594\n",
      "Epoch: 1200, Loss: 0.01997738890349865\n",
      "Epoch: 1201, Loss: 0.020015737041831017\n",
      "Epoch: 1202, Loss: 0.020006850361824036\n",
      "Epoch: 1203, Loss: 0.020079754292964935\n",
      "Epoch: 1204, Loss: 0.020169317722320557\n",
      "Epoch: 1205, Loss: 0.02014429308474064\n",
      "Epoch: 1206, Loss: 0.020101986825466156\n",
      "Epoch: 1207, Loss: 0.020054960623383522\n",
      "Epoch: 1208, Loss: 0.020126668736338615\n",
      "Epoch: 1209, Loss: 0.020122410729527473\n",
      "Epoch: 1210, Loss: 0.020030148327350616\n",
      "Epoch: 1211, Loss: 0.020005447790026665\n",
      "Epoch: 1212, Loss: 0.02002938650548458\n",
      "Epoch: 1213, Loss: 0.019993595778942108\n",
      "Epoch: 1214, Loss: 0.019971445202827454\n",
      "Epoch: 1215, Loss: 0.019972093403339386\n",
      "Epoch: 1216, Loss: 0.019968705251812935\n",
      "Epoch: 1217, Loss: 0.019935449585318565\n",
      "Epoch: 1218, Loss: 0.019915170967578888\n",
      "Epoch: 1219, Loss: 0.019921930506825447\n",
      "Epoch: 1220, Loss: 0.019938841462135315\n",
      "Epoch: 1221, Loss: 0.019936447963118553\n",
      "Epoch: 1222, Loss: 0.01992637850344181\n",
      "Epoch: 1223, Loss: 0.01991516910493374\n",
      "Epoch: 1224, Loss: 0.019920259714126587\n",
      "Epoch: 1225, Loss: 0.019926685839891434\n",
      "Epoch: 1226, Loss: 0.019942758604884148\n",
      "Epoch: 1227, Loss: 0.01999041438102722\n",
      "Epoch: 1228, Loss: 0.019984910264611244\n",
      "Epoch: 1229, Loss: 0.01995624601840973\n",
      "Epoch: 1230, Loss: 0.019932430237531662\n",
      "Epoch: 1231, Loss: 0.019937336444854736\n",
      "Epoch: 1232, Loss: 0.01989571936428547\n",
      "Epoch: 1233, Loss: 0.01989172212779522\n",
      "Epoch: 1234, Loss: 0.019900202751159668\n",
      "Epoch: 1235, Loss: 0.019885364919900894\n",
      "Epoch: 1236, Loss: 0.019887518137693405\n",
      "Epoch: 1237, Loss: 0.019906850531697273\n",
      "Epoch: 1238, Loss: 0.019904080778360367\n",
      "Epoch: 1239, Loss: 0.01988665759563446\n",
      "Epoch: 1240, Loss: 0.0198868028819561\n",
      "Epoch: 1241, Loss: 0.01992996223270893\n",
      "Epoch: 1242, Loss: 0.019923154264688492\n",
      "Epoch: 1243, Loss: 0.019899724051356316\n",
      "Epoch: 1244, Loss: 0.019937900826334953\n",
      "Epoch: 1245, Loss: 0.019950108602643013\n",
      "Epoch: 1246, Loss: 0.019902819767594337\n",
      "Epoch: 1247, Loss: 0.02006564661860466\n",
      "Epoch: 1248, Loss: 0.02024248242378235\n",
      "Epoch: 1249, Loss: 0.02007976733148098\n",
      "Epoch: 1250, Loss: 0.02006392367184162\n",
      "Epoch: 1251, Loss: 0.020098352804780006\n",
      "Epoch: 1252, Loss: 0.01996755599975586\n",
      "Epoch: 1253, Loss: 0.019881950691342354\n",
      "Epoch: 1254, Loss: 0.019903356209397316\n",
      "Epoch: 1255, Loss: 0.01989401876926422\n",
      "Epoch: 1256, Loss: 0.01985171250998974\n",
      "Epoch: 1257, Loss: 0.019840961322188377\n",
      "Epoch: 1258, Loss: 0.019827160984277725\n",
      "Epoch: 1259, Loss: 0.01980157569050789\n",
      "Epoch: 1260, Loss: 0.019790682941675186\n",
      "Epoch: 1261, Loss: 0.019792374223470688\n",
      "Epoch: 1262, Loss: 0.019798321649432182\n",
      "Epoch: 1263, Loss: 0.019794220104813576\n",
      "Epoch: 1264, Loss: 0.019809789955615997\n",
      "Epoch: 1265, Loss: 0.019833967089653015\n",
      "Epoch: 1266, Loss: 0.019831376150250435\n",
      "Epoch: 1267, Loss: 0.0198228657245636\n",
      "Epoch: 1268, Loss: 0.019880078732967377\n",
      "Epoch: 1269, Loss: 0.019902849569916725\n",
      "Epoch: 1270, Loss: 0.019843485206365585\n",
      "Epoch: 1271, Loss: 0.019911549985408783\n",
      "Epoch: 1272, Loss: 0.019980158656835556\n",
      "Epoch: 1273, Loss: 0.01990383304655552\n",
      "Epoch: 1274, Loss: 0.019990691915154457\n",
      "Epoch: 1275, Loss: 0.020149076357483864\n",
      "Epoch: 1276, Loss: 0.01997162029147148\n",
      "Epoch: 1277, Loss: 0.01995076984167099\n",
      "Epoch: 1278, Loss: 0.020017236471176147\n",
      "Epoch: 1279, Loss: 0.02004941552877426\n",
      "Epoch: 1280, Loss: 0.01992732658982277\n",
      "Epoch: 1281, Loss: 0.01988847553730011\n",
      "Epoch: 1282, Loss: 0.01997905597090721\n",
      "Epoch: 1283, Loss: 0.019958145916461945\n",
      "Epoch: 1284, Loss: 0.020028917118906975\n",
      "Epoch: 1285, Loss: 0.020176047459244728\n",
      "Epoch: 1286, Loss: 0.020112428814172745\n",
      "Epoch: 1287, Loss: 0.02015087567269802\n",
      "Epoch: 1288, Loss: 0.02006792649626732\n",
      "Epoch: 1289, Loss: 0.01998930424451828\n",
      "Epoch: 1290, Loss: 0.020127609372138977\n",
      "Epoch: 1291, Loss: 0.020085535943508148\n",
      "Epoch: 1292, Loss: 0.01997215487062931\n",
      "Epoch: 1293, Loss: 0.019960379227995872\n",
      "Epoch: 1294, Loss: 0.019868958741426468\n",
      "Epoch: 1295, Loss: 0.01986873708665371\n",
      "Epoch: 1296, Loss: 0.019893011078238487\n",
      "Epoch: 1297, Loss: 0.019848302006721497\n",
      "Epoch: 1298, Loss: 0.019857190549373627\n",
      "Epoch: 1299, Loss: 0.019858088344335556\n",
      "Epoch: 1300, Loss: 0.019825072959065437\n",
      "Epoch: 1301, Loss: 0.019783107563853264\n",
      "Epoch: 1302, Loss: 0.01980072446167469\n",
      "Epoch: 1303, Loss: 0.019809236750006676\n",
      "Epoch: 1304, Loss: 0.019812365993857384\n",
      "Epoch: 1305, Loss: 0.01979718543589115\n",
      "Epoch: 1306, Loss: 0.01980789750814438\n",
      "Epoch: 1307, Loss: 0.019821273162961006\n",
      "Epoch: 1308, Loss: 0.019806047901511192\n",
      "Epoch: 1309, Loss: 0.01977546326816082\n",
      "Epoch: 1310, Loss: 0.019770080223679543\n",
      "Epoch: 1311, Loss: 0.01976587250828743\n",
      "Epoch: 1312, Loss: 0.019758151844143867\n",
      "Epoch: 1313, Loss: 0.019748570397496223\n",
      "Epoch: 1314, Loss: 0.019733166322112083\n",
      "Epoch: 1315, Loss: 0.01971733756363392\n",
      "Epoch: 1316, Loss: 0.019742056727409363\n",
      "Epoch: 1317, Loss: 0.019756732508540154\n",
      "Epoch: 1318, Loss: 0.01974455453455448\n",
      "Epoch: 1319, Loss: 0.019728459417819977\n",
      "Epoch: 1320, Loss: 0.01975373364984989\n",
      "Epoch: 1321, Loss: 0.01982451044023037\n",
      "Epoch: 1322, Loss: 0.01976514793932438\n",
      "Epoch: 1323, Loss: 0.01974322833120823\n",
      "Epoch: 1324, Loss: 0.01978394016623497\n",
      "Epoch: 1325, Loss: 0.019767893478274345\n",
      "Epoch: 1326, Loss: 0.019719135016202927\n",
      "Epoch: 1327, Loss: 0.01982910931110382\n",
      "Epoch: 1328, Loss: 0.019965600222349167\n",
      "Epoch: 1329, Loss: 0.019938873127102852\n",
      "Epoch: 1330, Loss: 0.019801853224635124\n",
      "Epoch: 1331, Loss: 0.019871355965733528\n",
      "Epoch: 1332, Loss: 0.019919253885746002\n",
      "Epoch: 1333, Loss: 0.019789936020970345\n",
      "Epoch: 1334, Loss: 0.019739536568522453\n",
      "Epoch: 1335, Loss: 0.019768385216593742\n",
      "Epoch: 1336, Loss: 0.01972326450049877\n",
      "Epoch: 1337, Loss: 0.019702192395925522\n",
      "Epoch: 1338, Loss: 0.01976725272834301\n",
      "Epoch: 1339, Loss: 0.019758040085434914\n",
      "Epoch: 1340, Loss: 0.01978110708296299\n",
      "Epoch: 1341, Loss: 0.01981085166335106\n",
      "Epoch: 1342, Loss: 0.01982088014483452\n",
      "Epoch: 1343, Loss: 0.019767755642533302\n",
      "Epoch: 1344, Loss: 0.019785404205322266\n",
      "Epoch: 1345, Loss: 0.01980331912636757\n",
      "Epoch: 1346, Loss: 0.019812647253274918\n",
      "Epoch: 1347, Loss: 0.01988554559648037\n",
      "Epoch: 1348, Loss: 0.019855426624417305\n",
      "Epoch: 1349, Loss: 0.019777704030275345\n",
      "Epoch: 1350, Loss: 0.019879914820194244\n",
      "Epoch: 1351, Loss: 0.01974732242524624\n",
      "Epoch: 1352, Loss: 0.019825594499707222\n",
      "Epoch: 1353, Loss: 0.019915925338864326\n",
      "Epoch: 1354, Loss: 0.019790513440966606\n",
      "Epoch: 1355, Loss: 0.019736183807253838\n",
      "Epoch: 1356, Loss: 0.01989132910966873\n",
      "Epoch: 1357, Loss: 0.020092451944947243\n",
      "Epoch: 1358, Loss: 0.02003886178135872\n",
      "Epoch: 1359, Loss: 0.019893312826752663\n",
      "Epoch: 1360, Loss: 0.020084628835320473\n",
      "Epoch: 1361, Loss: 0.019981810823082924\n",
      "Epoch: 1362, Loss: 0.019977815449237823\n",
      "Epoch: 1363, Loss: 0.019977277144789696\n",
      "Epoch: 1364, Loss: 0.019867070019245148\n",
      "Epoch: 1365, Loss: 0.019795434549450874\n",
      "Epoch: 1366, Loss: 0.019673362374305725\n",
      "Epoch: 1367, Loss: 0.019650518894195557\n",
      "Epoch: 1368, Loss: 0.019653473049402237\n",
      "Epoch: 1369, Loss: 0.01965087093412876\n",
      "Epoch: 1370, Loss: 0.019652262330055237\n",
      "Epoch: 1371, Loss: 0.019660744816064835\n",
      "Epoch: 1372, Loss: 0.019625524058938026\n",
      "Epoch: 1373, Loss: 0.01961325667798519\n",
      "Epoch: 1374, Loss: 0.019597826525568962\n",
      "Epoch: 1375, Loss: 0.019613325595855713\n",
      "Epoch: 1376, Loss: 0.019623467698693275\n",
      "Epoch: 1377, Loss: 0.019649555906653404\n",
      "Epoch: 1378, Loss: 0.019640106707811356\n",
      "Epoch: 1379, Loss: 0.019657406955957413\n",
      "Epoch: 1380, Loss: 0.0196390338242054\n",
      "Epoch: 1381, Loss: 0.019630776718258858\n",
      "Epoch: 1382, Loss: 0.01963721588253975\n",
      "Epoch: 1383, Loss: 0.019682902842760086\n",
      "Epoch: 1384, Loss: 0.01964852400124073\n",
      "Epoch: 1385, Loss: 0.01963249035179615\n",
      "Epoch: 1386, Loss: 0.019605107605457306\n",
      "Epoch: 1387, Loss: 0.019594797864556313\n",
      "Epoch: 1388, Loss: 0.019609913229942322\n",
      "Epoch: 1389, Loss: 0.0196212287992239\n",
      "Epoch: 1390, Loss: 0.019603334367275238\n",
      "Epoch: 1391, Loss: 0.019620373845100403\n",
      "Epoch: 1392, Loss: 0.01961514540016651\n",
      "Epoch: 1393, Loss: 0.019599435850977898\n",
      "Epoch: 1394, Loss: 0.019566286355257034\n",
      "Epoch: 1395, Loss: 0.019572632387280464\n",
      "Epoch: 1396, Loss: 0.019597485661506653\n",
      "Epoch: 1397, Loss: 0.01959093287587166\n",
      "Epoch: 1398, Loss: 0.01958184316754341\n",
      "Epoch: 1399, Loss: 0.01961098425090313\n",
      "Epoch: 1400, Loss: 0.019614096730947495\n",
      "Epoch: 1401, Loss: 0.01959492638707161\n",
      "Epoch: 1402, Loss: 0.019608518108725548\n",
      "Epoch: 1403, Loss: 0.019569922238588333\n",
      "Epoch: 1404, Loss: 0.019600965082645416\n",
      "Epoch: 1405, Loss: 0.01967933028936386\n",
      "Epoch: 1406, Loss: 0.01959851197898388\n",
      "Epoch: 1407, Loss: 0.019661795347929\n",
      "Epoch: 1408, Loss: 0.019972048699855804\n",
      "Epoch: 1409, Loss: 0.019781772047281265\n",
      "Epoch: 1410, Loss: 0.02001986838877201\n",
      "Epoch: 1411, Loss: 0.01988661289215088\n",
      "Epoch: 1412, Loss: 0.019975310191512108\n",
      "Epoch: 1413, Loss: 0.020178889855742455\n",
      "Epoch: 1414, Loss: 0.02055034600198269\n",
      "Epoch: 1415, Loss: 0.020888006314635277\n",
      "Epoch: 1416, Loss: 0.020201262086629868\n",
      "Epoch: 1417, Loss: 0.020024118945002556\n",
      "Epoch: 1418, Loss: 0.0199576523154974\n",
      "Epoch: 1419, Loss: 0.019886307418346405\n",
      "Epoch: 1420, Loss: 0.019889265298843384\n",
      "Epoch: 1421, Loss: 0.01990719512104988\n",
      "Epoch: 1422, Loss: 0.019862446933984756\n",
      "Epoch: 1423, Loss: 0.019688140600919724\n",
      "Epoch: 1424, Loss: 0.01959111914038658\n",
      "Epoch: 1425, Loss: 0.019549190998077393\n",
      "Epoch: 1426, Loss: 0.01951354742050171\n",
      "Epoch: 1427, Loss: 0.019504301249980927\n",
      "Epoch: 1428, Loss: 0.019488278776407242\n",
      "Epoch: 1429, Loss: 0.01947866939008236\n",
      "Epoch: 1430, Loss: 0.019477449357509613\n",
      "Epoch: 1431, Loss: 0.019478339701890945\n",
      "Epoch: 1432, Loss: 0.019474009051918983\n",
      "Epoch: 1433, Loss: 0.01946561597287655\n",
      "Epoch: 1434, Loss: 0.01946830376982689\n",
      "Epoch: 1435, Loss: 0.01947760209441185\n",
      "Epoch: 1436, Loss: 0.019472438842058182\n",
      "Epoch: 1437, Loss: 0.01945800706744194\n",
      "Epoch: 1438, Loss: 0.01946966163814068\n",
      "Epoch: 1439, Loss: 0.019497383385896683\n",
      "Epoch: 1440, Loss: 0.01948850229382515\n",
      "Epoch: 1441, Loss: 0.019470658153295517\n",
      "Epoch: 1442, Loss: 0.019501373171806335\n",
      "Epoch: 1443, Loss: 0.019546890631318092\n",
      "Epoch: 1444, Loss: 0.019517483189702034\n",
      "Epoch: 1445, Loss: 0.019467011094093323\n",
      "Epoch: 1446, Loss: 0.01951252855360508\n",
      "Epoch: 1447, Loss: 0.01956982910633087\n",
      "Epoch: 1448, Loss: 0.01951405592262745\n",
      "Epoch: 1449, Loss: 0.019479980692267418\n",
      "Epoch: 1450, Loss: 0.01951548643410206\n",
      "Epoch: 1451, Loss: 0.01954849809408188\n",
      "Epoch: 1452, Loss: 0.0195402130484581\n",
      "Epoch: 1453, Loss: 0.01948310248553753\n",
      "Epoch: 1454, Loss: 0.019492870196700096\n",
      "Epoch: 1455, Loss: 0.019521627575159073\n",
      "Epoch: 1456, Loss: 0.01954258233308792\n",
      "Epoch: 1457, Loss: 0.019522346556186676\n",
      "Epoch: 1458, Loss: 0.01952506974339485\n",
      "Epoch: 1459, Loss: 0.019575409591197968\n",
      "Epoch: 1460, Loss: 0.019597729668021202\n",
      "Epoch: 1461, Loss: 0.01958390325307846\n",
      "Epoch: 1462, Loss: 0.019532665610313416\n",
      "Epoch: 1463, Loss: 0.019531436264514923\n",
      "Epoch: 1464, Loss: 0.01958131231367588\n",
      "Epoch: 1465, Loss: 0.019539566710591316\n",
      "Epoch: 1466, Loss: 0.01951608434319496\n",
      "Epoch: 1467, Loss: 0.019494591280817986\n",
      "Epoch: 1468, Loss: 0.019483093172311783\n",
      "Epoch: 1469, Loss: 0.019485069438815117\n",
      "Epoch: 1470, Loss: 0.019503707066178322\n",
      "Epoch: 1471, Loss: 0.019529448822140694\n",
      "Epoch: 1472, Loss: 0.019554583355784416\n",
      "Epoch: 1473, Loss: 0.019541291519999504\n",
      "Epoch: 1474, Loss: 0.01952328532934189\n",
      "Epoch: 1475, Loss: 0.019555075094103813\n",
      "Epoch: 1476, Loss: 0.019604187458753586\n",
      "Epoch: 1477, Loss: 0.0195472352206707\n",
      "Epoch: 1478, Loss: 0.019530652090907097\n",
      "Epoch: 1479, Loss: 0.01955564320087433\n",
      "Epoch: 1480, Loss: 0.019537996500730515\n",
      "Epoch: 1481, Loss: 0.019548479467630386\n",
      "Epoch: 1482, Loss: 0.019579308107495308\n",
      "Epoch: 1483, Loss: 0.01960507221519947\n",
      "Epoch: 1484, Loss: 0.01976257562637329\n",
      "Epoch: 1485, Loss: 0.01980559714138508\n",
      "Epoch: 1486, Loss: 0.01966979168355465\n",
      "Epoch: 1487, Loss: 0.019756855443120003\n",
      "Epoch: 1488, Loss: 0.01969185657799244\n",
      "Epoch: 1489, Loss: 0.019702505320310593\n",
      "Epoch: 1490, Loss: 0.01967642642557621\n",
      "Epoch: 1491, Loss: 0.019593089818954468\n",
      "Epoch: 1492, Loss: 0.019671374931931496\n",
      "Epoch: 1493, Loss: 0.019697602838277817\n",
      "Epoch: 1494, Loss: 0.019589195027947426\n",
      "Epoch: 1495, Loss: 0.019496778026223183\n",
      "Epoch: 1496, Loss: 0.019499242305755615\n",
      "Epoch: 1497, Loss: 0.0195343978703022\n",
      "Epoch: 1498, Loss: 0.01949259266257286\n",
      "Epoch: 1499, Loss: 0.019461888819932938\n",
      "Epoch: 1500, Loss: 0.019474873319268227\n",
      "Epoch: 1501, Loss: 0.019544191658496857\n",
      "Epoch: 1502, Loss: 0.019557150080800056\n",
      "Epoch: 1503, Loss: 0.01950259320437908\n",
      "Epoch: 1504, Loss: 0.01954749971628189\n",
      "Epoch: 1505, Loss: 0.01965804025530815\n",
      "Epoch: 1506, Loss: 0.019532974809408188\n",
      "Epoch: 1507, Loss: 0.01952454447746277\n",
      "Epoch: 1508, Loss: 0.019539451226592064\n",
      "Epoch: 1509, Loss: 0.019532786682248116\n",
      "Epoch: 1510, Loss: 0.019534055143594742\n",
      "Epoch: 1511, Loss: 0.019509833306074142\n",
      "Epoch: 1512, Loss: 0.01945820450782776\n",
      "Epoch: 1513, Loss: 0.01942889578640461\n",
      "Epoch: 1514, Loss: 0.019450930878520012\n",
      "Epoch: 1515, Loss: 0.019498877227306366\n",
      "Epoch: 1516, Loss: 0.019496887922286987\n",
      "Epoch: 1517, Loss: 0.01945299096405506\n",
      "Epoch: 1518, Loss: 0.019459519535303116\n",
      "Epoch: 1519, Loss: 0.01946573331952095\n",
      "Epoch: 1520, Loss: 0.019416440278291702\n",
      "Epoch: 1521, Loss: 0.01940678060054779\n",
      "Epoch: 1522, Loss: 0.01945757307112217\n",
      "Epoch: 1523, Loss: 0.01949874870479107\n",
      "Epoch: 1524, Loss: 0.019449478015303612\n",
      "Epoch: 1525, Loss: 0.01942889392375946\n",
      "Epoch: 1526, Loss: 0.01950143091380596\n",
      "Epoch: 1527, Loss: 0.019641704857349396\n",
      "Epoch: 1528, Loss: 0.01953856274485588\n",
      "Epoch: 1529, Loss: 0.019480960443615913\n",
      "Epoch: 1530, Loss: 0.019508689641952515\n",
      "Epoch: 1531, Loss: 0.01957753486931324\n",
      "Epoch: 1532, Loss: 0.01950087957084179\n",
      "Epoch: 1533, Loss: 0.019521191716194153\n",
      "Epoch: 1534, Loss: 0.019553111866116524\n",
      "Epoch: 1535, Loss: 0.01950448378920555\n",
      "Epoch: 1536, Loss: 0.019598161801695824\n",
      "Epoch: 1537, Loss: 0.019684890285134315\n",
      "Epoch: 1538, Loss: 0.019614791497588158\n",
      "Epoch: 1539, Loss: 0.01969952881336212\n",
      "Epoch: 1540, Loss: 0.019767392426729202\n",
      "Epoch: 1541, Loss: 0.01958642341196537\n",
      "Epoch: 1542, Loss: 0.019733725115656853\n",
      "Epoch: 1543, Loss: 0.01980205997824669\n",
      "Epoch: 1544, Loss: 0.019807569682598114\n",
      "Epoch: 1545, Loss: 0.019770754501223564\n",
      "Epoch: 1546, Loss: 0.019806673750281334\n",
      "Epoch: 1547, Loss: 0.019906610250473022\n",
      "Epoch: 1548, Loss: 0.019916150718927383\n",
      "Epoch: 1549, Loss: 0.019887248054146767\n",
      "Epoch: 1550, Loss: 0.019783245399594307\n",
      "Epoch: 1551, Loss: 0.019894693046808243\n",
      "Epoch: 1552, Loss: 0.0197454821318388\n",
      "Epoch: 1553, Loss: 0.019554726779460907\n",
      "Epoch: 1554, Loss: 0.019510116428136826\n",
      "Epoch: 1555, Loss: 0.0194861963391304\n",
      "Epoch: 1556, Loss: 0.019439559429883957\n",
      "Epoch: 1557, Loss: 0.019432762637734413\n",
      "Epoch: 1558, Loss: 0.019419776275753975\n",
      "Epoch: 1559, Loss: 0.019418297335505486\n",
      "Epoch: 1560, Loss: 0.019406527280807495\n",
      "Epoch: 1561, Loss: 0.019402209669351578\n",
      "Epoch: 1562, Loss: 0.019377576187253\n",
      "Epoch: 1563, Loss: 0.01938929222524166\n",
      "Epoch: 1564, Loss: 0.019388582557439804\n",
      "Epoch: 1565, Loss: 0.019394047558307648\n",
      "Epoch: 1566, Loss: 0.019378796219825745\n",
      "Epoch: 1567, Loss: 0.019374586641788483\n",
      "Epoch: 1568, Loss: 0.01937171444296837\n",
      "Epoch: 1569, Loss: 0.01938161812722683\n",
      "Epoch: 1570, Loss: 0.019384905695915222\n",
      "Epoch: 1571, Loss: 0.01937124878168106\n",
      "Epoch: 1572, Loss: 0.019377369433641434\n",
      "Epoch: 1573, Loss: 0.01939716935157776\n",
      "Epoch: 1574, Loss: 0.019391410052776337\n",
      "Epoch: 1575, Loss: 0.01935286447405815\n",
      "Epoch: 1576, Loss: 0.019380832090973854\n",
      "Epoch: 1577, Loss: 0.01944510079920292\n",
      "Epoch: 1578, Loss: 0.01944100111722946\n",
      "Epoch: 1579, Loss: 0.019402051344513893\n",
      "Epoch: 1580, Loss: 0.019461514428257942\n",
      "Epoch: 1581, Loss: 0.019506679847836494\n",
      "Epoch: 1582, Loss: 0.019527848809957504\n",
      "Epoch: 1583, Loss: 0.01948040910065174\n",
      "Epoch: 1584, Loss: 0.01951063610613346\n",
      "Epoch: 1585, Loss: 0.01957087032496929\n",
      "Epoch: 1586, Loss: 0.019565830007195473\n",
      "Epoch: 1587, Loss: 0.019525127485394478\n",
      "Epoch: 1588, Loss: 0.019584205001592636\n",
      "Epoch: 1589, Loss: 0.01966201327741146\n",
      "Epoch: 1590, Loss: 0.01961040124297142\n",
      "Epoch: 1591, Loss: 0.01957845501601696\n",
      "Epoch: 1592, Loss: 0.019495204091072083\n",
      "Epoch: 1593, Loss: 0.019551696255803108\n",
      "Epoch: 1594, Loss: 0.019568320363759995\n",
      "Epoch: 1595, Loss: 0.0194917693734169\n",
      "Epoch: 1596, Loss: 0.019525280222296715\n",
      "Epoch: 1597, Loss: 0.01948731392621994\n",
      "Epoch: 1598, Loss: 0.019452186301350594\n",
      "Epoch: 1599, Loss: 0.019569741562008858\n",
      "Epoch: 1600, Loss: 0.019631242379546165\n",
      "Epoch: 1601, Loss: 0.01956244558095932\n",
      "Epoch: 1602, Loss: 0.019404882565140724\n",
      "Epoch: 1603, Loss: 0.01940922625362873\n",
      "Epoch: 1604, Loss: 0.019384408369660378\n",
      "Epoch: 1605, Loss: 0.01940058544278145\n",
      "Epoch: 1606, Loss: 0.01939902827143669\n",
      "Epoch: 1607, Loss: 0.019358690828084946\n",
      "Epoch: 1608, Loss: 0.01935505121946335\n",
      "Epoch: 1609, Loss: 0.019424034282565117\n",
      "Epoch: 1610, Loss: 0.019466497004032135\n",
      "Epoch: 1611, Loss: 0.019443480297923088\n",
      "Epoch: 1612, Loss: 0.019515864551067352\n",
      "Epoch: 1613, Loss: 0.019561896100640297\n",
      "Epoch: 1614, Loss: 0.01946636475622654\n",
      "Epoch: 1615, Loss: 0.019459156319499016\n",
      "Epoch: 1616, Loss: 0.019478531554341316\n",
      "Epoch: 1617, Loss: 0.019452067092061043\n",
      "Epoch: 1618, Loss: 0.01939680054783821\n",
      "Epoch: 1619, Loss: 0.01945710927248001\n",
      "Epoch: 1620, Loss: 0.01941729709506035\n",
      "Epoch: 1621, Loss: 0.019388701766729355\n",
      "Epoch: 1622, Loss: 0.019424570724368095\n",
      "Epoch: 1623, Loss: 0.019436899572610855\n",
      "Epoch: 1624, Loss: 0.01945449784398079\n",
      "Epoch: 1625, Loss: 0.01947830617427826\n",
      "Epoch: 1626, Loss: 0.019435524940490723\n",
      "Epoch: 1627, Loss: 0.01945554092526436\n",
      "Epoch: 1628, Loss: 0.019661016762256622\n",
      "Epoch: 1629, Loss: 0.019537264481186867\n",
      "Epoch: 1630, Loss: 0.019460251554846764\n",
      "Epoch: 1631, Loss: 0.019513936713337898\n",
      "Epoch: 1632, Loss: 0.019522178918123245\n",
      "Epoch: 1633, Loss: 0.01948058232665062\n",
      "Epoch: 1634, Loss: 0.0194835402071476\n",
      "Epoch: 1635, Loss: 0.019459061324596405\n",
      "Epoch: 1636, Loss: 0.019417479634284973\n",
      "Epoch: 1637, Loss: 0.01943318173289299\n",
      "Epoch: 1638, Loss: 0.019436653703451157\n",
      "Epoch: 1639, Loss: 0.019424989819526672\n",
      "Epoch: 1640, Loss: 0.019414380192756653\n",
      "Epoch: 1641, Loss: 0.01950151100754738\n",
      "Epoch: 1642, Loss: 0.019591787829995155\n",
      "Epoch: 1643, Loss: 0.019568800926208496\n",
      "Epoch: 1644, Loss: 0.019609469920396805\n",
      "Epoch: 1645, Loss: 0.019550427794456482\n",
      "Epoch: 1646, Loss: 0.019570516422390938\n",
      "Epoch: 1647, Loss: 0.019567016512155533\n",
      "Epoch: 1648, Loss: 0.01960654743015766\n",
      "Epoch: 1649, Loss: 0.019705669954419136\n",
      "Epoch: 1650, Loss: 0.019563773646950722\n",
      "Epoch: 1651, Loss: 0.019589990377426147\n",
      "Epoch: 1652, Loss: 0.01963026076555252\n",
      "Epoch: 1653, Loss: 0.01966957002878189\n",
      "Epoch: 1654, Loss: 0.019788745790719986\n",
      "Epoch: 1655, Loss: 0.01966003328561783\n",
      "Epoch: 1656, Loss: 0.019481811672449112\n",
      "Epoch: 1657, Loss: 0.0194155965000391\n",
      "Epoch: 1658, Loss: 0.019398994743824005\n",
      "Epoch: 1659, Loss: 0.01936262473464012\n",
      "Epoch: 1660, Loss: 0.019371191039681435\n",
      "Epoch: 1661, Loss: 0.019401948899030685\n",
      "Epoch: 1662, Loss: 0.019482210278511047\n",
      "Epoch: 1663, Loss: 0.019428741186857224\n",
      "Epoch: 1664, Loss: 0.019399579614400864\n",
      "Epoch: 1665, Loss: 0.01936817355453968\n",
      "Epoch: 1666, Loss: 0.019341474398970604\n",
      "Epoch: 1667, Loss: 0.019323119893670082\n",
      "Epoch: 1668, Loss: 0.01931104063987732\n",
      "Epoch: 1669, Loss: 0.019320862367749214\n",
      "Epoch: 1670, Loss: 0.019352449104189873\n",
      "Epoch: 1671, Loss: 0.019334988668560982\n",
      "Epoch: 1672, Loss: 0.019323674961924553\n",
      "Epoch: 1673, Loss: 0.019326113164424896\n",
      "Epoch: 1674, Loss: 0.019342143088579178\n",
      "Epoch: 1675, Loss: 0.019343677908182144\n",
      "Epoch: 1676, Loss: 0.019319260492920876\n",
      "Epoch: 1677, Loss: 0.01930426061153412\n",
      "Epoch: 1678, Loss: 0.019308000802993774\n",
      "Epoch: 1679, Loss: 0.01929512433707714\n",
      "Epoch: 1680, Loss: 0.0192892923951149\n",
      "Epoch: 1681, Loss: 0.019292237237095833\n",
      "Epoch: 1682, Loss: 0.01929090917110443\n",
      "Epoch: 1683, Loss: 0.019289357587695122\n",
      "Epoch: 1684, Loss: 0.019290022552013397\n",
      "Epoch: 1685, Loss: 0.01928521879017353\n",
      "Epoch: 1686, Loss: 0.019302336499094963\n",
      "Epoch: 1687, Loss: 0.019325070083141327\n",
      "Epoch: 1688, Loss: 0.019331667572259903\n",
      "Epoch: 1689, Loss: 0.019325274974107742\n",
      "Epoch: 1690, Loss: 0.019369397312402725\n",
      "Epoch: 1691, Loss: 0.019366350024938583\n",
      "Epoch: 1692, Loss: 0.019350068643689156\n",
      "Epoch: 1693, Loss: 0.019357949495315552\n",
      "Epoch: 1694, Loss: 0.01937541551887989\n",
      "Epoch: 1695, Loss: 0.019428161904215813\n",
      "Epoch: 1696, Loss: 0.019538719207048416\n",
      "Epoch: 1697, Loss: 0.019558724015951157\n",
      "Epoch: 1698, Loss: 0.019783303141593933\n",
      "Epoch: 1699, Loss: 0.019692886620759964\n",
      "Epoch: 1700, Loss: 0.019653253257274628\n",
      "Epoch: 1701, Loss: 0.019957799464464188\n",
      "Epoch: 1702, Loss: 0.0201116856187582\n",
      "Epoch: 1703, Loss: 0.020113127306103706\n",
      "Epoch: 1704, Loss: 0.020481334999203682\n",
      "Epoch: 1705, Loss: 0.020679514855146408\n",
      "Epoch: 1706, Loss: 0.021126551553606987\n",
      "Epoch: 1707, Loss: 0.020812582224607468\n",
      "Epoch: 1708, Loss: 0.022410834208130836\n",
      "Epoch: 1709, Loss: 0.023889701813459396\n",
      "Epoch: 1710, Loss: 0.023561106994748116\n",
      "Epoch: 1711, Loss: 0.022820252925157547\n",
      "Epoch: 1712, Loss: 0.02304009161889553\n",
      "Epoch: 1713, Loss: 0.023524263873696327\n",
      "Epoch: 1714, Loss: 0.0243139136582613\n",
      "Epoch: 1715, Loss: 0.023331312462687492\n",
      "Epoch: 1716, Loss: 0.022178933024406433\n",
      "Epoch: 1717, Loss: 0.021631671115756035\n",
      "Epoch: 1718, Loss: 0.021092277020215988\n",
      "Epoch: 1719, Loss: 0.020862452685832977\n",
      "Epoch: 1720, Loss: 0.02079137973487377\n",
      "Epoch: 1721, Loss: 0.02003614604473114\n",
      "Epoch: 1722, Loss: 0.01997409574687481\n",
      "Epoch: 1723, Loss: 0.019810136407613754\n",
      "Epoch: 1724, Loss: 0.019642049446702003\n",
      "Epoch: 1725, Loss: 0.01955394819378853\n",
      "Epoch: 1726, Loss: 0.01949397474527359\n",
      "Epoch: 1727, Loss: 0.019445326179265976\n",
      "Epoch: 1728, Loss: 0.01942177675664425\n",
      "Epoch: 1729, Loss: 0.019397921860218048\n",
      "Epoch: 1730, Loss: 0.0193810872733593\n",
      "Epoch: 1731, Loss: 0.0193651020526886\n",
      "Epoch: 1732, Loss: 0.01935291662812233\n",
      "Epoch: 1733, Loss: 0.0193419698625803\n",
      "Epoch: 1734, Loss: 0.019332097843289375\n",
      "Epoch: 1735, Loss: 0.01932387426495552\n",
      "Epoch: 1736, Loss: 0.019316356629133224\n",
      "Epoch: 1737, Loss: 0.019309701398015022\n",
      "Epoch: 1738, Loss: 0.019303595647215843\n",
      "Epoch: 1739, Loss: 0.019298136234283447\n",
      "Epoch: 1740, Loss: 0.019293026998639107\n",
      "Epoch: 1741, Loss: 0.01928851567208767\n",
      "Epoch: 1742, Loss: 0.019284257665276527\n",
      "Epoch: 1743, Loss: 0.01928027719259262\n",
      "Epoch: 1744, Loss: 0.019276563078165054\n",
      "Epoch: 1745, Loss: 0.01927303709089756\n",
      "Epoch: 1746, Loss: 0.01926969550549984\n",
      "Epoch: 1747, Loss: 0.019266430288553238\n",
      "Epoch: 1748, Loss: 0.01926323212683201\n",
      "Epoch: 1749, Loss: 0.01926000602543354\n",
      "Epoch: 1750, Loss: 0.019256658852100372\n",
      "Epoch: 1751, Loss: 0.019252995029091835\n",
      "Epoch: 1752, Loss: 0.019248684868216515\n",
      "Epoch: 1753, Loss: 0.01924297958612442\n",
      "Epoch: 1754, Loss: 0.019234083592891693\n",
      "Epoch: 1755, Loss: 0.019217032939195633\n",
      "Epoch: 1756, Loss: 0.0191808994859457\n",
      "Epoch: 1757, Loss: 0.019152000546455383\n",
      "Epoch: 1758, Loss: 0.019261794164776802\n",
      "Epoch: 1759, Loss: 0.019330410286784172\n",
      "Epoch: 1760, Loss: 0.01928960159420967\n",
      "Epoch: 1761, Loss: 0.019236382097005844\n",
      "Epoch: 1762, Loss: 0.01916452869772911\n",
      "Epoch: 1763, Loss: 0.019165225327014923\n",
      "Epoch: 1764, Loss: 0.0191337987780571\n",
      "Epoch: 1765, Loss: 0.019123202189803123\n",
      "Epoch: 1766, Loss: 0.019116690382361412\n",
      "Epoch: 1767, Loss: 0.01911291666328907\n",
      "Epoch: 1768, Loss: 0.019110877066850662\n",
      "Epoch: 1769, Loss: 0.019108068197965622\n",
      "Epoch: 1770, Loss: 0.0191063079982996\n",
      "Epoch: 1771, Loss: 0.01910443976521492\n",
      "Epoch: 1772, Loss: 0.01910289190709591\n",
      "Epoch: 1773, Loss: 0.01910197176039219\n",
      "Epoch: 1774, Loss: 0.019101161509752274\n",
      "Epoch: 1775, Loss: 0.019100887700915337\n",
      "Epoch: 1776, Loss: 0.019101707264780998\n",
      "Epoch: 1777, Loss: 0.019101478159427643\n",
      "Epoch: 1778, Loss: 0.019103677943348885\n",
      "Epoch: 1779, Loss: 0.019102243706583977\n",
      "Epoch: 1780, Loss: 0.01910332590341568\n",
      "Epoch: 1781, Loss: 0.019100790843367577\n",
      "Epoch: 1782, Loss: 0.01910029537975788\n",
      "Epoch: 1783, Loss: 0.019097384065389633\n",
      "Epoch: 1784, Loss: 0.01909582130610943\n",
      "Epoch: 1785, Loss: 0.019092880189418793\n",
      "Epoch: 1786, Loss: 0.01909063197672367\n",
      "Epoch: 1787, Loss: 0.01908763498067856\n",
      "Epoch: 1788, Loss: 0.019084693863987923\n",
      "Epoch: 1789, Loss: 0.019081275910139084\n",
      "Epoch: 1790, Loss: 0.019077399745583534\n",
      "Epoch: 1791, Loss: 0.019072920083999634\n",
      "Epoch: 1792, Loss: 0.01906743459403515\n",
      "Epoch: 1793, Loss: 0.019060684368014336\n",
      "Epoch: 1794, Loss: 0.019052311778068542\n",
      "Epoch: 1795, Loss: 0.019041717052459717\n",
      "Epoch: 1796, Loss: 0.019029973074793816\n",
      "Epoch: 1797, Loss: 0.01901828683912754\n",
      "Epoch: 1798, Loss: 0.019011633470654488\n",
      "Epoch: 1799, Loss: 0.01901492290198803\n",
      "Epoch: 1800, Loss: 0.01902865245938301\n",
      "Epoch: 1801, Loss: 0.01904243417084217\n",
      "Epoch: 1802, Loss: 0.019050847738981247\n",
      "Epoch: 1803, Loss: 0.019043713808059692\n",
      "Epoch: 1804, Loss: 0.019048018380999565\n",
      "Epoch: 1805, Loss: 0.01905425824224949\n",
      "Epoch: 1806, Loss: 0.01905466429889202\n",
      "Epoch: 1807, Loss: 0.019055230543017387\n",
      "Epoch: 1808, Loss: 0.019047703593969345\n",
      "Epoch: 1809, Loss: 0.019046969711780548\n",
      "Epoch: 1810, Loss: 0.019040178507566452\n",
      "Epoch: 1811, Loss: 0.019036846235394478\n",
      "Epoch: 1812, Loss: 0.019041242077946663\n",
      "Epoch: 1813, Loss: 0.0190522950142622\n",
      "Epoch: 1814, Loss: 0.019076481461524963\n",
      "Epoch: 1815, Loss: 0.019138026982545853\n",
      "Epoch: 1816, Loss: 0.019056199118494987\n",
      "Epoch: 1817, Loss: 0.01903262920677662\n",
      "Epoch: 1818, Loss: 0.019040677696466446\n",
      "Epoch: 1819, Loss: 0.019029144197702408\n",
      "Epoch: 1820, Loss: 0.019027559086680412\n",
      "Epoch: 1821, Loss: 0.019018663093447685\n",
      "Epoch: 1822, Loss: 0.01901526004076004\n",
      "Epoch: 1823, Loss: 0.019004719331860542\n",
      "Epoch: 1824, Loss: 0.01899752952158451\n",
      "Epoch: 1825, Loss: 0.018995147198438644\n",
      "Epoch: 1826, Loss: 0.018988782539963722\n",
      "Epoch: 1827, Loss: 0.01898055523633957\n",
      "Epoch: 1828, Loss: 0.018972914665937424\n",
      "Epoch: 1829, Loss: 0.018966276198625565\n",
      "Epoch: 1830, Loss: 0.01896207593381405\n",
      "Epoch: 1831, Loss: 0.01895962469279766\n",
      "Epoch: 1832, Loss: 0.01896335557103157\n",
      "Epoch: 1833, Loss: 0.018968908116221428\n",
      "Epoch: 1834, Loss: 0.018979838117957115\n",
      "Epoch: 1835, Loss: 0.01899281144142151\n",
      "Epoch: 1836, Loss: 0.018998056650161743\n",
      "Epoch: 1837, Loss: 0.019011616706848145\n",
      "Epoch: 1838, Loss: 0.0190013088285923\n",
      "Epoch: 1839, Loss: 0.01900930143892765\n",
      "Epoch: 1840, Loss: 0.018991978839039803\n",
      "Epoch: 1841, Loss: 0.018997563049197197\n",
      "Epoch: 1842, Loss: 0.018992245197296143\n",
      "Epoch: 1843, Loss: 0.01902094855904579\n",
      "Epoch: 1844, Loss: 0.01904091238975525\n",
      "Epoch: 1845, Loss: 0.019059179350733757\n",
      "Epoch: 1846, Loss: 0.019054345786571503\n",
      "Epoch: 1847, Loss: 0.01903950423002243\n",
      "Epoch: 1848, Loss: 0.019025703892111778\n",
      "Epoch: 1849, Loss: 0.019008606672286987\n",
      "Epoch: 1850, Loss: 0.019000211730599403\n",
      "Epoch: 1851, Loss: 0.018987447023391724\n",
      "Epoch: 1852, Loss: 0.018992947414517403\n",
      "Epoch: 1853, Loss: 0.019002674147486687\n",
      "Epoch: 1854, Loss: 0.01901968941092491\n",
      "Epoch: 1855, Loss: 0.019024448469281197\n",
      "Epoch: 1856, Loss: 0.019035976380109787\n",
      "Epoch: 1857, Loss: 0.019031085073947906\n",
      "Epoch: 1858, Loss: 0.019022513180971146\n",
      "Epoch: 1859, Loss: 0.019008876755833626\n",
      "Epoch: 1860, Loss: 0.01901441626250744\n",
      "Epoch: 1861, Loss: 0.019018545746803284\n",
      "Epoch: 1862, Loss: 0.019022271037101746\n",
      "Epoch: 1863, Loss: 0.019019916653633118\n",
      "Epoch: 1864, Loss: 0.019043290987610817\n",
      "Epoch: 1865, Loss: 0.019008517265319824\n",
      "Epoch: 1866, Loss: 0.019000748172402382\n",
      "Epoch: 1867, Loss: 0.018988074734807014\n",
      "Epoch: 1868, Loss: 0.018982544541358948\n",
      "Epoch: 1869, Loss: 0.018964339047670364\n",
      "Epoch: 1870, Loss: 0.01896616257727146\n",
      "Epoch: 1871, Loss: 0.018970679491758347\n",
      "Epoch: 1872, Loss: 0.018978124484419823\n",
      "Epoch: 1873, Loss: 0.018967874348163605\n",
      "Epoch: 1874, Loss: 0.01897324249148369\n",
      "Epoch: 1875, Loss: 0.01897314190864563\n",
      "Epoch: 1876, Loss: 0.018993811681866646\n",
      "Epoch: 1877, Loss: 0.018980368971824646\n",
      "Epoch: 1878, Loss: 0.01898634247481823\n",
      "Epoch: 1879, Loss: 0.01897628791630268\n",
      "Epoch: 1880, Loss: 0.018981153145432472\n",
      "Epoch: 1881, Loss: 0.01896907202899456\n",
      "Epoch: 1882, Loss: 0.018983112648129463\n",
      "Epoch: 1883, Loss: 0.01897101104259491\n",
      "Epoch: 1884, Loss: 0.018955783918499947\n",
      "Epoch: 1885, Loss: 0.01894512213766575\n",
      "Epoch: 1886, Loss: 0.01894998364150524\n",
      "Epoch: 1887, Loss: 0.018969092518091202\n",
      "Epoch: 1888, Loss: 0.018973171710968018\n",
      "Epoch: 1889, Loss: 0.018981005996465683\n",
      "Epoch: 1890, Loss: 0.0189625546336174\n",
      "Epoch: 1891, Loss: 0.018949178978800774\n",
      "Epoch: 1892, Loss: 0.018963530659675598\n",
      "Epoch: 1893, Loss: 0.01899769902229309\n",
      "Epoch: 1894, Loss: 0.019024157896637917\n",
      "Epoch: 1895, Loss: 0.019079944118857384\n",
      "Epoch: 1896, Loss: 0.019121522083878517\n",
      "Epoch: 1897, Loss: 0.019062263891100883\n",
      "Epoch: 1898, Loss: 0.019011901691555977\n",
      "Epoch: 1899, Loss: 0.018959300592541695\n",
      "Epoch: 1900, Loss: 0.01894681341946125\n",
      "Epoch: 1901, Loss: 0.018957430496811867\n",
      "Epoch: 1902, Loss: 0.018959982320666313\n",
      "Epoch: 1903, Loss: 0.018970131874084473\n",
      "Epoch: 1904, Loss: 0.018976915627717972\n",
      "Epoch: 1905, Loss: 0.018989551812410355\n",
      "Epoch: 1906, Loss: 0.018973909318447113\n",
      "Epoch: 1907, Loss: 0.01895837113261223\n",
      "Epoch: 1908, Loss: 0.018949629738926888\n",
      "Epoch: 1909, Loss: 0.018964601680636406\n",
      "Epoch: 1910, Loss: 0.018986985087394714\n",
      "Epoch: 1911, Loss: 0.019017720595002174\n",
      "Epoch: 1912, Loss: 0.01899651437997818\n",
      "Epoch: 1913, Loss: 0.018989859148859978\n",
      "Epoch: 1914, Loss: 0.018969811499118805\n",
      "Epoch: 1915, Loss: 0.018953585997223854\n",
      "Epoch: 1916, Loss: 0.018940633162856102\n",
      "Epoch: 1917, Loss: 0.018945837393403053\n",
      "Epoch: 1918, Loss: 0.018967339769005775\n",
      "Epoch: 1919, Loss: 0.018998362123966217\n",
      "Epoch: 1920, Loss: 0.018975768238306046\n",
      "Epoch: 1921, Loss: 0.018986154347658157\n",
      "Epoch: 1922, Loss: 0.018957847729325294\n",
      "Epoch: 1923, Loss: 0.018962588161230087\n",
      "Epoch: 1924, Loss: 0.01903148926794529\n",
      "Epoch: 1925, Loss: 0.019063936546444893\n",
      "Epoch: 1926, Loss: 0.019165579229593277\n",
      "Epoch: 1927, Loss: 0.019304217770695686\n",
      "Epoch: 1928, Loss: 0.019409123808145523\n",
      "Epoch: 1929, Loss: 0.019195588305592537\n",
      "Epoch: 1930, Loss: 0.019490595906972885\n",
      "Epoch: 1931, Loss: 0.019492894411087036\n",
      "Epoch: 1932, Loss: 0.019361399114131927\n",
      "Epoch: 1933, Loss: 0.019559308886528015\n",
      "Epoch: 1934, Loss: 0.01939299702644348\n",
      "Epoch: 1935, Loss: 0.019877083599567413\n",
      "Epoch: 1936, Loss: 0.019710039719939232\n",
      "Epoch: 1937, Loss: 0.0199241042137146\n",
      "Epoch: 1938, Loss: 0.01979549042880535\n",
      "Epoch: 1939, Loss: 0.019526267424225807\n",
      "Epoch: 1940, Loss: 0.019547874107956886\n",
      "Epoch: 1941, Loss: 0.019387125968933105\n",
      "Epoch: 1942, Loss: 0.01923280581831932\n",
      "Epoch: 1943, Loss: 0.019115513190627098\n",
      "Epoch: 1944, Loss: 0.019109399989247322\n",
      "Epoch: 1945, Loss: 0.01917187124490738\n",
      "Epoch: 1946, Loss: 0.019100425764918327\n",
      "Epoch: 1947, Loss: 0.019060155376791954\n",
      "Epoch: 1948, Loss: 0.01905159465968609\n",
      "Epoch: 1949, Loss: 0.019045500084757805\n",
      "Epoch: 1950, Loss: 0.019067630171775818\n",
      "Epoch: 1951, Loss: 0.019043108448386192\n",
      "Epoch: 1952, Loss: 0.019040880724787712\n",
      "Epoch: 1953, Loss: 0.019029200077056885\n",
      "Epoch: 1954, Loss: 0.018994932994246483\n",
      "Epoch: 1955, Loss: 0.018945014104247093\n",
      "Epoch: 1956, Loss: 0.018930403515696526\n",
      "Epoch: 1957, Loss: 0.01892934739589691\n",
      "Epoch: 1958, Loss: 0.018949437886476517\n",
      "Epoch: 1959, Loss: 0.018970955163240433\n",
      "Epoch: 1960, Loss: 0.018970057368278503\n",
      "Epoch: 1961, Loss: 0.01895262859761715\n",
      "Epoch: 1962, Loss: 0.018939252942800522\n",
      "Epoch: 1963, Loss: 0.018938174471259117\n",
      "Epoch: 1964, Loss: 0.018927263095974922\n",
      "Epoch: 1965, Loss: 0.01892814040184021\n",
      "Epoch: 1966, Loss: 0.01892755925655365\n",
      "Epoch: 1967, Loss: 0.018930092453956604\n",
      "Epoch: 1968, Loss: 0.018942885100841522\n",
      "Epoch: 1969, Loss: 0.018945608288049698\n",
      "Epoch: 1970, Loss: 0.018961435183882713\n",
      "Epoch: 1971, Loss: 0.018958155065774918\n",
      "Epoch: 1972, Loss: 0.018972188234329224\n",
      "Epoch: 1973, Loss: 0.018975667655467987\n",
      "Epoch: 1974, Loss: 0.0189988873898983\n",
      "Epoch: 1975, Loss: 0.01900400035083294\n",
      "Epoch: 1976, Loss: 0.019020890817046165\n",
      "Epoch: 1977, Loss: 0.019015416502952576\n",
      "Epoch: 1978, Loss: 0.019012294709682465\n",
      "Epoch: 1979, Loss: 0.01899692602455616\n",
      "Epoch: 1980, Loss: 0.018991610035300255\n",
      "Epoch: 1981, Loss: 0.01898796856403351\n",
      "Epoch: 1982, Loss: 0.018998345360159874\n",
      "Epoch: 1983, Loss: 0.01899624988436699\n",
      "Epoch: 1984, Loss: 0.019001251086592674\n",
      "Epoch: 1985, Loss: 0.01897846721112728\n",
      "Epoch: 1986, Loss: 0.018962377682328224\n",
      "Epoch: 1987, Loss: 0.01893346570432186\n",
      "Epoch: 1988, Loss: 0.018916569650173187\n",
      "Epoch: 1989, Loss: 0.0188981294631958\n",
      "Epoch: 1990, Loss: 0.018894098699092865\n",
      "Epoch: 1991, Loss: 0.018892616033554077\n",
      "Epoch: 1992, Loss: 0.018898354843258858\n",
      "Epoch: 1993, Loss: 0.018899045884609222\n",
      "Epoch: 1994, Loss: 0.018895292654633522\n",
      "Epoch: 1995, Loss: 0.018885433673858643\n",
      "Epoch: 1996, Loss: 0.018881984055042267\n",
      "Epoch: 1997, Loss: 0.018886998295783997\n",
      "Epoch: 1998, Loss: 0.018908368423581123\n",
      "Epoch: 1999, Loss: 0.018918896093964577\n",
      "Epoch: 2000, Loss: 0.018931085243821144\n",
      "torch.Size([18, 10, 20])\n"
     ]
    }
   ],
   "source": [
    "model = LSTMRacePosition(input_size=20, hidden_size=64, output_size=10)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "temp = None\n",
    "num_epochs = 2000\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_x, batch_y in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(batch_x)\n",
    "        # print(output.shape)\n",
    "        # print(batch_y.shape)\n",
    "        loss = criterion(output, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        temp = output.shape\n",
    "    print(\"Epoch: {}, Loss: {}\".format(epoch+1, loss.item()))\n",
    "print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get cosine similarity on test set\n",
    "with torch.no_grad():\n",
    "    predictions = model(torch.tensor(one_hot_encode(X_test,20), dtype=torch.float32))\n",
    "    predictions = predictions.argmax(dim=2).tolist()\n",
    "\n",
    "    # predictions = predictions.numpy()\n",
    "# make only the max value 1 and the rest 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19, 4, 10, 6, 8, 13, 5, 4, 11, 1], [8, 6, 13, 3, 6, 14, 13, 11, 12, 10], [13, 14, 5, 10, 12, 3, 8, 7, 9, 2], [8, 1, 6, 0, 3, 11, 5, 7, 9, 10], [10, 14, 15, 16, 7, 2, 17, 11, 8, 12], [17, 7, 19, 5, 14, 4, 12, 6, 8, 5], [12, 1, 8, 10, 3, 7, 11, 13, 4, 14], [5, 13, 12, 1, 2, 7, 3, 9, 10, 4], [8, 17, 12, 11, 10, 13, 14, 6, 2, 15], [6, 5, 10, 3, 12, 9, 7, 1, 8, 10], [8, 4, 10, 13, 4, 5, 7, 11, 14, 0], [9, 2, 12, 6, 12, 4, 7, 1, 4, 5], [3, 17, 16, 12, 11, 14, 8, 1, 0, 10], [15, 3, 13, 9, 11, 12, 1, 5, 18, 8], [17, 11, 13, 7, 12, 14, 19, 8, 4, 10], [4, 7, 11, 6, 1, 10, 9, 8, 0, 3], [12, 13, 6, 7, 14, 8, 18, 19, 5, 11]]\n",
      "[[20, 5, 11, 7, 9, 14, 6, 5, 12, 2], [9, 7, 14, 4, 7, 15, 14, 12, 13, 11], [14, 15, 6, 11, 13, 4, 9, 8, 10, 3], [9, 2, 7, 1, 4, 12, 6, 8, 10, 11], [11, 15, 16, 17, 8, 3, 18, 12, 9, 13], [18, 8, 20, 6, 15, 5, 13, 7, 9, 6], [13, 2, 9, 11, 4, 8, 12, 14, 5, 15], [6, 14, 13, 2, 3, 8, 4, 10, 11, 5], [9, 18, 13, 12, 11, 14, 15, 7, 3, 16], [7, 6, 11, 4, 13, 10, 8, 2, 9, 11], [9, 5, 11, 14, 5, 6, 8, 12, 15, 1], [10, 3, 13, 7, 13, 5, 8, 2, 5, 6], [4, 18, 17, 13, 12, 15, 9, 2, 1, 11], [16, 4, 14, 10, 12, 13, 2, 6, 19, 9], [18, 12, 14, 8, 13, 15, 20, 9, 5, 11], [5, 8, 12, 7, 2, 11, 10, 9, 1, 4], [13, 14, 7, 8, 15, 9, 19, 20, 6, 12]]\n"
     ]
    }
   ],
   "source": [
    "print(predictions)\n",
    "# add one to each value\n",
    "for i in range(len(predictions)):\n",
    "    for j in range(len(predictions[i])):\n",
    "        predictions[i][j] += 1\n",
    "print(predictions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20  5 11  7  9 14  6  5 12  2]\n",
      "[ 8  2  2  5  3 11  7  6  2  2]\n",
      "0.8637257676283169\n",
      "===================================================================================\n",
      "0.8637257676283169\n",
      "[ 9  7 14  4  7 15 14 12 13 11]\n",
      "[15 18 12 13 15 17 17 13 19 15]\n",
      "0.9484771988421224\n",
      "===================================================================================\n",
      "0.9484771988421224\n",
      "[14 15  6 11 13  4  9  8 10  3]\n",
      "[ 8 14 15 14 11 17  6 16  6  8]\n",
      "0.8492846143086356\n",
      "===================================================================================\n",
      "0.8492846143086356\n",
      "[ 9  2  7  1  4 12  6  8 10 11]\n",
      "[13 11 11 11 12 13  9  9 14 12]\n",
      "0.9100816894838395\n",
      "===================================================================================\n",
      "0.9100816894838395\n",
      "[11 15 16 17  8  3 18 12  9 13]\n",
      "[14 17 15 16 12 17 15 14 14 14]\n",
      "0.9404413704260469\n",
      "===================================================================================\n",
      "0.9404413704260469\n",
      "[18  8 20  6 15  5 13  7  9  6]\n",
      "[16 12 15 11 13 15 12 12 16 15]\n",
      "0.9109449586809105\n",
      "===================================================================================\n",
      "0.9109449586809105\n",
      "[13  2  9 11  4  8 12 14  5 15]\n",
      "[10 10  6  6  5  8 12 10 11  6]\n",
      "0.8774575823156006\n",
      "===================================================================================\n",
      "0.8774575823156006\n",
      "[ 6 14 13  2  3  8  4 10 11  5]\n",
      "[11 17 17 14 12 17 13  9 14 15]\n",
      "0.9011317615411529\n",
      "===================================================================================\n",
      "0.9011317615411529\n",
      "[ 9 18 13 12 11 14 15  7  3 16]\n",
      "[16  9 14 17 14 17 16 16 11 10]\n",
      "0.9090832095767554\n",
      "===================================================================================\n",
      "0.9090832095767554\n",
      "[ 7  6 11  4 13 10  8  2  9 11]\n",
      "[13 11  8  6  6  5  8 10  7  4]\n",
      "0.8173922982766013\n",
      "===================================================================================\n",
      "0.8173922982766013\n",
      "[ 9  5 11 14  5  6  8 12 15  1]\n",
      "[3 3 2 3 4 1 1 2 3 6]\n",
      "0.7168100430143384\n",
      "===================================================================================\n",
      "0.7168100430143384\n",
      "[10  3 13  7 13  5  8  2  5  6]\n",
      "[ 5  9 10  7  4  6 15 13  8  8]\n",
      "0.779223578185982\n",
      "===================================================================================\n",
      "0.779223578185982\n",
      "[ 4 18 17 13 12 15  9  2  1 11]\n",
      "[18 12 18 17 14 11 18 14 16 12]\n",
      "0.8326619653618647\n",
      "===================================================================================\n",
      "0.8326619653618647\n",
      "[16  4 14 10 12 13  2  6 19  9]\n",
      "[13  4  5  8  5  8  6 15  3 10]\n",
      "0.7873626640294139\n",
      "===================================================================================\n",
      "0.7873626640294139\n",
      "[18 12 14  8 13 15 20  9  5 11]\n",
      "[17 16 14  7  9 16 11 19 17 15]\n",
      "0.9071341703892252\n",
      "===================================================================================\n",
      "0.9071341703892252\n",
      "[ 5  8 12  7  2 11 10  9  1  4]\n",
      "[ 7 12 10 17 13 14 16 19 13 14]\n",
      "0.8793865200988186\n",
      "===================================================================================\n",
      "0.8793865200988186\n",
      "[13 14  7  8 15  9 19 20  6 12]\n",
      "[13 17 15 14 14  8  6 15 14 17]\n",
      "0.8917350096375136\n",
      "===================================================================================\n",
      "0.8917350096375136\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# print acc\n",
    "count = 0\n",
    "for i in range(len(predictions)):\n",
    "    np_pred = np.array(predictions[i]) \n",
    "    np_y_test = np.array(y_test[i]) \n",
    "\n",
    "    similarity = cosine_similarity([np_pred, np_y_test])\n",
    "    cosine_sim = similarity[0][1]\n",
    "    print(np_pred )\n",
    "    print(np_y_test )\n",
    "    print(cosine_sim)\n",
    "    print('===================================================================================')\n",
    "    print(cosine_sim)\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
